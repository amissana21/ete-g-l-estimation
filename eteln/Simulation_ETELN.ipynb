{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3LfTxi6bqZkl"
      },
      "outputs": [],
      "source": [
        "!pip install jax jaxlib\n",
        "!pip install --quiet --upgrade scipy\n",
        "!pip install --quiet jax jaxlib optax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nSZoOLdPiRhT"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "from jax.scipy.stats import norm\n",
        "import jax.numpy as jnp\n",
        "from scipy.stats import norm\n",
        "import time\n",
        "import jax.numpy as jnp\n",
        "from numpy.polynomial.legendre import leggauss\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.optimize import minimize_scalar, brentq, minimize\n",
        "from scipy.special import gamma\n",
        "from numpy.polynomial.legendre import leggauss\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from numpy.random import default_rng\n",
        "from math import log\n",
        "from numpy.random import default_rng, SeedSequence\n",
        "from scipy.stats import kstwobign, cramervonmises, uniform\n",
        "from joblib import Parallel, delayed\n",
        "from itertools import zip_longest\n",
        "from collections import OrderedDict\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ==============================================================\n",
        "# ETELN Simulation Same J\n",
        "# ==============================================================\n"
      ],
      "metadata": {
        "id": "AABhVUXywLsU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================\n",
        "# ETELN ARE Table\n",
        "# ==============================================================\n",
        "\n",
        "# ---------- pretty, wide table printing ----------\n",
        "pd.set_option(\"display.width\", 2000)\n",
        "pd.set_option(\"display.max_columns\", None)\n",
        "pd.set_option(\"display.expand_frame_repr\", False)\n",
        "\n",
        "\n",
        "class ETELNARE:\n",
        "    def __init__(self, theta=1.0, kuma_a=1.0, kuma_b=1.0, n_quad=200):\n",
        "        self.theta = theta\n",
        "        self.kuma_a = kuma_a\n",
        "        self.kuma_b = kuma_b\n",
        "        self.n_quad = n_quad\n",
        "        # Precompute Gauss–Legendre nodes & weights\n",
        "        self.nodes, self.weights = np.polynomial.legendre.leggauss(n_quad)\n",
        "        # Transform nodes from [-1,1] → [0,1]\n",
        "        self.u = 0.5 * (self.nodes + 1)\n",
        "        self.w = 0.5 * self.weights\n",
        "\n",
        "    def kumaraswamy_weight(self, u, a=None, b=None):\n",
        "        if a is None: a = self.kuma_a\n",
        "        if b is None: b = self.kuma_b\n",
        "        return a * b * (u ** (a - 1)) * ((1 - u**a) ** (b - 1))\n",
        "\n",
        "    # ---- Dk integral using Gauss–Legendre ----\n",
        "    def compute_dk(self, beta, k):\n",
        "        \"\"\"\n",
        "        Compute d_{h,k}(β) = ∫₀¹ J(u) [Φ⁻¹[(2^β-(2^β-1)u)^(-1/β)]]^k du\n",
        "        \"\"\"\n",
        "        u, w = self.u, self.w\n",
        "        weights = self.kumaraswamy_weight(u)\n",
        "\n",
        "        # u_0(β) = [2^β - (2^β-1)u]^(-1/β)\n",
        "        base = 2**beta - (2**beta - 1) * u\n",
        "\n",
        "        # Ensure base > 0 and compute u0\n",
        "        mask = base > 0\n",
        "        u0 = np.zeros_like(u)\n",
        "        u0[mask] = base[mask] ** (-1/beta)\n",
        "\n",
        "        # Clip u0 to valid probability range [ε, 1-ε]\n",
        "        eps = 1e-9\n",
        "        u0 = np.clip(u0, eps, 1 - eps)\n",
        "\n",
        "        # ξ = Φ⁻¹[u₀(β)]\n",
        "        xi = norm.ppf(u0)\n",
        "\n",
        "        # Integrand: J(u) * ξ^k\n",
        "        integrand = weights * (xi ** k)\n",
        "\n",
        "        return np.sum(w * integrand)\n",
        "\n",
        "    def tau(self, beta):\n",
        "        \"\"\"τ_h(β) = d_{h,2}(β) - [d_{h,1}(β)]²\"\"\"\n",
        "        D1 = self.compute_dk(beta, 1)\n",
        "        D2 = self.compute_dk(beta, 2)\n",
        "        return D2 - D1**2\n",
        "\n",
        "    def solve_beta(self, mu1, mu2, beta_range=(-3, 3)):\n",
        "        \"\"\"\n",
        "        Solve implicit equation for β, then compute α\n",
        "        For ETELN: μ₁ = log(θ) + (1/α)d_{h,1}\n",
        "        So: d_{h,1}/α = μ₁ - log(θ)\n",
        "\n",
        "        Implicit equation: d_{h,1}/√τ_h = (μ₁ - log θ)/√Δ_h\n",
        "        \"\"\"\n",
        "        Delta = mu2 - mu1**2\n",
        "\n",
        "        if Delta <= 0:\n",
        "            print(f\"  Warning: Delta <= 0 ({Delta:.6f})\")\n",
        "            return np.nan, np.nan\n",
        "\n",
        "        def f(beta):\n",
        "            try:\n",
        "                D1 = self.compute_dk(beta, 1)\n",
        "                t = self.tau(beta)\n",
        "\n",
        "                if t <= 0:\n",
        "                    return np.nan\n",
        "\n",
        "                # R(β) = d_{h,1}/√τ_h - (μ₁ - log θ)/√Δ_h\n",
        "                # Note: For ETELN, it's (μ₁ - log θ) not (log θ - μ₁)\n",
        "                lhs = D1 / np.sqrt(t)\n",
        "                rhs = (mu1 - np.log(self.theta)) / np.sqrt(Delta)\n",
        "\n",
        "                return lhs - rhs\n",
        "            except:\n",
        "                return np.nan\n",
        "\n",
        "        # Try to find sign change\n",
        "        beta_test = np.linspace(beta_range[0], beta_range[1], 20)\n",
        "        f_vals = [f(b) for b in beta_test]\n",
        "        f_vals = np.array([v if not np.isnan(v) else 0 for v in f_vals])\n",
        "\n",
        "        # Check for sign change\n",
        "        sign_changes = np.where(np.diff(np.sign(f_vals)))[0]\n",
        "\n",
        "        if len(sign_changes) == 0:\n",
        "            return np.nan, np.nan\n",
        "\n",
        "        # Use first sign change\n",
        "        idx = sign_changes[0]\n",
        "        beta_low = beta_test[idx]\n",
        "        beta_high = beta_test[idx + 1]\n",
        "\n",
        "        from scipy.optimize import brentq\n",
        "        try:\n",
        "            beta_hat = brentq(f, beta_low, beta_high, xtol=1e-10, rtol=1e-8, maxiter=500)\n",
        "            t = self.tau(beta_hat)\n",
        "            alpha_hat = np.sqrt(t / Delta)\n",
        "            return alpha_hat, beta_hat\n",
        "        except Exception as e:\n",
        "            print(f\"  Brentq failed: {e}\")\n",
        "            return np.nan, np.nan\n",
        "\n",
        "    # ---- Variance–covariance matrix via Λ integrals ----\n",
        "    def compute_lambda_integral(self, type_num, alpha, beta):\n",
        "        \"\"\"\n",
        "        Compute Λ_{h,i} integrals for ETELN\n",
        "        These involve 1/φ(ξ) terms\n",
        "        \"\"\"\n",
        "        u, w = self.u, self.w\n",
        "        weights = self.kumaraswamy_weight(u)\n",
        "\n",
        "        # u_0(β) = [2^β - (2^β-1)u]^(-1/β)\n",
        "        base = 2**beta - (2**beta - 1) * u\n",
        "        mask = base > 0\n",
        "        u0 = np.zeros_like(u)\n",
        "        u0[mask] = base[mask] ** (-1/beta)\n",
        "\n",
        "        # Clip to valid range\n",
        "        eps = 1e-9\n",
        "        u0 = np.clip(u0, eps, 1 - eps)\n",
        "\n",
        "        # ξ = Φ⁻¹[u₀(β)]\n",
        "        xi = norm.ppf(u0)\n",
        "\n",
        "        # φ(ξ) = standard normal pdf\n",
        "        phi_xi = norm.pdf(xi)\n",
        "\n",
        "        # g(u) = [2^β-(2^β-1)u]^(-(1+β)/β) / φ(ξ)\n",
        "        exponent = -(1 + beta) / beta\n",
        "        g = np.zeros_like(u)\n",
        "        valid_mask = (base > 0) & (phi_xi > 1e-300)\n",
        "        g[valid_mask] = (base[valid_mask] ** exponent) / phi_xi[valid_mask]\n",
        "\n",
        "        # kernel K(v,w) = min(v,w) - v*w\n",
        "        def kernel(v, w):\n",
        "            return np.minimum(v, w) - v * w\n",
        "\n",
        "        result = 0.0\n",
        "        for i in range(len(u)):\n",
        "            for j in range(len(u)):\n",
        "                if type_num == 1:\n",
        "                    # Λ_{h,1}: g_i * g_j\n",
        "                    val = weights[i] * weights[j] * kernel(u[i], u[j]) * g[i] * g[j]\n",
        "                elif type_num == 2:\n",
        "                    # Λ_{h,2}: g_i * ξ_j * g_j\n",
        "                    val = weights[i] * weights[j] * kernel(u[i], u[j]) * g[i] * xi[j] * g[j]\n",
        "                elif type_num == 3:\n",
        "                    # Λ_{h,3}: ξ_i * g_i * ξ_j * g_j\n",
        "                    val = weights[i] * weights[j] * kernel(u[i], u[j]) * xi[i] * g[i] * xi[j] * g[j]\n",
        "                else:\n",
        "                    raise ValueError(\"Invalid type_num\")\n",
        "                result += w[i] * w[j] * val\n",
        "\n",
        "        return result\n",
        "\n",
        "    def compute_variance_covariance(self, alpha, beta):\n",
        "        \"\"\"\n",
        "        Compute Σ_L for ETELN (Different h, Same J)\n",
        "        \"\"\"\n",
        "        delta = ((2**beta - 1) / (alpha * beta)) ** 2\n",
        "\n",
        "        L1 = self.compute_lambda_integral(1, alpha, beta)\n",
        "        L2 = self.compute_lambda_integral(2, alpha, beta)\n",
        "        L3 = self.compute_lambda_integral(3, alpha, beta)\n",
        "\n",
        "        # PLUS signs in off-diagonal (different from ETELL)\n",
        "        Sigma11 = delta * L1\n",
        "        Sigma12 = delta * (2*np.log(self.theta)*L1 + 2/alpha*L2)\n",
        "        Sigma22 = delta * (4*np.log(self.theta)**2*L1 + 8*np.log(self.theta)/alpha*L2 + 4/alpha**2*L3)\n",
        "\n",
        "        return np.array([[Sigma11, Sigma12], [Sigma12, Sigma22]])\n",
        "\n",
        "    def fisher_information(self, alpha, beta, n):\n",
        "        \"\"\"\n",
        "        Compute Fisher Information for ETELN\n",
        "        \"\"\"\n",
        "        # Integration over u ∈ [0,1]\n",
        "        u_int = np.linspace(1e-6, 1 - 1e-6, 64)\n",
        "\n",
        "        # u_0(β) = [2^β - (2^β-1)u]^(-1/β)\n",
        "        u0 = (2**beta - (2**beta - 1) * u_int) ** (-1/beta)\n",
        "        u0 = np.clip(u0, 1e-9, 1 - 1e-9)\n",
        "\n",
        "        # ξ = Φ⁻¹[u₀]\n",
        "        xi = norm.ppf(u0)\n",
        "        phi_xi = norm.pdf(xi)\n",
        "        Phi_xi = norm.cdf(xi)\n",
        "\n",
        "        # Avoid division by zero\n",
        "        ratio = np.where(Phi_xi > 1e-300, phi_xi / Phi_xi, 0.0)\n",
        "        ratio2 = np.where(Phi_xi > 1e-300, (phi_xi / Phi_xi) ** 2, 0.0)\n",
        "\n",
        "        # Expectations\n",
        "        moment2 = np.trapz(xi**2, u_int) / alpha**2\n",
        "        moment_ratio1 = np.trapz(ratio * xi, u_int) / alpha\n",
        "        moment_ratio3 = np.trapz(xi**3 * ratio, u_int) / alpha**2\n",
        "        moment_ratio2_sq = np.trapz(xi**2 * ratio2, u_int) / alpha**2\n",
        "\n",
        "        # Fisher Information elements\n",
        "        two_pow_beta = 2**beta\n",
        "        denom = two_pow_beta - 1\n",
        "\n",
        "        # I_ββ (same as ETELL)\n",
        "        Ibb = (1 / beta**2) * (1 - (two_pow_beta * beta**2 * (np.log(2)**2)) / (denom**2))\n",
        "\n",
        "        # I_αα\n",
        "        Iaa = (1 / alpha**2) * (1 + moment2 + (beta + 1)**2 * moment_ratio2_sq +\n",
        "                                 2 * alpha * (beta + 1) * moment_ratio3)\n",
        "\n",
        "        # I_αβ\n",
        "        Iab = moment_ratio1\n",
        "\n",
        "        return n * np.array([[Iaa, Iab], [Iab, Ibb]])\n",
        "\n",
        "    # ---- ARE ----\n",
        "    def compute_ARE(self, mu1, mu2, n):\n",
        "        \"\"\"Compute ARE for ETELN L-estimator vs MLE\"\"\"\n",
        "        alpha_hat, beta_hat = self.solve_beta(mu1, mu2)\n",
        "\n",
        "        if np.isnan(alpha_hat) or np.isnan(beta_hat):\n",
        "            return np.nan\n",
        "\n",
        "        Sigma = self.compute_variance_covariance(alpha_hat, beta_hat) / n\n",
        "\n",
        "        # Jacobian (finite differences)\n",
        "        eps = 1e-6\n",
        "        def get_params(m1, m2):\n",
        "            a, b = self.solve_beta(m1, m2)\n",
        "            if np.isnan(a) or np.isnan(b):\n",
        "                return alpha_hat, beta_hat\n",
        "            return a, b\n",
        "\n",
        "        alpha_p1, beta_p1 = get_params(mu1 + eps, mu2)\n",
        "        alpha_m1, beta_m1 = get_params(mu1 - eps, mu2)\n",
        "        alpha_p2, beta_p2 = get_params(mu1, mu2 + eps)\n",
        "        alpha_m2, beta_m2 = get_params(mu1, mu2 - eps)\n",
        "\n",
        "        D = np.array([\n",
        "            [(alpha_p1 - alpha_m1) / (2*eps), (alpha_p2 - alpha_m2) / (2*eps)],\n",
        "            [(beta_p1 - beta_m1) / (2*eps), (beta_p2 - beta_m2) / (2*eps)]\n",
        "        ])\n",
        "\n",
        "        S_K = D @ Sigma @ D.T\n",
        "        I = self.fisher_information(alpha_hat, beta_hat, n)\n",
        "\n",
        "        try:\n",
        "            S_MLE = np.linalg.inv(I)\n",
        "        except np.linalg.LinAlgError:\n",
        "            return np.nan\n",
        "\n",
        "        det_S_K = np.linalg.det(S_K)\n",
        "        det_S_MLE = np.linalg.det(S_MLE)\n",
        "\n",
        "        if det_S_K > 0 and det_S_MLE > 0:\n",
        "            ARE_det = np.sqrt(det_S_MLE / det_S_K)\n",
        "        else:\n",
        "            ARE_det = np.nan\n",
        "\n",
        "        return ARE_det\n",
        "\n"
      ],
      "metadata": {
        "id": "wc-6H-jq1ceM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================\n",
        "# ETELN Simulation Study - Same J Design\n",
        "# ==============================================================\n",
        "\n",
        "class ETELNSimulation:\n",
        "    \"\"\"\n",
        "    ETELN Simulation with L-estimation (Same J, Different h design)\n",
        "      - Stable quantile generation via Φ⁻¹\n",
        "      - Vectorized Λ integrals with 1/φ(ξ) terms\n",
        "      - Robust beta solver\n",
        "      - MLE for ETELN\n",
        "      - Determinant-based RE/ARE\n",
        "    \"\"\"\n",
        "\n",
        "    # ----------------------------- init & quadrature -----------------------------\n",
        "    def __init__(self, theta=1.0, alpha=2.0, beta=0.5, n_quad=200,\n",
        "                 use_det_re=True, use_numeric_info=False, rng=None):\n",
        "        self.theta = float(theta)\n",
        "        self.alpha_true = float(alpha)\n",
        "        self.beta_true = float(beta)\n",
        "        self.use_det_re = bool(use_det_re)\n",
        "        self.use_numeric_info = bool(use_numeric_info)\n",
        "\n",
        "        self.nodes, self.weights = leggauss(n_quad)\n",
        "        self.u = 0.5 * (self.nodes + 1.0)   # map [-1,1] -> [0,1]\n",
        "        self.w = 0.5 * self.weights\n",
        "        self._K = None                      # cache Brownian-bridge kernel\n",
        "        self.rng = np.random.default_rng(rng)\n",
        "\n",
        "    # ----------------------------- distributions & transforms -----------------------------\n",
        "    @staticmethod\n",
        "    def kumaraswamy_weight(u, a, b):\n",
        "        return a * b * (u**(a-1.0)) * ((1.0 - u**a)**(b-1.0))\n",
        "\n",
        "    def _stable_terms_eteln(self, beta, u):\n",
        "        \"\"\"\n",
        "        Return u0, xi, phi_xi, g for ETELN:\n",
        "          u0 = [2^β - (2^β-1)u]^(-1/β)\n",
        "          xi = Φ⁻¹[u0]\n",
        "          phi_xi = φ(xi)\n",
        "          g = [2^β-(2^β-1)u]^(-(1+β)/β) / φ(ξ)\n",
        "        \"\"\"\n",
        "        with np.errstate(all='ignore'):\n",
        "            two_pow_beta = np.exp(beta * np.log(2.0))\n",
        "            base = two_pow_beta - (two_pow_beta - 1.0) * u\n",
        "            base = np.maximum(base, 1e-15)\n",
        "\n",
        "            # Handle beta ≈ 0 case\n",
        "            if abs(beta) < 1e-8:\n",
        "                # Limit: [2^β - (2^β-1)u]^(-1/β) → 2^(-(1-u))\n",
        "                u0 = np.exp(-(1.0 - u) * np.log(2.0))  # = 2^(-(1-u))\n",
        "                exponent = -1.0  # limit of -(1+β)/β as β→0\n",
        "            else:\n",
        "                u0 = base ** (-1.0/beta)\n",
        "                exponent = -(1.0 + beta) / beta\n",
        "\n",
        "            u0 = np.clip(u0, 1e-9, 1 - 1e-9)\n",
        "\n",
        "            xi = norm.ppf(u0)\n",
        "            xi = np.where(np.isfinite(xi), xi, 0.0)\n",
        "\n",
        "            phi_xi = norm.pdf(xi)\n",
        "            phi_xi = np.maximum(phi_xi, 1e-300)\n",
        "\n",
        "            g = np.zeros_like(u)\n",
        "            valid = (base > 0) & (phi_xi > 1e-300)\n",
        "            g[valid] = (base[valid] ** exponent) / phi_xi[valid]\n",
        "            g = np.where(np.isfinite(g), g, 0.0)\n",
        "\n",
        "        return u0, xi, phi_xi, g\n",
        "\n",
        "    def _kernel_matrix(self):\n",
        "        if self._K is None:\n",
        "            u = self.u\n",
        "            self._K = np.minimum(u[:,None], u[None,:]) - (u[:,None] * u[None,:])\n",
        "        return self._K\n",
        "\n",
        "    # ----------------------------- quantile & sampling -----------------------------\n",
        "    def generate_eteln_sample(self, n):\n",
        "        \"\"\"\n",
        "        Inverse-transform sampling from ETELN(θ, α, β).\n",
        "        Q(u) = θ exp{(1/α) Φ⁻¹[(2^β-(2^β-1)u)^(-1/β)]}\n",
        "        \"\"\"\n",
        "        u = self.rng.uniform(0.0, 1.0, int(n))\n",
        "\n",
        "        with np.errstate(all='ignore'):\n",
        "            if abs(self.beta_true) < 1e-8:\n",
        "                # Limit case\n",
        "                u0 = 2.0 ** (-(1.0 - u))\n",
        "            else:\n",
        "                two_pow_beta = np.exp(self.beta_true * np.log(2.0))\n",
        "                base = two_pow_beta - (two_pow_beta - 1.0) * u\n",
        "                u0 = base ** (-1/self.beta_true)\n",
        "\n",
        "            u0 = np.clip(u0, 1e-9, 1 - 1e-9)\n",
        "            xi = norm.ppf(u0)\n",
        "            x = self.theta * np.exp((1.0/self.alpha_true) * xi)\n",
        "\n",
        "        return x\n",
        "\n",
        "    # ----------------------------- d_k and tau -----------------------------\n",
        "    def compute_dk(self, beta, k, a, b):\n",
        "        \"\"\"\n",
        "        d_k(β) = ∫_0^1 J(u;a,b) [Φ⁻¹[(2^β-(2^β-1)u)^(-1/β)]]^k du\n",
        "        \"\"\"\n",
        "        u, w = self.u, self.w\n",
        "        J = self.kumaraswamy_weight(u, a, b)\n",
        "\n",
        "        # Handle beta ≈ 0 separately\n",
        "        if abs(beta) < 1e-8:\n",
        "            u0 = np.exp(-(1.0 - u) * np.log(2.0))  # 2^(-(1-u))\n",
        "            u0 = np.clip(u0, 1e-9, 1 - 1e-9)\n",
        "            xi = norm.ppf(u0)\n",
        "        else:\n",
        "            u0, xi, _, _ = self._stable_terms_eteln(beta, u)\n",
        "\n",
        "        if k == 1:\n",
        "            integrand = J * xi\n",
        "        elif k == 2:\n",
        "            integrand = J * (xi ** 2)\n",
        "        else:\n",
        "            raise ValueError(\"k must be 1 or 2\")\n",
        "\n",
        "        return np.sum(w * integrand)\n",
        "\n",
        "    def tau(self, beta, a, b):\n",
        "        \"\"\"τ_h(β) = d_{h,2}(β) - [d_{h,1}(β)]²\"\"\"\n",
        "        d1 = self.compute_dk(beta, 1, a, b)\n",
        "        d2 = self.compute_dk(beta, 2, a, b)\n",
        "        return d2 - d1**2\n",
        "\n",
        "    # ----------------------------- Λ integrals & covariance -----------------------------\n",
        "    def _lambda_triplet(self, alpha, beta, a, b):\n",
        "        \"\"\"\n",
        "        Vectorized Λ1, Λ2, Λ3 with 1/φ(ξ) terms for ETELN\n",
        "        \"\"\"\n",
        "        u, w = self.u, self.w\n",
        "        J = self.kumaraswamy_weight(u, a, b)\n",
        "        u0, xi, phi_xi, g = self._stable_terms_eteln(beta, u)\n",
        "\n",
        "        W = (w * J)[:,None] * (w * J)[None,:]\n",
        "        K = self._kernel_matrix()\n",
        "\n",
        "        G = g[:,None] * g[None,:]\n",
        "        xi_g_right = (xi[None,:] * g[None,:])\n",
        "        xi_g_xi_g = (xi[:,None] * g[:,None]) * (xi[None,:] * g[None,:])\n",
        "\n",
        "        L1 = np.sum(W * K * G)\n",
        "        L2 = np.sum(W * K * (g[:,None] * xi_g_right))\n",
        "        L3 = np.sum(W * K * xi_g_xi_g)\n",
        "\n",
        "        return L1, L2, L3\n",
        "\n",
        "    def Sigma_mu(self, alpha, beta, a, b):\n",
        "        \"\"\"\n",
        "        Asymptotic covariance of (μ̂1, μ̂2) for ETELN\n",
        "        Note: PLUS signs in off-diagonal (different from ETELL)\n",
        "        \"\"\"\n",
        "        with np.errstate(all='ignore'):\n",
        "            delta = ((np.exp(beta * np.log(2.0)) - 1.0) / (alpha * beta)) ** 2\n",
        "\n",
        "        L1, L2, L3 = self._lambda_triplet(alpha, beta, a, b)\n",
        "        logt = np.log(self.theta)\n",
        "\n",
        "        # PLUS signs (not minus!)\n",
        "        S11 = delta * L1\n",
        "        S12 = delta * (2*logt*L1 + 2/alpha * L2)\n",
        "        S22 = delta * (4*(logt**2)*L1 + 8*logt/alpha * L2 + 4/(alpha**2)*L3)\n",
        "\n",
        "        S = np.array([[S11, S12], [S12, S22]])\n",
        "        return 0.5 * (S + S.T)\n",
        "\n",
        "    # ----------------------------- solving beta and alpha from sample L-moments -----------------------------\n",
        "    def solve_beta(self, mu1, mu2, a, b):\n",
        "        \"\"\"\n",
        "        Solve for β via d_{h,1}/sqrt(tau) = (μ1 - log θ)/sqrt(Δ)\n",
        "        Note: DIFFERENT SIGN from ETELL! (μ1 - log θ) not (log θ - μ1)\n",
        "        \"\"\"\n",
        "        Delta = mu2 - mu1**2\n",
        "        if Delta <= 1e-12:\n",
        "            return self.beta_true\n",
        "\n",
        "        # For ETELN: (μ1 - log θ) [POSITIVE]\n",
        "        target = (mu1 - np.log(self.theta)) / np.sqrt(Delta)\n",
        "\n",
        "        def R(beta):\n",
        "            # Protect against beta = 0\n",
        "            beta_safe = beta if abs(beta) > 1e-8 else np.sign(beta) * 1e-8\n",
        "\n",
        "            d1 = self.compute_dk(beta_safe, 1, a, b)\n",
        "            t = self.tau(beta_safe, a, b)\n",
        "            if not np.isfinite(d1) or t <= 0:\n",
        "                return np.nan\n",
        "            return d1/np.sqrt(t) - target\n",
        "\n",
        "        grid = np.linspace(-3.5, 3.5, 71)\n",
        "        vals = np.array([R(bi) for bi in grid])\n",
        "        sgn = np.sign(vals)\n",
        "\n",
        "        for i in range(len(grid)-1):\n",
        "            if np.isfinite(vals[i]) and np.isfinite(vals[i+1]) and sgn[i]*sgn[i+1] < 0:\n",
        "                try:\n",
        "                    return brentq(lambda b: R(b), grid[i], grid[i+1], xtol=1e-7, maxiter=100)\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "        out = minimize_scalar(lambda b: (R(b) if np.isfinite(R(b)) else 1e6)**2,\n",
        "                              bounds=(-4,4), method='bounded')\n",
        "        return out.x if out.success else self.beta_true\n",
        "\n",
        "    # ----------------------------- L-estimator on a sample -----------------------------\n",
        "    def kumaraswamy_l_estimator(self, x, a, b):\n",
        "        \"\"\"L-estimator with J(u;a,b) weights for ETELN\"\"\"\n",
        "        x = np.asarray(x)\n",
        "        x = x[x >= self.theta]\n",
        "        n = x.size\n",
        "        if n < 3:\n",
        "            return np.nan, np.nan\n",
        "\n",
        "        xs = np.sort(x)\n",
        "        i = np.arange(1, n+1)\n",
        "        uo = i/(n+1.0)\n",
        "        J = self.kumaraswamy_weight(uo, a, b)\n",
        "\n",
        "        lx = np.log(xs)\n",
        "        mu1 = np.mean(J * lx)\n",
        "        mu2 = np.mean(J * (lx**2))\n",
        "\n",
        "        Delta = mu2 - mu1**2\n",
        "        if Delta <= 0:\n",
        "            return np.nan, np.nan\n",
        "\n",
        "        beta_hat = self.solve_beta(mu1, mu2, a, b)\n",
        "        t_beta = self.tau(beta_hat, a, b)\n",
        "\n",
        "        if not np.isfinite(t_beta) or t_beta <= 0:\n",
        "            return np.nan, np.nan\n",
        "\n",
        "        alpha_hat = np.sqrt(t_beta / Delta)\n",
        "        return alpha_hat, beta_hat\n",
        "\n",
        "    # ----------------------------- MLE -----------------------------\n",
        "    def mle_eteln(self, x):\n",
        "        \"\"\"\n",
        "        MLE for ETELN (θ known): maximize ll(α,β)\n",
        "        \"\"\"\n",
        "        xv = np.asarray(x)\n",
        "        xv = xv[xv >= self.theta]\n",
        "        n = xv.size\n",
        "        if n < 5:\n",
        "            return np.nan, np.nan\n",
        "\n",
        "        def nll(params):\n",
        "            alpha, beta = params\n",
        "            if alpha <= 0 or np.abs(beta) > 5:\n",
        "                return 1e10\n",
        "            try:\n",
        "                with np.errstate(all='ignore'):\n",
        "                    if abs(beta) < 1e-8:\n",
        "                        const = -np.log(np.log(2.0))\n",
        "                    else:\n",
        "                        two_b = np.exp(beta * np.log(2.0))\n",
        "                        const = np.log(np.abs(beta)) - np.log(np.abs(two_b - 1.0))\n",
        "\n",
        "                    # ETELN log-likelihood\n",
        "                    zi = alpha * np.log(xv / self.theta)\n",
        "                    phi_zi = norm.pdf(zi)\n",
        "                    Phi_zi = norm.cdf(zi)\n",
        "\n",
        "                    # Avoid log(0)\n",
        "                    Phi_zi = np.maximum(Phi_zi, 1e-300)\n",
        "                    phi_zi = np.maximum(phi_zi, 1e-300)\n",
        "\n",
        "                    ll = (n * np.log(alpha) + n * const\n",
        "                          - n * 0.5 * np.log(2*np.pi)\n",
        "                          - np.sum(np.log(xv))\n",
        "                          - 0.5 * alpha**2 * np.sum((np.log(xv/self.theta))**2)\n",
        "                          - (beta + 1) * np.sum(np.log(Phi_zi)))\n",
        "\n",
        "                    return -ll if np.isfinite(ll) else 1e10\n",
        "            except Exception:\n",
        "                return 1e10\n",
        "\n",
        "        # Initial guess\n",
        "        lx = np.log(xv)\n",
        "        m1 = lx.mean()\n",
        "        m2 = (lx**2).mean()\n",
        "        alpha0 = 1.0 / np.sqrt(max(m2 - m1**2, 1e-4))\n",
        "        beta0 = np.clip(self.beta_true, -3.0, 3.0)\n",
        "\n",
        "        try:\n",
        "            res = minimize(nll, x0=[alpha0, beta0],\n",
        "                          bounds=[(0.05, 10.0), (-3.0, 3.0)],\n",
        "                          method=\"L-BFGS-B\")\n",
        "            if res.success and res.fun < 1e9:\n",
        "                return res.x[0], res.x[1]\n",
        "\n",
        "            # Fallback\n",
        "            res = minimize(nll, x0=[self.alpha_true, self.beta_true],\n",
        "                          bounds=[(0.05, 10.0), (-3.0, 3.0)],\n",
        "                          method=\"L-BFGS-B\")\n",
        "            return (res.x[0], res.x[1]) if res.success else (np.nan, np.nan)\n",
        "        except Exception:\n",
        "            return np.nan, np.nan\n",
        "\n",
        "    # ----------------------------- Fisher information -----------------------------\n",
        "    def fisher_information(self, alpha, beta, n):\n",
        "        \"\"\"\n",
        "        Fisher Information for ETELN using numerical integration\n",
        "        \"\"\"\n",
        "        try:\n",
        "            u_int = np.linspace(1e-6, 1 - 1e-6, 35)\n",
        "\n",
        "            with np.errstate(all='ignore'):\n",
        "                two_b = np.exp(beta * np.log(2.0))\n",
        "                u0 = (two_b - (two_b - 1.0) * u_int) ** (-1/beta)\n",
        "                u0 = np.clip(u0, 1e-9, 1 - 1e-9)\n",
        "\n",
        "                xi = norm.ppf(u0)\n",
        "                phi_xi = norm.pdf(xi)\n",
        "                Phi_xi = norm.cdf(xi)\n",
        "\n",
        "                ratio = np.where(Phi_xi > 1e-300, phi_xi / Phi_xi, 0.0)\n",
        "                ratio2 = np.where(Phi_xi > 1e-300, (phi_xi / Phi_xi) ** 2, 0.0)\n",
        "\n",
        "                moment2 = np.trapz(xi**2, u_int) / alpha**2\n",
        "                moment_ratio1 = np.trapz(ratio * xi, u_int) / alpha\n",
        "                moment_ratio3 = np.trapz(xi**3 * ratio, u_int) / alpha**2\n",
        "                moment_ratio2_sq = np.trapz(xi**2 * ratio2, u_int) / alpha**2\n",
        "\n",
        "                denom = two_b - 1.0\n",
        "                ln2 = np.log(2.0)\n",
        "\n",
        "                Ibb = (1/beta**2) * (1 - (two_b * beta**2 * (ln2**2)) / (denom**2))\n",
        "                Iaa = (1/alpha**2) * (1 + moment2 + (beta + 1)**2 * moment_ratio2_sq +\n",
        "                                       2 * alpha * (beta + 1) * moment_ratio3)\n",
        "                Iab = moment_ratio1\n",
        "\n",
        "                I = n * np.array([[Iaa, Iab], [Iab, Ibb]])\n",
        "                return I\n",
        "        except:\n",
        "            return None\n",
        "\n",
        "    # ----------------------------- ARE computation -----------------------------\n",
        "    def _population_mu(self, alpha, beta, a, b):\n",
        "        \"\"\"Compute population μ1, μ2 for given (α,β) and Kumaraswamy (a,b)\"\"\"\n",
        "        u, w = self.u, self.w\n",
        "\n",
        "        with np.errstate(all='ignore'):\n",
        "            two_b = np.exp(beta * np.log(2.0))\n",
        "            base = two_b - (two_b - 1.0) * u\n",
        "            u0 = base ** (-1/beta)\n",
        "            u0 = np.clip(u0, 1e-9, 1 - 1e-9)\n",
        "            xi = norm.ppf(u0)\n",
        "\n",
        "            q = self.theta * np.exp((1.0/alpha) * xi)\n",
        "            J = self.kumaraswamy_weight(u, a, b)\n",
        "\n",
        "            mu1 = np.sum(w * J * np.log(q))\n",
        "            mu2 = np.sum(w * J * (np.log(q)**2))\n",
        "\n",
        "        return mu1, mu2\n",
        "\n",
        "    def _jacobian_D(self, mu1, mu2, a, b, alpha_hat, beta_hat):\n",
        "        \"\"\"Numeric Jacobian D = ∂(α,β)/∂(μ1,μ2)\"\"\"\n",
        "        eps1 = 1e-6 * max(1.0, abs(mu1))\n",
        "        eps2 = 1e-6 * max(1.0, abs(mu2))\n",
        "\n",
        "        def solve_pair(m1, m2):\n",
        "            try:\n",
        "                b = self.solve_beta(m1, m2, a, b)\n",
        "                t = self.tau(b, a, b)\n",
        "                a_hat = np.sqrt(t / max(m2 - m1**2, 1e-12))\n",
        "                return a_hat, b\n",
        "            except Exception:\n",
        "                return alpha_hat, beta_hat\n",
        "\n",
        "        a_p, b_p = solve_pair(mu1 + eps1, mu2)\n",
        "        a_m, b_m = solve_pair(mu1 - eps1, mu2)\n",
        "        d11 = (a_p - a_m) / (2*eps1)\n",
        "        d21 = (b_p - b_m) / (2*eps1)\n",
        "\n",
        "        a_p, b_p = solve_pair(mu1, mu2 + eps2)\n",
        "        a_m, b_m = solve_pair(mu1, mu2 - eps2)\n",
        "        d12 = (a_p - a_m) / (2*eps2)\n",
        "        d22 = (b_p - b_m) / (2*eps2)\n",
        "\n",
        "        D = np.array([[d11, d12], [d21, d22]])\n",
        "        return D\n",
        "\n",
        "    def compute_theoretical_are(self, a, b):\n",
        "        \"\"\"Use ETELNARE class to compute theoretical ARE\"\"\"\n",
        "\n",
        "        solver = ETELNARE(theta=self.theta, kuma_a=a, kuma_b=b, n_quad=200)\n",
        "        mu1, mu2 = self._population_mu(self.alpha_true, self.beta_true, a, b)\n",
        "        return solver.compute_ARE(mu1, mu2, n=5000)\n",
        "\n",
        "    # ----------------------------- simulation with RE -----------------------------\n",
        "    def run_simulation_with_re_se(self, sample_sizes, kuma_params,\n",
        "                                  n_batches=10, sims_per_batch=100, verbose=True, ref_at=\"true\"):\n",
        "        \"\"\"\n",
        "        Run simulation study with RE computation\n",
        "        [Same structure as ETELL version]\n",
        "        \"\"\"\n",
        "        all_results = {}\n",
        "        for n in sample_sizes:\n",
        "            if verbose:\n",
        "                print(f\"\\nRunning n={n} with {n_batches} batches...\")\n",
        "\n",
        "            # Precompute ARE∞ for each (a,b)\n",
        "            are_inf = {(a,b): self.compute_theoretical_are(a, b) for (a,b) in kuma_params}\n",
        "\n",
        "            batch_stats = []\n",
        "            for bidx in range(n_batches):\n",
        "                if verbose and bidx % 2 == 0:\n",
        "                    print(f\"  Batch {bidx+1}/{n_batches}\")\n",
        "\n",
        "                est = {\"MLE\": {\"alpha\": [], \"beta\": []}}\n",
        "                for a,b in kuma_params:\n",
        "                    est[f\"K({a},{b})\"] = {\"alpha\": [], \"beta\": []}\n",
        "\n",
        "                # Simulations in this batch\n",
        "                for _ in range(sims_per_batch):\n",
        "                    x = self.generate_eteln_sample(n)\n",
        "                    a_mle, b_mle = self.mle_eteln(x)\n",
        "                    if np.isfinite(a_mle) and np.isfinite(b_mle):\n",
        "                        est[\"MLE\"][\"alpha\"].append(a_mle)\n",
        "                        est[\"MLE\"][\"beta\"].append(b_mle)\n",
        "                    for a,b in kuma_params:\n",
        "                        ak, bk = self.kumaraswamy_l_estimator(x, a, b)\n",
        "                        if np.isfinite(ak) and np.isfinite(bk):\n",
        "                            est[f\"K({a},{b})\"][\"alpha\"].append(ak)\n",
        "                            est[f\"K({a},{b})\"][\"beta\"].append(bk)\n",
        "\n",
        "                # Per-batch stats\n",
        "                batch = {}\n",
        "\n",
        "                def _winsorize_pair(a_vals, b_vals, p=0.01):\n",
        "                    ax = np.asarray(a_vals, float)\n",
        "                    bx = np.asarray(b_vals, float)\n",
        "                    if ax.size < 3:\n",
        "                        return ax, bx\n",
        "                    lo = int(np.floor(p*ax.size))\n",
        "                    hi = int(np.ceil((1-p)*ax.size))\n",
        "                    axs = np.sort(ax)\n",
        "                    bxs = np.sort(bx)\n",
        "                    a_lo, a_hi = axs[lo], axs[min(hi, ax.size-1)]\n",
        "                    b_lo, b_hi = bxs[lo], bxs[min(hi, bx.size-1)]\n",
        "                    ax_cl = np.clip(ax, a_lo, a_hi)\n",
        "                    bx_cl = np.clip(bx, b_lo, b_hi)\n",
        "                    return ax_cl, bx_cl\n",
        "\n",
        "                def det_re(a_list, b_list, S_asymp_mle_ref):\n",
        "                    vals = np.c_[a_list, b_list]\n",
        "                    if vals.shape[0] < 3:\n",
        "                        return np.nan\n",
        "                    a_vals, b_vals = _winsorize_pair(vals[:,0], vals[:,1])\n",
        "                    S = np.cov(np.c_[a_vals, b_vals], rowvar=False, ddof=1)\n",
        "                    S = 0.5*(S + S.T) + 1e-9*np.eye(2)\n",
        "                    den = np.linalg.det(S)\n",
        "                    num = np.linalg.det(S_asymp_mle_ref)\n",
        "                    return np.sqrt(num/den) if den > 0 else np.nan\n",
        "\n",
        "                # MLE row\n",
        "                if len(est[\"MLE\"][\"alpha\"]) > 0:\n",
        "                    avals = np.array(est[\"MLE\"][\"alpha\"])\n",
        "                    bvals = np.array(est[\"MLE\"][\"beta\"])\n",
        "\n",
        "                    if ref_at == \"batch\":\n",
        "                        alpha_ref = float(np.mean(avals))\n",
        "                        beta_ref = float(np.mean(bvals))\n",
        "                    else:\n",
        "                        alpha_ref = self.alpha_true\n",
        "                        beta_ref = self.beta_true\n",
        "\n",
        "                    I_ref = self.fisher_information(alpha_ref, beta_ref, n)\n",
        "                    if I_ref is None:\n",
        "                        continue\n",
        "                    S_asympt_mle_ref = np.linalg.inv(I_ref)\n",
        "\n",
        "                    batch[\"MLE\"] = {\n",
        "                        \"alpha_mean\": np.mean(avals) / self.alpha_true,\n",
        "                        \"alpha_se\": np.std(avals, ddof=1) / (self.alpha_true * np.sqrt(len(avals))),\n",
        "                        \"beta_mean\": np.mean(bvals) / self.beta_true,\n",
        "                        \"beta_se\": np.std(bvals, ddof=1) / (self.beta_true * np.sqrt(len(bvals))),\n",
        "                        \"re\": det_re(avals, bvals, S_asympt_mle_ref),\n",
        "                        \"re_asymptotic\": 1.0\n",
        "                    }\n",
        "\n",
        "                    # K(a,b) rows\n",
        "                    for a,b in kuma_params:\n",
        "                        key = f\"K({a},{b})\"\n",
        "                        if len(est[key][\"alpha\"]) > 0:\n",
        "                            avals_k = np.array(est[key][\"alpha\"])\n",
        "                            bvals_k = np.array(est[key][\"beta\"])\n",
        "                            batch[key] = {\n",
        "                                \"alpha_mean\": np.mean(avals_k) / self.alpha_true,\n",
        "                                \"alpha_se\": np.std(avals_k, ddof=1) / (self.alpha_true * np.sqrt(len(avals_k))),\n",
        "                                \"beta_mean\": np.mean(bvals_k) / self.beta_true,\n",
        "                                \"beta_se\": np.std(bvals_k, ddof=1) / (self.beta_true * np.sqrt(len(bvals_k))),\n",
        "                                \"re\": det_re(avals_k, bvals_k, S_asympt_mle_ref),\n",
        "                                \"re_asymptotic\": are_inf[(a,b)]\n",
        "                            }\n",
        "\n",
        "                batch_stats.append(batch)\n",
        "\n",
        "            # Aggregate across batches\n",
        "            final = {}\n",
        "            keys = set().union(*[b.keys() for b in batch_stats])\n",
        "            for key in keys:\n",
        "                def collect(field):\n",
        "                    vals = [b[key][field] for b in batch_stats\n",
        "                           if key in b and field in b[key] and np.isfinite(b[key][field])]\n",
        "                    return np.array(vals)\n",
        "\n",
        "                a_mean = collect(\"alpha_mean\")\n",
        "                a_se = collect(\"alpha_se\")\n",
        "                b_mean = collect(\"beta_mean\")\n",
        "                b_se = collect(\"beta_se\")\n",
        "                re_vals = collect(\"re\")\n",
        "                re_inf = collect(\"re_asymptotic\")\n",
        "\n",
        "                if a_mean.size > 0:\n",
        "                    final[key] = {\n",
        "                        \"alpha_mean\": a_mean.mean(),\n",
        "                        \"alpha_se\": a_se.mean() if a_se.size>0 else np.nan,\n",
        "                        \"beta_mean\": b_mean.mean() if b_mean.size>0 else np.nan,\n",
        "                        \"beta_se\": b_se.mean() if b_se.size>0 else np.nan,\n",
        "                        \"re\": re_vals.mean() if re_vals.size>0 else np.nan,\n",
        "                        \"re_se\": re_vals.std(ddof=1)/np.sqrt(re_vals.size) if re_vals.size>1 else np.nan,\n",
        "                        \"re_asymptotic\": (1.0 if key==\"MLE\" else (re_inf.mean() if re_inf.size>0 else np.nan))\n",
        "                    }\n",
        "\n",
        "            all_results[n] = final\n",
        "\n",
        "            if verbose:\n",
        "                print(f\"  Total simulations (MLE): {n_batches * sims_per_batch}\")\n",
        "\n",
        "        return all_results\n",
        "\n",
        "    # ----------------------------- pretty printer -----------------------------\n",
        "    def print_results_table(self, results, sample_sizes, kuma_params):\n",
        "        print(\"\\n\" + \"=\"*120)\n",
        "        print(f\"Table: Standardized MEAN and RE from ETELN(α={self.alpha_true}, β={self.beta_true}, θ={self.theta})\")\n",
        "        print(\"Entries are mean values (standard errors)\")\n",
        "        print(\"=\"*120)\n",
        "\n",
        "        col_w, last_w = 14, 10\n",
        "        header = \"KS Par\".ljust(14)\n",
        "        for n in sample_sizes:\n",
        "            header += f\"{f'n={n}':^{col_w*2}}\"\n",
        "        header += f\"{'n→∞':^{last_w*2}}\"\n",
        "        print(header)\n",
        "\n",
        "        sub = \"(a,b)\".ljust(14)\n",
        "        for _ in sample_sizes:\n",
        "            sub += f\"{'α̂/α':>{col_w}}{'β̂/β':>{col_w}}\"\n",
        "        sub += f\"{'α̂/α':>{last_w}}{'β̂/β':>{last_w}}\"\n",
        "        print(sub)\n",
        "\n",
        "        # Means\n",
        "        print(\"\\nMEAN VALUES:\")\n",
        "        def row_for(key, label=None):\n",
        "            lab = (label or key).ljust(14)\n",
        "            out = lab\n",
        "            for n in sample_sizes:\n",
        "                if n in results and key in results[n]:\n",
        "                    s = results[n][key]\n",
        "                    out += f\"{s['alpha_mean']:5.2f}({s['alpha_se']:.3f})\".rjust(col_w)\n",
        "                    out += f\"{s['beta_mean']:5.2f}({s['beta_se']:.3f})\".rjust(col_w)\n",
        "                else:\n",
        "                    out += f\"{'---':>{col_w*2}}\"\n",
        "            out += f\"{'1.00':>{last_w}}{'1.00':>{last_w}}\"\n",
        "            print(out)\n",
        "\n",
        "        row_for(\"MLE\", \"MLE\")\n",
        "        for a,b in kuma_params:\n",
        "            row_for(f\"K({a},{b})\", f\"J({a},{b})\")\n",
        "\n",
        "        # RE\n",
        "        print(\"\\n\" + \"-\"*120)\n",
        "        print(\"RELATIVE EFFICIENCY:\")\n",
        "        def re_row(key, label=None):\n",
        "            lab = (label or key).ljust(14)\n",
        "            out = lab\n",
        "            for n in sample_sizes:\n",
        "                if n in results and key in results[n]:\n",
        "                    s = results[n][key]\n",
        "                    re = s.get(\"re\", np.nan)\n",
        "                    se = s.get(\"re_se\", np.nan)\n",
        "                    out += f\"{re:5.3f}({se:.3f})\".rjust(col_w)\n",
        "                else:\n",
        "                    out += f\"{'---':>{col_w}}\"\n",
        "            # Asymptotic\n",
        "            n0 = sample_sizes[0]\n",
        "            if n0 in results and key in results[n0]:\n",
        "                out += f\"{results[n0][key]['re_asymptotic']:5.3f}\".rjust(last_w)\n",
        "            else:\n",
        "                out += f\"{'---':>{last_w}}\"\n",
        "            print(out)\n",
        "\n",
        "        re_row(\"MLE\", \"MLE\")\n",
        "        for a,b in kuma_params:\n",
        "            re_row(f\"K({a},{b})\", f\"J({a},{b})\")\n",
        "\n",
        "\n",
        "# ----------------------------- example runner -----------------------------\n",
        "def run_eteln_simulation_study():\n",
        "    alpha_true, beta_true, theta_true = 2.0, 0.5, 1.0\n",
        "    sample_sizes = [100, 250, 500, 1000]\n",
        "    kuma_params = [\n",
        "        (1.0, 1.0),\n",
        "        (0.3, 1.0),\n",
        "        (1.2, 1.3),\n",
        "        (0.8, 1.0),\n",
        "        (4.0, 12.0),\n",
        "        (2.0, 1.0),\n",
        "        (5.0, 5.0),\n",
        "    ]\n",
        "\n",
        "    print(\"ETELN Simulation Study\")\n",
        "    print(f\"True params: α={alpha_true}, β={beta_true}, θ={theta_true}\")\n",
        "\n",
        "    sim = ETELNSimulation(theta=theta_true, alpha=alpha_true, beta=beta_true,\n",
        "                          n_quad=600, use_det_re=True, use_numeric_info=False, rng=123)\n",
        "\n",
        "    results = sim.run_simulation_with_re_se(\n",
        "        sample_sizes=sample_sizes,\n",
        "        kuma_params=kuma_params,\n",
        "        n_batches=50,\n",
        "        sims_per_batch=200,\n",
        "        verbose=True,\n",
        "        ref_at=\"true\",\n",
        "    )\n",
        "\n",
        "    sim.print_results_table(results, sample_sizes, kuma_params)\n",
        "    return results\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
        "    t0 = time.perf_counter()\n",
        "    _ = run_eteln_simulation_study()\n",
        "    print(f\"\\n⏱️ Total runtime: {time.perf_counter() - t0:.2f} s\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GkMe55NNv7BG",
        "outputId": "2b82327f-10c5-4ff2-f39f-c70d91376869"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ETELN Simulation Study\n",
            "True params: α=2.0, β=0.5, θ=1.0\n",
            "\n",
            "Running n=100 with 50 batches...\n",
            "  Batch 1/50\n",
            "  Batch 3/50\n",
            "  Batch 5/50\n",
            "  Batch 7/50\n",
            "  Batch 9/50\n",
            "  Batch 11/50\n",
            "  Batch 13/50\n",
            "  Batch 15/50\n",
            "  Batch 17/50\n",
            "  Batch 19/50\n",
            "  Batch 21/50\n",
            "  Batch 23/50\n",
            "  Batch 25/50\n",
            "  Batch 27/50\n",
            "  Batch 29/50\n",
            "  Batch 31/50\n",
            "  Batch 33/50\n",
            "  Batch 35/50\n",
            "  Batch 37/50\n",
            "  Batch 39/50\n",
            "  Batch 41/50\n",
            "  Batch 43/50\n",
            "  Batch 45/50\n",
            "  Batch 47/50\n",
            "  Batch 49/50\n",
            "  Total simulations (MLE): 10000\n",
            "\n",
            "Running n=250 with 50 batches...\n",
            "  Batch 1/50\n",
            "  Batch 3/50\n",
            "  Batch 5/50\n",
            "  Batch 7/50\n",
            "  Batch 9/50\n",
            "  Batch 11/50\n",
            "  Batch 13/50\n",
            "  Batch 15/50\n",
            "  Batch 17/50\n",
            "  Batch 19/50\n",
            "  Batch 21/50\n",
            "  Batch 23/50\n",
            "  Batch 25/50\n",
            "  Batch 27/50\n",
            "  Batch 29/50\n",
            "  Batch 31/50\n",
            "  Batch 33/50\n",
            "  Batch 35/50\n",
            "  Batch 37/50\n",
            "  Batch 39/50\n",
            "  Batch 41/50\n",
            "  Batch 43/50\n",
            "  Batch 45/50\n",
            "  Batch 47/50\n",
            "  Batch 49/50\n",
            "  Total simulations (MLE): 10000\n",
            "\n",
            "Running n=500 with 50 batches...\n",
            "  Batch 1/50\n",
            "  Batch 3/50\n",
            "  Batch 5/50\n",
            "  Batch 7/50\n",
            "  Batch 9/50\n",
            "  Batch 11/50\n",
            "  Batch 13/50\n",
            "  Batch 15/50\n",
            "  Batch 17/50\n",
            "  Batch 19/50\n",
            "  Batch 21/50\n",
            "  Batch 23/50\n",
            "  Batch 25/50\n",
            "  Batch 27/50\n",
            "  Batch 29/50\n",
            "  Batch 31/50\n",
            "  Batch 33/50\n",
            "  Batch 35/50\n",
            "  Batch 37/50\n",
            "  Batch 39/50\n",
            "  Batch 41/50\n",
            "  Batch 43/50\n",
            "  Batch 45/50\n",
            "  Batch 47/50\n",
            "  Batch 49/50\n",
            "  Total simulations (MLE): 10000\n",
            "\n",
            "Running n=1000 with 50 batches...\n",
            "  Batch 1/50\n",
            "  Batch 3/50\n",
            "  Batch 5/50\n",
            "  Batch 7/50\n",
            "  Batch 9/50\n",
            "  Batch 11/50\n",
            "  Batch 13/50\n",
            "  Batch 15/50\n",
            "  Batch 17/50\n",
            "  Batch 19/50\n",
            "  Batch 21/50\n",
            "  Batch 23/50\n",
            "  Batch 25/50\n",
            "  Batch 27/50\n",
            "  Batch 29/50\n",
            "  Batch 31/50\n",
            "  Batch 33/50\n",
            "  Batch 35/50\n",
            "  Batch 37/50\n",
            "  Batch 39/50\n",
            "  Batch 41/50\n",
            "  Batch 43/50\n",
            "  Batch 45/50\n",
            "  Batch 47/50\n",
            "  Batch 49/50\n",
            "  Total simulations (MLE): 10000\n",
            "\n",
            "========================================================================================================================\n",
            "Table: Standardized MEAN and RE from ETELN(α=2.0, β=0.5, θ=1.0)\n",
            "Entries are mean values (standard errors)\n",
            "========================================================================================================================\n",
            "KS Par                   n=100                       n=250                       n=500                       n=1000                   n→∞         \n",
            "(a,b)                   α̂/α          β̂/β          α̂/α          β̂/β          α̂/α          β̂/β          α̂/α          β̂/β      α̂/α      β̂/β\n",
            "\n",
            "MEAN VALUES:\n",
            "MLE              1.02(0.010)   0.83(0.120)   1.01(0.006)   0.95(0.076)   1.00(0.004)   0.97(0.053)   1.00(0.003)   0.98(0.038)      1.00      1.00\n",
            "J(1.0,1.0)       1.03(0.010)   0.81(0.122)   1.01(0.006)   0.93(0.076)   1.00(0.004)   0.97(0.053)   1.00(0.003)   0.98(0.038)      1.00      1.00\n",
            "J(0.3,1.0)       1.02(0.010)   0.90(0.127)   1.01(0.007)   0.98(0.080)   1.00(0.005)   0.99(0.056)   1.00(0.003)   0.99(0.040)      1.00      1.00\n",
            "J(1.2,1.3)       0.99(0.011)   1.03(0.128)   0.99(0.007)   1.06(0.079)   1.00(0.005)   1.04(0.055)   1.00(0.003)   1.02(0.039)      1.00      1.00\n",
            "J(0.8,1.0)       1.02(0.010)   0.82(0.121)   1.01(0.006)   0.94(0.076)   1.00(0.004)   0.97(0.053)   1.00(0.003)   0.98(0.038)      1.00      1.00\n",
            "J(4.0,12.0)      1.05(0.025)   0.86(0.256)   1.00(0.017)   1.15(0.177)   1.00(0.012)   1.08(0.120)   1.00(0.008)   1.04(0.078)      1.00      1.00\n",
            "J(2.0,1.0)       1.03(0.011)   0.82(0.130)   1.01(0.007)   0.93(0.081)   1.01(0.005)   0.97(0.057)   1.00(0.003)   0.97(0.041)      1.00      1.00\n",
            "J(5.0,5.0)       1.03(0.016)   0.58(0.189)   1.01(0.010)   0.85(0.111)   1.01(0.007)   0.92(0.075)   1.00(0.005)   0.96(0.052)      1.00      1.00\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "RELATIVE EFFICIENCY:\n",
            "MLE             0.954(0.011)  0.976(0.010)  1.003(0.011)  1.002(0.010)     1.000\n",
            "J(1.0,1.0)      0.946(0.011)  0.972(0.010)  0.998(0.010)  0.996(0.010)     0.997\n",
            "J(0.3,1.0)      0.910(0.009)  0.925(0.010)  0.951(0.010)  0.951(0.009)     0.949\n",
            "J(1.2,1.3)      0.912(0.009)  0.938(0.010)  0.967(0.010)  0.964(0.010)     0.965\n",
            "J(0.8,1.0)      0.950(0.010)  0.973(0.011)  1.000(0.010)  0.999(0.010)     0.999\n",
            "J(4.0,12.0)     0.300(0.004)  0.288(0.004)  0.307(0.005)  0.350(0.005)     0.391\n",
            "J(2.0,1.0)      0.880(0.010)  0.907(0.009)  0.929(0.009)  0.921(0.009)     0.927\n",
            "J(5.0,5.0)      0.519(0.006)  0.578(0.008)  0.620(0.006)  0.626(0.006)     0.641\n",
            "\n",
            "⏱️ Total runtime: 33470.09 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ==============================================================\n",
        "# ETELN Simulation Different J\n",
        "# ==============================================================\n"
      ],
      "metadata": {
        "id": "YMfFmovrwU9f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================\n",
        "# ETELN Simulation - DESIGN B (Different J, Same h)\n",
        "# ==============================================================\n",
        "\n",
        "class ETELNSimulation_DesignB:\n",
        "    \"\"\"\n",
        "    Design B for ETELN with enhanced robustness:\n",
        "      - Different J weights (J₁ ≠ J₂)\n",
        "      - Same h = log(x)\n",
        "      - Adaptive sign handling for Δ_w\n",
        "      - Multiple solving strategies\n",
        "      - Φ⁻¹ transformations with 1/φ(ξ) terms\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, theta=1.0, alpha=2.0, beta=0.5, n_quad=250,\n",
        "                 use_det_re=True, use_numeric_info=False, rng=None):\n",
        "        self.theta = float(theta)\n",
        "        self.alpha_true = float(alpha)\n",
        "        self.beta_true = float(beta)\n",
        "        self.use_det_re = bool(use_det_re)\n",
        "        self.use_numeric_info = bool(use_numeric_info)\n",
        "\n",
        "        self.nodes, self.weights = leggauss(n_quad)\n",
        "        self.u = 0.5 * (self.nodes + 1.0)\n",
        "        self.w = 0.5 * self.weights\n",
        "        self._K = None\n",
        "        self.rng = np.random.default_rng(rng)\n",
        "\n",
        "    @staticmethod\n",
        "    def kumaraswamy_weight(u, a, b):\n",
        "        \"\"\"Kumaraswamy pdf with numerical stability\"\"\"\n",
        "        with np.errstate(all='ignore'):\n",
        "            if a > 20 or b > 20:\n",
        "                result = a * b * np.exp((a-1)*np.log(u) + (b-1)*np.log(1 - u**a))\n",
        "            else:\n",
        "                result = a * b * (u ** (a - 1.0)) * ((1.0 - u**a) ** (b - 1.0))\n",
        "            return np.nan_to_num(result, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "\n",
        "    def _stable_terms_eteln(self, beta, u):\n",
        "        \"\"\"\n",
        "        Stable computation for ETELN:\n",
        "        Returns u0, xi, phi_xi, g\n",
        "        \"\"\"\n",
        "        with np.errstate(all='ignore'):\n",
        "            two_pow_beta = np.exp(beta * np.log(2.0))\n",
        "            base = two_pow_beta - (two_pow_beta - 1.0) * u\n",
        "            base = np.maximum(base, 1e-15)\n",
        "\n",
        "            if abs(beta) < 1e-8:\n",
        "                u0 = np.exp(-(1.0 - u) * np.log(2.0))\n",
        "                exponent = -1.0\n",
        "            else:\n",
        "                u0 = base ** (-1.0/beta)\n",
        "                exponent = -(1.0 + beta) / beta\n",
        "\n",
        "            u0 = np.clip(u0, 1e-9, 1 - 1e-9)\n",
        "\n",
        "            xi = norm.ppf(u0)\n",
        "            xi = np.where(np.isfinite(xi), xi, 0.0)\n",
        "\n",
        "            phi_xi = norm.pdf(xi)\n",
        "            phi_xi = np.maximum(phi_xi, 1e-300)\n",
        "\n",
        "            g = np.zeros_like(u)\n",
        "            valid = (base > 0) & (phi_xi > 1e-300)\n",
        "            g[valid] = (base[valid] ** exponent) / phi_xi[valid]\n",
        "            g = np.where(np.isfinite(g), g, 0.0)\n",
        "\n",
        "        return u0, xi, phi_xi, g\n",
        "\n",
        "    def _kernel_matrix(self):\n",
        "        if self._K is None:\n",
        "            u = self.u\n",
        "            self._K = np.minimum(u[:, None], u[None, :]) - (u[:, None] * u[None, :])\n",
        "        return self._K\n",
        "\n",
        "    def generate_eteln_sample(self, n):\n",
        "        \"\"\"Inverse-transform sampling for ETELN\"\"\"\n",
        "        u = self.rng.uniform(0.0, 1.0, int(n))\n",
        "\n",
        "        with np.errstate(all='ignore'):\n",
        "            if abs(self.beta_true) < 1e-8:\n",
        "                u0 = 2.0 ** (-(1.0 - u))\n",
        "            else:\n",
        "                two_pow_beta = np.exp(self.beta_true * np.log(2.0))\n",
        "                base = two_pow_beta - (two_pow_beta - 1.0) * u\n",
        "                u0 = base ** (-1/self.beta_true)\n",
        "\n",
        "            u0 = np.clip(u0, 1e-9, 1 - 1e-9)\n",
        "            xi = norm.ppf(u0)\n",
        "            x = self.theta * np.exp((1.0/self.alpha_true) * xi)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def compute_dw_k(self, beta, k, a, b):\n",
        "        \"\"\"\n",
        "        d_{w,k}(β) = ∫_0^1 J(u;a,b) [Φ⁻¹[(2^β-(2^β-1)u)^(-1/β)]]^k du\n",
        "        \"\"\"\n",
        "        u, w = self.u, self.w\n",
        "        J = self.kumaraswamy_weight(u, a, b)\n",
        "\n",
        "        if abs(beta) < 1e-8:\n",
        "            u0 = np.exp(-(1.0 - u) * np.log(2.0))\n",
        "            u0 = np.clip(u0, 1e-9, 1 - 1e-9)\n",
        "            xi = norm.ppf(u0)\n",
        "        else:\n",
        "            u0, xi, _, _ = self._stable_terms_eteln(beta, u)\n",
        "\n",
        "        xi = np.where(np.isfinite(xi), xi, 0.0)\n",
        "        integrand = J * xi\n",
        "        result = np.sum(w * integrand)\n",
        "\n",
        "        return result if np.isfinite(result) else np.nan\n",
        "\n",
        "    def tau_w(self, beta, a1, b1, a2, b2):\n",
        "        \"\"\"\n",
        "        τ_w(β) = d_{w,2}(β) - d_{w,1}(β)\n",
        "        Note: d_{w,1} uses J₁, d_{w,2} uses J₂\n",
        "        \"\"\"\n",
        "        d1 = self.compute_dw_k(beta, 1, a1, b1)\n",
        "        d2 = self.compute_dw_k(beta, 2, a2, b2)\n",
        "\n",
        "        if not (np.isfinite(d1) and np.isfinite(d2)):\n",
        "            return np.nan\n",
        "\n",
        "        return d2 - d1\n",
        "\n",
        "    def solve_beta_designB_robust(self, mu1, mu2, a1, b1, a2, b2, verbose=False):\n",
        "        \"\"\"\n",
        "        Ultra-robust β solver for ETELN Design B\n",
        "        Ψ(β) = d_{w,1}(β)/τ_w(β) - (μ₁ - log θ)/Δ_w = 0\n",
        "        Note: POSITIVE ratio for ETELN! (different from ETELL)\n",
        "        \"\"\"\n",
        "        Delta_w = mu2 - mu1\n",
        "\n",
        "        if abs(Delta_w) < 1e-12:\n",
        "            if verbose:\n",
        "                print(f\"    Δ_w too small: {Delta_w:.2e}\")\n",
        "            return np.nan, False\n",
        "\n",
        "        def Psi(beta, swap=False):\n",
        "            \"\"\"\n",
        "            For ETELN: Ψ(β) = d_{w,1}/τ_w - (μ₁ - log θ)/Δ_w\n",
        "            If swap=True, use d_{w,2} instead\n",
        "            \"\"\"\n",
        "            try:\n",
        "                if swap:\n",
        "                    d_num = self.compute_dw_k(beta, 2, a2, b2)\n",
        "                    tau = -self.tau_w(beta, a1, b1, a2, b2)\n",
        "                else:\n",
        "                    d_num = self.compute_dw_k(beta, 1, a1, b1)\n",
        "                    tau = self.tau_w(beta, a1, b1, a2, b2)\n",
        "\n",
        "                if not (np.isfinite(d_num) and np.isfinite(tau)):\n",
        "                    return np.nan\n",
        "\n",
        "                if abs(tau) < 1e-14:\n",
        "                    return 1e10 * np.sign(tau + 1e-15)\n",
        "\n",
        "                # ETELN: (μ₁ - log θ) not (log θ - μ₁)\n",
        "                result = (d_num / tau) - (mu1 - np.log(self.theta)) / Delta_w\n",
        "                return result if np.isfinite(result) else np.nan\n",
        "            except:\n",
        "                return np.nan\n",
        "\n",
        "        # Multiple solving strategies\n",
        "        strategies = [\n",
        "            (\"standard\", False, (-3.5, 3.5, 150)),\n",
        "            (\"standard\", False, (-4.5, 4.5, 200)),\n",
        "            (\"swapped\", True, (-3.5, 3.5, 150)),\n",
        "            (\"swapped\", True, (-4.5, 4.5, 200)),\n",
        "        ]\n",
        "\n",
        "        for strategy_name, swap, (beta_min, beta_max, n_grid) in strategies:\n",
        "            try:\n",
        "                grid = np.linspace(beta_min, beta_max, n_grid)\n",
        "                psi_vals = np.array([Psi(b, swap=swap) for b in grid])\n",
        "\n",
        "                valid = np.isfinite(psi_vals)\n",
        "                if np.sum(valid) < 3:\n",
        "                    continue\n",
        "\n",
        "                psi_valid = psi_vals[valid]\n",
        "                beta_valid = grid[valid]\n",
        "\n",
        "                signs = np.sign(psi_valid)\n",
        "                sign_changes = np.where(np.diff(signs) != 0)[0]\n",
        "\n",
        "                if len(sign_changes) == 0:\n",
        "                    continue\n",
        "\n",
        "                for idx in sign_changes:\n",
        "                    a, b = beta_valid[idx], beta_valid[idx + 1]\n",
        "\n",
        "                    fa, fb = Psi(a, swap=swap), Psi(b, swap=swap)\n",
        "                    if not (np.isfinite(fa) and np.isfinite(fb)):\n",
        "                        continue\n",
        "\n",
        "                    if fa * fb < 0:\n",
        "                        try:\n",
        "                            beta_hat = brentq(lambda bb: Psi(bb, swap=swap),\n",
        "                                            a, b, xtol=1e-10, rtol=1e-9, maxiter=500)\n",
        "\n",
        "                            tau = self.tau_w(beta_hat, a1, b1, a2, b2)\n",
        "                            if swap:\n",
        "                                tau = -tau\n",
        "\n",
        "                            # POSITIVE ratio for ETELN (not negative!)\n",
        "                            alpha_hat = tau / Delta_w\n",
        "\n",
        "                            if (alpha_hat > 0.01 and alpha_hat < 100 and\n",
        "                                np.isfinite(alpha_hat) and abs(beta_hat) < 10):\n",
        "\n",
        "                                if verbose and swap:\n",
        "                                    print(f\"    Success with {strategy_name} strategy\")\n",
        "\n",
        "                                return beta_hat, swap\n",
        "                        except:\n",
        "                            continue\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "        # Optimization fallback\n",
        "        for swap in [False, True]:\n",
        "            try:\n",
        "                def objective(beta):\n",
        "                    val = Psi(beta, swap=swap)\n",
        "                    return abs(val) if np.isfinite(val) else 1e10\n",
        "\n",
        "                result = minimize_scalar(objective, bounds=(-5, 5), method='bounded',\n",
        "                                       options={'maxiter': 500})\n",
        "\n",
        "                if result.success and result.fun < 0.01:\n",
        "                    beta_hat = result.x\n",
        "                    tau = self.tau_w(beta_hat, a1, b1, a2, b2)\n",
        "                    if swap:\n",
        "                        tau = -tau\n",
        "\n",
        "                    alpha_hat = tau / Delta_w\n",
        "\n",
        "                    if alpha_hat > 0.01 and np.isfinite(alpha_hat):\n",
        "                        if verbose and swap:\n",
        "                            print(f\"    Success with optimization {['standard','swapped'][swap]}\")\n",
        "                        return beta_hat, swap\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"    All strategies failed\")\n",
        "\n",
        "        return np.nan, False\n",
        "\n",
        "    def kumaraswamy_l_estimator_designB_robust(self, x, a1, b1, a2, b2, verbose=False):\n",
        "        \"\"\"L-estimator for ETELN Design B with robust solving\"\"\"\n",
        "        x = np.asarray(x)\n",
        "        x = x[x >= self.theta]\n",
        "        n = x.size\n",
        "        if n < 3:\n",
        "            return np.nan, np.nan\n",
        "\n",
        "        xs = np.sort(x)\n",
        "        i = np.arange(1, n + 1)\n",
        "        uo = i / (n + 1.0)\n",
        "\n",
        "        J1 = self.kumaraswamy_weight(uo, a1, b1)\n",
        "        J2 = self.kumaraswamy_weight(uo, a2, b2)\n",
        "\n",
        "        lx = np.log(xs)\n",
        "        mu1_orig = np.mean(J1 * lx)\n",
        "        mu2_orig = np.mean(J2 * lx)\n",
        "\n",
        "        Delta_w_orig = mu2_orig - mu1_orig\n",
        "\n",
        "        if abs(Delta_w_orig) < 1e-12:\n",
        "            if verbose:\n",
        "                print(f\"  J₁({a1},{b1})×J₂({a2},{b2}): Δ_w ≈ 0\")\n",
        "            return np.nan, np.nan\n",
        "\n",
        "        beta_hat, swapped = self.solve_beta_designB_robust(\n",
        "            mu1_orig, mu2_orig, a1, b1, a2, b2, verbose=verbose\n",
        "        )\n",
        "\n",
        "        if np.isnan(beta_hat):\n",
        "            if verbose:\n",
        "                print(f\"  J₁({a1},{b1})×J₂({a2},{b2}): β solve failed\")\n",
        "            return np.nan, np.nan\n",
        "\n",
        "        tau = self.tau_w(beta_hat, a1, b1, a2, b2)\n",
        "        if swapped:\n",
        "            tau = -tau\n",
        "\n",
        "        if not np.isfinite(tau) or abs(tau) < 1e-12:\n",
        "            if verbose:\n",
        "                print(f\"  J₁({a1},{b1})×J₂({a2},{b2}): τ_w invalid\")\n",
        "            return np.nan, np.nan\n",
        "\n",
        "        # POSITIVE ratio for ETELN\n",
        "        alpha_hat = tau / Delta_w_orig\n",
        "\n",
        "        if alpha_hat <= 0:\n",
        "            if verbose:\n",
        "                print(f\"  J₁({a1},{b1})×J₂({a2},{b2}): α̂={alpha_hat:.3f} ≤ 0\")\n",
        "            return np.nan, np.nan\n",
        "\n",
        "        if not np.isfinite(alpha_hat):\n",
        "            if verbose:\n",
        "                print(f\"  J₁({a1},{b1})×J₂({a2},{b2}): α̂ not finite\")\n",
        "            return np.nan, np.nan\n",
        "\n",
        "        # Sanity check\n",
        "        if (abs(alpha_hat - self.alpha_true) > 5 * self.alpha_true or\n",
        "            abs(beta_hat - self.beta_true) > 10):\n",
        "            if verbose:\n",
        "                print(f\"  J₁({a1},{b1})×J₂({a2},{b2}): estimates too far from truth\")\n",
        "            return np.nan, np.nan\n",
        "\n",
        "        return alpha_hat, beta_hat\n",
        "\n",
        "    def _lambda_w_pair(self, alpha, beta, ai, bi, aj, bj):\n",
        "        \"\"\"\n",
        "        Compute Λ_{w,ij} with 1/φ(ξ) terms for ETELN\n",
        "        \"\"\"\n",
        "        u, w = self.u, self.w\n",
        "        Ji = self.kumaraswamy_weight(u, ai, bi)\n",
        "        Jj = self.kumaraswamy_weight(u, aj, bj)\n",
        "        u0, xi, phi_xi, g = self._stable_terms_eteln(beta, u)\n",
        "\n",
        "        W = (w * Ji)[:, None] * (w * Jj)[None, :]\n",
        "        K = self._kernel_matrix()\n",
        "        G = g[:, None] * g[None, :]\n",
        "\n",
        "        return np.sum(W * K * G)\n",
        "\n",
        "    def Sigma_mu_designB(self, alpha, beta, a1, b1, a2, b2):\n",
        "        \"\"\"Asymptotic covariance for ETELN Design B\"\"\"\n",
        "        delta_sq = ((np.exp(beta * np.log(2.0)) - 1.0) / (alpha * beta)) ** 2\n",
        "\n",
        "        L11 = self._lambda_w_pair(alpha, beta, a1, b1, a1, b1)\n",
        "        L12 = self._lambda_w_pair(alpha, beta, a1, b1, a2, b2)\n",
        "        L22 = self._lambda_w_pair(alpha, beta, a2, b2, a2, b2)\n",
        "\n",
        "        S = delta_sq * np.array([[L11, L12], [L12, L22]])\n",
        "        return 0.5 * (S + S.T)\n",
        "\n",
        "    def mle_eteln(self, x):\n",
        "        \"\"\"MLE for ETELN\"\"\"\n",
        "        xv = np.asarray(x)\n",
        "        xv = xv[xv >= self.theta]\n",
        "        n = xv.size\n",
        "        if n < 5:\n",
        "            return np.nan, np.nan\n",
        "\n",
        "        def nll(params):\n",
        "            alpha, beta = params\n",
        "            if alpha <= 0 or np.abs(beta) > 5:\n",
        "                return 1e10\n",
        "            try:\n",
        "                with np.errstate(all='ignore'):\n",
        "                    if abs(beta) < 1e-8:\n",
        "                        const = -np.log(np.log(2.0))\n",
        "                    else:\n",
        "                        two_b = np.exp(beta * np.log(2.0))\n",
        "                        const = np.log(np.abs(beta)) - np.log(np.abs(two_b - 1.0))\n",
        "\n",
        "                    zi = alpha * np.log(xv / self.theta)\n",
        "                    phi_zi = norm.pdf(zi)\n",
        "                    Phi_zi = norm.cdf(zi)\n",
        "\n",
        "                    Phi_zi = np.maximum(Phi_zi, 1e-300)\n",
        "                    phi_zi = np.maximum(phi_zi, 1e-300)\n",
        "\n",
        "                    ll = (n * np.log(alpha) + n * const\n",
        "                          - n * 0.5 * np.log(2*np.pi)\n",
        "                          - np.sum(np.log(xv))\n",
        "                          - 0.5 * alpha**2 * np.sum((np.log(xv/self.theta))**2)\n",
        "                          - (beta + 1) * np.sum(np.log(Phi_zi)))\n",
        "\n",
        "                    return -ll if np.isfinite(ll) else 1e10\n",
        "            except:\n",
        "                return 1e10\n",
        "\n",
        "        lx = np.log(xv)\n",
        "        m1 = lx.mean()\n",
        "        m2 = (lx**2).mean()\n",
        "        alpha0 = 1.0 / np.sqrt(max(m2 - m1**2, 1e-4))\n",
        "        beta0 = np.clip(self.beta_true, -3.0, 3.0)\n",
        "\n",
        "        try:\n",
        "            res = minimize(nll, x0=[alpha0, beta0],\n",
        "                          bounds=[(0.05, 10.0), (-3.0, 3.0)],\n",
        "                          method=\"L-BFGS-B\")\n",
        "            if res.success and res.fun < 1e9:\n",
        "                return res.x[0], res.x[1]\n",
        "\n",
        "            res = minimize(nll, x0=[self.alpha_true, self.beta_true],\n",
        "                          bounds=[(0.05, 10.0), (-3.0, 3.0)],\n",
        "                          method=\"L-BFGS-B\")\n",
        "            return (res.x[0], res.x[1]) if res.success else (np.nan, np.nan)\n",
        "        except:\n",
        "            return np.nan, np.nan\n",
        "\n",
        "    def fisher_information(self, alpha, beta, n):\n",
        "        \"\"\"Fisher Information for ETELN\"\"\"\n",
        "        try:\n",
        "            u_int = np.linspace(1e-6, 1 - 1e-6, 50)\n",
        "\n",
        "            with np.errstate(all='ignore'):\n",
        "                two_b = np.exp(beta * np.log(2.0))\n",
        "                u0 = (two_b - (two_b - 1.0) * u_int) ** (-1/beta)\n",
        "                u0 = np.clip(u0, 1e-9, 1 - 1e-9)\n",
        "\n",
        "                xi = norm.ppf(u0)\n",
        "                phi_xi = norm.pdf(xi)\n",
        "                Phi_xi = norm.cdf(xi)\n",
        "\n",
        "                ratio = np.where(Phi_xi > 1e-300, phi_xi / Phi_xi, 0.0)\n",
        "                ratio2 = np.where(Phi_xi > 1e-300, (phi_xi / Phi_xi) ** 2, 0.0)\n",
        "\n",
        "                moment2 = np.trapz(xi**2, u_int) / alpha**2\n",
        "                moment_ratio1 = np.trapz(ratio * xi, u_int) / alpha\n",
        "                moment_ratio3 = np.trapz(xi**3 * ratio, u_int) / alpha**2\n",
        "                moment_ratio2_sq = np.trapz(xi**2 * ratio2, u_int) / alpha**2\n",
        "\n",
        "                denom = two_b - 1.0\n",
        "                ln2 = np.log(2.0)\n",
        "\n",
        "                Ibb = (1/beta**2) * (1 - (two_b * beta**2 * (ln2**2)) / (denom**2))\n",
        "                Iaa = (1/alpha**2) * (1 + moment2 + (beta + 1)**2 * moment_ratio2_sq +\n",
        "                                       2 * alpha * (beta + 1) * moment_ratio3)\n",
        "                Iab = moment_ratio1\n",
        "\n",
        "                I = n * np.array([[Iaa, Iab], [Iab, Ibb]])\n",
        "                return I\n",
        "        except:\n",
        "            return None\n",
        "\n",
        "    def compute_theoretical_are_designB(self, a1, b1, a2, b2):\n",
        "        \"\"\"Compute theoretical ARE for ETELN Design B\"\"\"\n",
        "        u, w = self.u, self.w\n",
        "\n",
        "        with np.errstate(all='ignore'):\n",
        "            two_b = np.exp(self.beta_true * np.log(2.0))\n",
        "            base = two_b - (two_b - 1.0) * u\n",
        "            u0 = base ** (-1/self.beta_true)\n",
        "            u0 = np.clip(u0, 1e-9, 1 - 1e-9)\n",
        "            xi = norm.ppf(u0)\n",
        "\n",
        "            q = self.theta * np.exp((1.0/self.alpha_true) * xi)\n",
        "\n",
        "        J1 = self.kumaraswamy_weight(u, a1, b1)\n",
        "        J2 = self.kumaraswamy_weight(u, a2, b2)\n",
        "\n",
        "        mu1 = np.sum(w * J1 * np.log(q))\n",
        "        mu2 = np.sum(w * J2 * np.log(q))\n",
        "\n",
        "        beta_hat, swapped = self.solve_beta_designB_robust(mu1, mu2, a1, b1, a2, b2)\n",
        "\n",
        "        if np.isnan(beta_hat):\n",
        "            return np.nan\n",
        "\n",
        "        tau = self.tau_w(beta_hat, a1, b1, a2, b2)\n",
        "        if swapped:\n",
        "            tau = -tau\n",
        "\n",
        "        alpha_hat = tau / (mu2 - mu1)\n",
        "\n",
        "        if not (np.isfinite(alpha_hat) and np.isfinite(beta_hat) and alpha_hat > 0):\n",
        "            return np.nan\n",
        "\n",
        "        try:\n",
        "            n_large = 5000\n",
        "            Sigma_mu = self.Sigma_mu_designB(alpha_hat, beta_hat, a1, b1, a2, b2) / n_large\n",
        "\n",
        "            eps = 1e-6\n",
        "\n",
        "            def solve_pair(m1, m2):\n",
        "                try:\n",
        "                    b, sw = self.solve_beta_designB_robust(m1, m2, a1, b1, a2, b2)\n",
        "                    tau = self.tau_w(b, a1, b1, a2, b2)\n",
        "                    if sw:\n",
        "                        tau = -tau\n",
        "                    a = tau / (m2 - m1)\n",
        "                    return a, b\n",
        "                except:\n",
        "                    return alpha_hat, beta_hat\n",
        "\n",
        "            a_p1, b_p1 = solve_pair(mu1 + eps, mu2)\n",
        "            a_m1, b_m1 = solve_pair(mu1 - eps, mu2)\n",
        "            a_p2, b_p2 = solve_pair(mu1, mu2 + eps)\n",
        "            a_m2, b_m2 = solve_pair(mu1, mu2 - eps)\n",
        "\n",
        "            D = np.array([\n",
        "                [(a_p1 - a_m1) / (2 * eps), (a_p2 - a_m2) / (2 * eps)],\n",
        "                [(b_p1 - b_m1) / (2 * eps), (b_p2 - b_m2) / (2 * eps)]\n",
        "            ])\n",
        "\n",
        "            if abs(np.linalg.det(D)) < 1e-12:\n",
        "                return np.nan\n",
        "\n",
        "            S_L = D @ Sigma_mu @ D.T\n",
        "            I = self.fisher_information(alpha_hat, beta_hat, n_large)\n",
        "            if I is None:\n",
        "                return np.nan\n",
        "\n",
        "            S_MLE = np.linalg.inv(I)\n",
        "\n",
        "            det_S_L = np.linalg.det(S_L)\n",
        "            det_S_MLE = np.linalg.det(S_MLE)\n",
        "\n",
        "            if det_S_L <= 0 or det_S_MLE <= 0:\n",
        "                return np.nan\n",
        "\n",
        "            ARE = np.sqrt(det_S_MLE / det_S_L)\n",
        "\n",
        "            if not np.isfinite(ARE) or ARE < 1e-6 or ARE > 2:\n",
        "                return np.nan\n",
        "\n",
        "            return ARE\n",
        "        except:\n",
        "            return np.nan\n",
        "\n",
        "    def run_simulation_with_re_se_designB(self, sample_sizes, j_pairs,\n",
        "                                          n_batches=10, sims_per_batch=100,\n",
        "                                          verbose=True, ref_at=\"true\"):\n",
        "        \"\"\"Run simulation for ETELN Design B\"\"\"\n",
        "        all_results = {}\n",
        "\n",
        "        for n in sample_sizes:\n",
        "            if verbose:\n",
        "                print(f\"\\nRunning n={n} with {n_batches} batches...\")\n",
        "\n",
        "            are_inf = {}\n",
        "            for (a1, b1), (a2, b2) in j_pairs:\n",
        "                are = self.compute_theoretical_are_designB(a1, b1, a2, b2)\n",
        "                are_inf[((a1, b1), (a2, b2))] = are\n",
        "\n",
        "            batch_stats = []\n",
        "\n",
        "            for bidx in range(n_batches):\n",
        "                if verbose and bidx % 5 == 0:\n",
        "                    print(f\"  Batch {bidx + 1}/{n_batches}\")\n",
        "\n",
        "                est = {\"MLE\": {\"alpha\": [], \"beta\": []}}\n",
        "                for (a1, b1), (a2, b2) in j_pairs:\n",
        "                    key = f\"J1({a1},{b1})×J2({a2},{b2})\"\n",
        "                    est[key] = {\"alpha\": [], \"beta\": []}\n",
        "\n",
        "                for _ in range(sims_per_batch):\n",
        "                    x = self.generate_eteln_sample(n)\n",
        "\n",
        "                    a_mle, b_mle = self.mle_eteln(x)\n",
        "                    if np.isfinite(a_mle) and np.isfinite(b_mle):\n",
        "                        est[\"MLE\"][\"alpha\"].append(a_mle)\n",
        "                        est[\"MLE\"][\"beta\"].append(b_mle)\n",
        "\n",
        "                    for (a1, b1), (a2, b2) in j_pairs:\n",
        "                        key = f\"J1({a1},{b1})×J2({a2},{b2})\"\n",
        "                        ak, bk = self.kumaraswamy_l_estimator_designB_robust(\n",
        "                            x, a1, b1, a2, b2, verbose=False\n",
        "                        )\n",
        "                        if np.isfinite(ak) and np.isfinite(bk):\n",
        "                            est[key][\"alpha\"].append(ak)\n",
        "                            est[key][\"beta\"].append(bk)\n",
        "\n",
        "                batch = {}\n",
        "\n",
        "                def _winsorize_pair(a_vals, b_vals, p=0.00):\n",
        "                    ax = np.asarray(a_vals, float)\n",
        "                    bx = np.asarray(b_vals, float)\n",
        "                    if ax.size < 3:\n",
        "                        return ax, bx\n",
        "                    lo = int(np.floor(p * ax.size))\n",
        "                    hi = int(np.ceil((1 - p) * ax.size))\n",
        "                    axs = np.sort(ax)\n",
        "                    bxs = np.sort(bx)\n",
        "                    a_lo, a_hi = axs[lo], axs[min(hi, ax.size - 1)]\n",
        "                    b_lo, b_hi = bxs[lo], bxs[min(hi, bx.size - 1)]\n",
        "                    ax_cl = np.clip(ax, a_lo, a_hi)\n",
        "                    bx_cl = np.clip(bx, b_lo, b_hi)\n",
        "                    return ax_cl, bx_cl\n",
        "\n",
        "                def det_re(a_list, b_list, S_asymp_mle_ref):\n",
        "                    vals = np.c_[a_list, b_list]\n",
        "                    if vals.shape[0] < 3:\n",
        "                        return np.nan\n",
        "                    a_vals, b_vals = _winsorize_pair(vals[:, 0], vals[:, 1])\n",
        "                    S = np.cov(np.c_[a_vals, b_vals], rowvar=False, ddof=1)\n",
        "                    S = 0.5 * (S + S.T) + 1e-9 * np.eye(2)\n",
        "                    den = np.linalg.det(S)\n",
        "                    num = np.linalg.det(S_asymp_mle_ref)\n",
        "                    return np.sqrt(num / den) if den > 0 else np.nan\n",
        "\n",
        "                if len(est[\"MLE\"][\"alpha\"]) > 0:\n",
        "                    avals = np.array(est[\"MLE\"][\"alpha\"])\n",
        "                    bvals = np.array(est[\"MLE\"][\"beta\"])\n",
        "\n",
        "                    if ref_at == \"batch\":\n",
        "                        alpha_ref = float(np.mean(avals))\n",
        "                        beta_ref = float(np.mean(bvals))\n",
        "                    else:\n",
        "                        alpha_ref = self.alpha_true\n",
        "                        beta_ref = self.beta_true\n",
        "\n",
        "                    I_ref = self.fisher_information(alpha_ref, beta_ref, n)\n",
        "                    if I_ref is None:\n",
        "                        continue\n",
        "                    S_asymp_mle_ref = np.linalg.inv(I_ref)\n",
        "\n",
        "                    batch[\"MLE\"] = {\n",
        "                        \"alpha_mean\": np.mean(avals) / self.alpha_true,\n",
        "                        \"alpha_se\": np.std(avals, ddof=1) / (self.alpha_true * np.sqrt(len(avals))),\n",
        "                        \"beta_mean\": np.mean(bvals) / self.beta_true,\n",
        "                        \"beta_se\": np.std(bvals, ddof=1) / (self.beta_true * np.sqrt(len(bvals))),\n",
        "                        \"re\": det_re(avals, bvals, S_asymp_mle_ref),\n",
        "                        \"re_asymptotic\": 1.0\n",
        "                    }\n",
        "\n",
        "                    for (a1, b1), (a2, b2) in j_pairs:\n",
        "                        key = f\"J1({a1},{b1})×J2({a2},{b2})\"\n",
        "                        if len(est[key][\"alpha\"]) > 0:\n",
        "                            avals_k = np.array(est[key][\"alpha\"])\n",
        "                            bvals_k = np.array(est[key][\"beta\"])\n",
        "                            batch[key] = {\n",
        "                                \"alpha_mean\": np.mean(avals_k) / self.alpha_true,\n",
        "                                \"alpha_se\": np.std(avals_k, ddof=1) / (self.alpha_true * np.sqrt(len(avals_k))),\n",
        "                                \"beta_mean\": np.mean(bvals_k) / self.beta_true,\n",
        "                                \"beta_se\": np.std(bvals_k, ddof=1) / (self.beta_true * np.sqrt(len(bvals_k))),\n",
        "                                \"re\": det_re(avals_k, bvals_k, S_asymp_mle_ref),\n",
        "                                \"re_asymptotic\": are_inf[((a1, b1), (a2, b2))]\n",
        "                            }\n",
        "\n",
        "                batch_stats.append(batch)\n",
        "\n",
        "            final = {}\n",
        "            keys = set().union(*[b.keys() for b in batch_stats])\n",
        "\n",
        "            for key in keys:\n",
        "                def collect(field):\n",
        "                    vals = [b[key][field] for b in batch_stats\n",
        "                           if key in b and field in b[key] and np.isfinite(b[key][field])]\n",
        "                    return np.array(vals)\n",
        "\n",
        "                a_mean = collect(\"alpha_mean\")\n",
        "                a_se = collect(\"alpha_se\")\n",
        "                b_mean = collect(\"beta_mean\")\n",
        "                b_se = collect(\"beta_se\")\n",
        "                re_vals = collect(\"re\")\n",
        "                re_inf = collect(\"re_asymptotic\")\n",
        "\n",
        "                if a_mean.size > 0:\n",
        "                    final[key] = {\n",
        "                        \"alpha_mean\": a_mean.mean(),\n",
        "                        \"alpha_se\": a_se.mean() if a_se.size > 0 else np.nan,\n",
        "                        \"beta_mean\": b_mean.mean() if b_mean.size > 0 else np.nan,\n",
        "                        \"beta_se\": b_se.mean() if b_se.size > 0 else np.nan,\n",
        "                        \"re\": re_vals.mean() if re_vals.size > 0 else np.nan,\n",
        "                        \"re_se\": re_vals.std(ddof=1) / np.sqrt(re_vals.size) if re_vals.size > 1 else np.nan,\n",
        "                        \"re_asymptotic\": (1.0 if key == \"MLE\" else (re_inf.mean() if re_inf.size > 0 else np.nan))\n",
        "                    }\n",
        "\n",
        "            all_results[n] = final\n",
        "\n",
        "        return all_results\n",
        "\n",
        "    def print_results_table_designB(self, results, sample_sizes, j_pairs):\n",
        "        \"\"\"Print results table for ETELN Design B\"\"\"\n",
        "        print(\"\\n\" + \"=\" * 140)\n",
        "        print(f\"Design B: Standardized MEAN and RE from ETELN(α={self.alpha_true}, β={self.beta_true}, θ={self.theta})\")\n",
        "        print(\"Different J (J₁ ≠ J₂), Same h = log(x)\")\n",
        "        print(\"=\" * 140)\n",
        "\n",
        "        col_w, last_w = 14, 10\n",
        "        header = \"Weight Config\".ljust(30)\n",
        "        for n in sample_sizes:\n",
        "            header += f\"{f'n={n}':^{col_w * 2}}\"\n",
        "        header += f\"{'n→∞':^{last_w * 2}}\"\n",
        "        print(header)\n",
        "\n",
        "        sub = \"J₁(a₁,b₁)×J₂(a₂,b₂)\".ljust(30)\n",
        "        for _ in sample_sizes:\n",
        "            sub += f\"{'α̂/α':>{col_w}}{'β̂/β':>{col_w}}\"\n",
        "        sub += f\"{'α̂/α':>{last_w}}{'β̂/β':>{last_w}}\"\n",
        "        print(sub)\n",
        "\n",
        "        print(\"\\nMEAN VALUES:\")\n",
        "\n",
        "        def row_for(key, label=None):\n",
        "            lab = (label or key).ljust(30)\n",
        "            out = lab\n",
        "            for n in sample_sizes:\n",
        "                if n in results and key in results[n]:\n",
        "                    s = results[n][key]\n",
        "                    out += f\"{s['alpha_mean']:5.2f}({s['alpha_se']:.3f})\".rjust(col_w)\n",
        "                    out += f\"{s['beta_mean']:5.2f}({s['beta_se']:.3f})\".rjust(col_w)\n",
        "                else:\n",
        "                    out += f\"{'---':>{col_w * 2}}\"\n",
        "            out += f\"{'1.00':>{last_w}}{'1.00':>{last_w}}\"\n",
        "            print(out)\n",
        "\n",
        "        row_for(\"MLE\", \"MLE\")\n",
        "        for (a1, b1), (a2, b2) in j_pairs:\n",
        "            key = f\"J1({a1},{b1})×J2({a2},{b2})\"\n",
        "            row_for(key, f\"J₁({a1},{b1})×J₂({a2},{b2})\")\n",
        "\n",
        "        print(\"\\n\" + \"-\" * 140)\n",
        "        print(\"RELATIVE EFFICIENCY:\")\n",
        "\n",
        "        def re_row(key, label=None):\n",
        "            lab = (label or key).ljust(30)\n",
        "            out = lab\n",
        "            for n in sample_sizes:\n",
        "                if n in results and key in results[n]:\n",
        "                    s = results[n][key]\n",
        "                    re = s.get(\"re\", np.nan)\n",
        "                    se = s.get(\"re_se\", np.nan)\n",
        "                    out += f\"{re:5.3f}({se:.3f})\".rjust(col_w)\n",
        "                else:\n",
        "                    out += f\"{'---':>{col_w}}\"\n",
        "\n",
        "            n0 = sample_sizes[0]\n",
        "            if n0 in results and key in results[n0]:\n",
        "                out += f\"{results[n0][key]['re_asymptotic']:5.3f}\".rjust(last_w)\n",
        "            else:\n",
        "                out += f\"{'---':>{last_w}}\"\n",
        "            print(out)\n",
        "\n",
        "        re_row(\"MLE\", \"MLE\")\n",
        "        for (a1, b1), (a2, b2) in j_pairs:\n",
        "            key = f\"J1({a1},{b1})×J2({a2},{b2})\"\n",
        "            re_row(key, f\"J₁({a1},{b1})×J₂({a2},{b2})\")\n",
        "\n",
        "\n",
        "# ==============================================================\n",
        "# Runner\n",
        "# ==============================================================\n",
        "\n",
        "def run_eteln_simulation_study_designB_robust():\n",
        "    \"\"\"Run ETELN Design B simulation\"\"\"\n",
        "    alpha_true, beta_true, theta_true = 2.0, 0.5, 1.0\n",
        "    sample_sizes = [100, 250, 500, 1000]\n",
        "\n",
        "    j_pairs = [\n",
        "        ((1.0, 1.0), (1.0, 2.0)),\n",
        "        ((1.0, 1.0), (0.3, 1.0)),\n",
        "        ((1.0, 1.0), (1.2, 1.8)),\n",
        "        ((1.0, 1.0), (0.8, 1.0)),\n",
        "        ((1.0, 1.0), (4.0, 12.0)),\n",
        "        ((1.0, 1.0), (2.0, 1.0)),\n",
        "    ]\n",
        "\n",
        "    print(\"=\"*70)\n",
        "    print(\"ETELN Simulation Study - DESIGN B\")\n",
        "    print(\"Different J (J₁ ≠ J₂), Same h = log(x)\")\n",
        "    print(f\"True params: α={alpha_true}, β={beta_true}, θ={theta_true}\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    sim = ETELNSimulation_DesignB(\n",
        "        theta=theta_true,\n",
        "        alpha=alpha_true,\n",
        "        beta=beta_true,\n",
        "        n_quad=250,\n",
        "        use_det_re=True,\n",
        "        use_numeric_info=False,\n",
        "        rng=123\n",
        "    )\n",
        "\n",
        "    results = sim.run_simulation_with_re_se_designB(\n",
        "        sample_sizes=sample_sizes,\n",
        "        j_pairs=j_pairs,\n",
        "        n_batches=50,\n",
        "        sims_per_batch=200,\n",
        "        verbose=True,\n",
        "        ref_at=\"true\"\n",
        "    )\n",
        "\n",
        "    sim.print_results_table_designB(results, sample_sizes, j_pairs)\n",
        "    return results\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
        "    t0 = time.perf_counter()\n",
        "    results = run_eteln_simulation_study_designB_robust()\n",
        "    print(f\"\\n⏱️ Total runtime: {time.perf_counter() - t0:.2f} s\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDfgZhgV4Fd_",
        "outputId": "d18ad430-2b03-403a-a5be-17fdfdf2ef1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "ETELN Simulation Study - DESIGN B\n",
            "Different J (J₁ ≠ J₂), Same h = log(x)\n",
            "True params: α=2.0, β=0.5, θ=1.0\n",
            "======================================================================\n",
            "\n",
            "Running n=100 with 50 batches...\n",
            "  Batch 1/50\n",
            "  Batch 6/50\n",
            "  Batch 11/50\n",
            "  Batch 16/50\n",
            "  Batch 21/50\n",
            "  Batch 26/50\n",
            "  Batch 31/50\n",
            "  Batch 36/50\n",
            "  Batch 41/50\n",
            "  Batch 46/50\n",
            "\n",
            "Running n=250 with 50 batches...\n",
            "  Batch 1/50\n",
            "  Batch 6/50\n",
            "  Batch 11/50\n",
            "  Batch 16/50\n",
            "  Batch 21/50\n",
            "  Batch 26/50\n",
            "  Batch 31/50\n",
            "  Batch 36/50\n",
            "  Batch 41/50\n",
            "  Batch 46/50\n",
            "\n",
            "Running n=500 with 50 batches...\n",
            "  Batch 1/50\n",
            "  Batch 6/50\n",
            "  Batch 11/50\n",
            "  Batch 16/50\n",
            "  Batch 21/50\n",
            "  Batch 26/50\n",
            "  Batch 31/50\n",
            "  Batch 36/50\n",
            "  Batch 41/50\n",
            "  Batch 46/50\n",
            "\n",
            "Running n=1000 with 50 batches...\n",
            "  Batch 1/50\n",
            "  Batch 6/50\n",
            "  Batch 11/50\n",
            "  Batch 16/50\n",
            "  Batch 21/50\n",
            "  Batch 26/50\n",
            "  Batch 31/50\n",
            "  Batch 36/50\n",
            "  Batch 41/50\n",
            "  Batch 46/50\n",
            "\n",
            "============================================================================================================================================\n",
            "Design B: Standardized MEAN and RE from ETELN(α=2.0, β=0.5, θ=1.0)\n",
            "Different J (J₁ ≠ J₂), Same h = log(x)\n",
            "============================================================================================================================================\n",
            "Weight Config                            n=100                       n=250                       n=500                       n=1000                   n→∞         \n",
            "J₁(a₁,b₁)×J₂(a₂,b₂)                     α̂/α          β̂/β          α̂/α          β̂/β          α̂/α          β̂/β          α̂/α          β̂/β      α̂/α      β̂/β\n",
            "\n",
            "MEAN VALUES:\n",
            "MLE                              1.02(0.010)   0.83(0.120)   1.01(0.006)   0.95(0.076)   1.00(0.004)   0.97(0.053)   1.00(0.003)   0.98(0.038)      1.00      1.00\n",
            "J₁(1.0,1.0)×J₂(1.0,2.0)          1.05(0.011)   0.50(0.124)   1.02(0.007)   0.82(0.079)   1.01(0.005)   0.91(0.055)   1.00(0.003)   0.95(0.039)      1.00      1.00\n",
            "J₁(1.0,1.0)×J₂(0.3,1.0)          1.02(0.013)   0.97(0.159)   1.00(0.008)   1.01(0.099)   1.00(0.006)   1.00(0.068)   1.00(0.004)   1.00(0.048)      1.00      1.00\n",
            "J₁(1.0,1.0)×J₂(1.2,1.8)          1.08(0.010)   0.20(0.119)   1.03(0.006)   0.69(0.076)   1.01(0.004)   0.84(0.053)   1.01(0.003)   0.92(0.038)      1.00      1.00\n",
            "J₁(1.0,1.0)×J₂(0.8,1.0)          1.03(0.012)   0.75(0.138)   1.01(0.007)   0.93(0.088)   1.01(0.005)   0.96(0.061)   1.00(0.004)   0.98(0.043)      1.00      1.00\n",
            "J₁(1.0,1.0)×J₂(4.0,12.0)         1.05(0.012)   0.56(0.148)   1.02(0.007)   0.84(0.089)   1.01(0.005)   0.92(0.062)   1.00(0.004)   0.95(0.044)      1.00      1.00\n",
            "J₁(1.0,1.0)×J₂(2.0,1.0)          1.05(0.011)   0.50(0.124)   1.02(0.007)   0.82(0.079)   1.01(0.005)   0.91(0.055)   1.00(0.003)   0.95(0.039)      1.00      1.00\n",
            "\n",
            "--------------------------------------------------------------------------------------------------------------------------------------------\n",
            "RELATIVE EFFICIENCY:\n",
            "MLE                             0.951(0.011)  0.972(0.010)  1.001(0.010)  0.998(0.010)     1.000\n",
            "J₁(1.0,1.0)×J₂(1.0,2.0)         0.895(0.009)  0.917(0.010)  0.949(0.010)  0.949(0.009)     0.945\n",
            "J₁(1.0,1.0)×J₂(0.3,1.0)         0.699(0.007)  0.730(0.008)  0.759(0.007)  0.767(0.007)     0.762\n",
            "J₁(1.0,1.0)×J₂(1.2,1.8)         0.911(0.010)  0.949(0.010)  0.982(0.010)  0.980(0.010)     0.980\n",
            "J₁(1.0,1.0)×J₂(0.8,1.0)         0.805(0.008)  0.826(0.009)  0.855(0.008)  0.861(0.008)     0.855\n",
            "J₁(1.0,1.0)×J₂(4.0,12.0)        0.747(0.009)  0.811(0.009)  0.848(0.009)  0.849(0.009)     0.856\n",
            "J₁(1.0,1.0)×J₂(2.0,1.0)         0.895(0.009)  0.917(0.010)  0.949(0.010)  0.949(0.009)     0.945\n",
            "\n",
            "⏱️ Total runtime: 32925.63 s\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}