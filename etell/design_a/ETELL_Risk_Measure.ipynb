{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3LfTxi6bqZkl"
      },
      "outputs": [],
      "source": [
        "!pip install jax jaxlib\n",
        "!pip install --quiet --upgrade scipy\n",
        "!pip install --quiet jax jaxlib optax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nSZoOLdPiRhT"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "from jax.scipy.stats import norm\n",
        "import jax.numpy as jnp\n",
        "from scipy.stats import norm\n",
        "import time\n",
        "import jax.numpy as jnp\n",
        "from numpy.polynomial.legendre import leggauss\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.optimize import minimize_scalar, brentq, minimize\n",
        "from scipy.special import gamma\n",
        "from numpy.polynomial.legendre import leggauss\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from numpy.random import default_rng\n",
        "from math import log\n",
        "from numpy.random import default_rng, SeedSequence\n",
        "from scipy.stats import kstwobign, cramervonmises, uniform\n",
        "from joblib import Parallel, delayed\n",
        "from itertools import zip_longest\n",
        "from collections import OrderedDict\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ==============================================================\n",
        "# Risk Measure\n",
        "# ==============================================================\n"
      ],
      "metadata": {
        "id": "qFvvPE35DBrh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NM1y1vS7aLvW",
        "outputId": "8b365626-cfa0-4194-a491-61937262d101"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Norwegian fire insurance (kNOK), strict > 500 ===\n",
            "n_total: 9181\n",
            "n_after_theta (x>500): 9020\n",
            "year_min_max: (1972, 1992)\n",
            "min_kNOK: 501\n",
            "max_kNOK: 465,365\n",
            "mean_kNOK: 2,247.860\n",
            "q1_kNOK: 711\n",
            "q3_kNOK: 1,817\n",
            "skewness: 30.61\n",
            "\n",
            "Counts: 9020, 9020, 50, 50\n",
            "Original max -> Modified original max: 465,365 -> 2,000,000\n",
            "Sampled max  -> Modified sampled max : 4,607  -> 2,000,000\n",
            "θ (fixed): 500 kNOK\n",
            "Monster (cap): 2,000,000 kNOK  = 2,000,000,000 NOK\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# 1) Load\n",
        "path = \"/content/sample_data/norwegianfire_raw.csv\"\n",
        "df = pd.read_csv(path)\n",
        "df[\"year_full\"] = 1900 + df[\"year\"].astype(int)\n",
        "\n",
        "# -------- Choose the cap in NOK -----------------\n",
        "\n",
        "MONSTER_NOK = 2_000_000_000  # 2 billion NOK   (alternative)\n",
        "\n",
        "MONSTER_kNOK = MONSTER_NOK / 1_000.0\n",
        "\n",
        "# 2) Strict threshold: keep claims EXCEEDING 500 kNOK\n",
        "theta_kNOK = 500.0\n",
        "df_work = df.loc[df[\"size\"] > theta_kNOK].copy()\n",
        "n_total = len(df)\n",
        "n_work  = len(df_work)\n",
        "\n",
        "# 3) Helper for \"nearest\" empirical quantile (robust across pandas/numpy versions)\n",
        "def q_nearest(x: np.ndarray, p: float) -> float:\n",
        "    x = np.asarray(x, float)\n",
        "    x = x[~np.isnan(x)]\n",
        "    if x.size == 0:\n",
        "        return np.nan\n",
        "    s = pd.Series(x)\n",
        "    try:\n",
        "        return float(s.quantile(p, method=\"nearest\"))\n",
        "    except TypeError:\n",
        "        try:\n",
        "            return float(s.quantile(p, interpolation=\"nearest\"))\n",
        "        except TypeError:\n",
        "            try:\n",
        "                return float(np.quantile(x, p, method=\"nearest\"))\n",
        "            except TypeError:\n",
        "                return float(np.percentile(x, 100*p, interpolation=\"nearest\"))\n",
        "\n",
        "# 4) Headline stats (kNOK)\n",
        "s = df_work[\"size\"].astype(float)\n",
        "n = s.size\n",
        "m1 = s.mean()\n",
        "q1 = q_nearest(s.values, 0.25)\n",
        "q3 = q_nearest(s.values, 0.75)\n",
        "\n",
        "# Unbiased (Fisher–Pearson) sample skewness\n",
        "m2 = np.mean((s - m1)**2)\n",
        "m3 = np.mean((s - m1)**3)\n",
        "g1 = m3 / (m2**1.5) if m2 > 0 else np.nan\n",
        "skew_unbiased = (np.sqrt(n*(n-1))/(n-2))*g1 if n > 2 else np.nan\n",
        "\n",
        "print(\"=== Norwegian fire insurance (kNOK), strict > 500 ===\")\n",
        "print(f\"n_total: {n_total}\")\n",
        "print(f\"n_after_theta (x>500): {n_work}\")\n",
        "print(f\"year_min_max: ({int(df['year_full'].min())}, {int(df['year_full'].max())})\")\n",
        "print(f\"min_kNOK: {s.min():,.0f}\")\n",
        "print(f\"max_kNOK: {s.max():,.0f}\")\n",
        "print(f\"mean_kNOK: {m1:,.3f}\")\n",
        "print(f\"q1_kNOK: {q1:,.0f}\")\n",
        "print(f\"q3_kNOK: {q3:,.0f}\")\n",
        "print(f\"skewness: {skew_unbiased:.2f}\")\n",
        "\n",
        "# ---------- Build the four arrays (all in kNOK) ----------\n",
        "# 1) Original data (x > 500)\n",
        "x_original = np.asarray(df_work[\"size\"].values, dtype=float)\n",
        "x_original = np.sort(x_original)\n",
        "\n",
        "# 2) Modified original: replace the single maximum with MONSTER_kNOK\n",
        "x_mod_original = x_original.copy()\n",
        "imax = np.argmax(x_mod_original)\n",
        "x_mod_original[imax] = MONSTER_kNOK\n",
        "x_mod_original = np.sort(x_mod_original)\n",
        "\n",
        "# 3) Sampled: n=50, seed=123\n",
        "rng = np.random.default_rng(123)\n",
        "idx50 = rng.choice(x_original.shape[0], size=50, replace=False)\n",
        "x_sampled = np.sort(x_original[idx50])\n",
        "\n",
        "# 4) Modified sampled: replace its maximum with MONSTER_kNOK\n",
        "x_mod_sampled = x_sampled.copy()\n",
        "jmax = np.argmax(x_mod_sampled)\n",
        "x_mod_sampled[jmax] = MONSTER_kNOK\n",
        "x_mod_sampled = np.sort(x_mod_sampled)\n",
        "\n",
        "# 5) Wire up θ for the ETLL code that uses Greek theta\n",
        "θ = theta_kNOK\n",
        "\n",
        "# Quick sanity prints\n",
        "print(f\"\\nCounts: {len(x_original)}, {len(x_mod_original)}, {len(x_sampled)}, {len(x_mod_sampled)}\")\n",
        "print(f\"Original max -> Modified original max: {np.max(x_original):,.0f} -> {np.max(x_mod_original):,.0f}\")\n",
        "print(f\"Sampled max  -> Modified sampled max : {np.max(x_sampled):,.0f}  -> {np.max(x_mod_sampled):,.0f}\")\n",
        "print(f\"θ (fixed): {θ:,.0f} kNOK\")\n",
        "print(f\"Monster (cap): {MONSTER_kNOK:,.0f} kNOK  = {int(MONSTER_NOK):,} NOK\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== Print the sampled values in a 5×10 grid ======\n",
        "\n",
        "def print_sample_block(x, title, rows=5, cols=10, integers=True):\n",
        "    \"\"\"\n",
        "    Print values as a rows×cols block, left-to-right then top-to-bottom,\n",
        "    with thousands separators. Assumes len(x) == rows*cols (e.g., 50).\n",
        "    \"\"\"\n",
        "    x = np.sort(np.asarray(x, float))\n",
        "    if x.size != rows*cols:\n",
        "        raise ValueError(f\"Expected {rows*cols} values, got {x.size}. \"\n",
        "                         f\"Adjust rows/cols or sample size.\")\n",
        "    if integers:\n",
        "        x_disp = np.round(x).astype(int)\n",
        "        fmt = lambda v: f\"{v:,.0f}\"\n",
        "    else:\n",
        "        x_disp = x\n",
        "        fmt = lambda v: f\"{v:,.3f}\"\n",
        "\n",
        "    print(title)\n",
        "    for r in range(rows):\n",
        "        start = r*cols\n",
        "        row_vals = [fmt(v) for v in x_disp[start:start+cols]]\n",
        "        print(\", \".join(row_vals))\n",
        "    print()  # blank line after the block\n",
        "\n",
        "# ---- Print both blocks (kNOK) ----\n",
        "print_sample_block(x_sampled,      \"Sampled data (n=50, kNOK):\")\n",
        "print_sample_block(x_mod_sampled,  \"Modified sampled data (n=50, kNOK):\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwKDpZ7Xt8kY",
        "outputId": "9c4539f5-e711-4e94-b15e-7c5fde4ab5a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sampled data (n=50, kNOK):\n",
            "505, 512, 513, 520, 541, 615, 632, 641, 650, 650\n",
            "675, 675, 682, 698, 699, 700, 704, 704, 718, 735\n",
            "745, 805, 822, 901, 911, 942, 957, 961, 1,035, 1,060\n",
            "1,075, 1,223, 1,244, 1,343, 1,500, 1,743, 1,750, 2,039, 2,072, 2,097\n",
            "2,139, 2,220, 2,294, 2,348, 2,468, 2,764, 3,317, 3,814, 4,377, 4,607\n",
            "\n",
            "Modified sampled data (n=50, kNOK):\n",
            "505, 512, 513, 520, 541, 615, 632, 641, 650, 650\n",
            "675, 675, 682, 698, 699, 700, 704, 704, 718, 735\n",
            "745, 805, 822, 901, 911, 942, 957, 961, 1,035, 1,060\n",
            "1,075, 1,223, 1,244, 1,343, 1,500, 1,743, 1,750, 2,039, 2,072, 2,097\n",
            "2,139, 2,220, 2,294, 2,348, 2,468, 2,764, 3,317, 3,814, 4,377, 2,000,000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EfQuWPd-_wxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7MPJYYxv_xH5"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ---- optional: keep BLAS threads = 1 per worker to avoid oversubscription\n",
        "try:\n",
        "    from threadpoolctl import threadpool_limits\n",
        "    _HAS_TPCTL = True\n",
        "except Exception:\n",
        "    _HAS_TPCTL = False\n",
        "\n",
        "# ---------------- Performance knobs ----------------\n",
        "N_JOBS       = -1       # use all cores\n",
        "BACKEND      = \"loky\"   # processes for CPU-bound work\n",
        "BLAS_THREADS = 1        # 1 BLAS thread per worker\n",
        "\n",
        "# Numerical effort: high for observed fit, lighter for MC refits\n",
        "NQUAD_OBS = 800\n",
        "NQUAD_MC  = 200\n",
        "GRID_OBS  = 401\n",
        "GRID_MC   = 201\n",
        "MC_BATCH  = 200         # chunk MC jobs to lower overhead\n",
        "\n",
        "# ---- Monte-Carlo reps\n",
        "# Use big B for full-sample fixed-parameter MC\n",
        "MC_B_ORIG      = 10000\n",
        "MC_B_MOD_ORIG  = 10000\n",
        "# Moderate B for n=50 refitting MC\n",
        "MC_B_SAMP      = 2000\n",
        "MC_B_MOD_SAMP  = 2000\n",
        "\n",
        "ln2 = np.log(2.0)\n",
        "\n",
        "# ---------- Core ETLL pieces (θ fixed) ----------\n",
        "def etll_cdf(x, alpha, beta, theta):\n",
        "    x = np.asarray(x, float)\n",
        "    u = np.zeros_like(x, dtype=float)\n",
        "    m = x > theta\n",
        "    if not np.any(m):\n",
        "        return u\n",
        "    t = (theta / x[m])**alpha\n",
        "    if abs(beta) < 1e-8:\n",
        "        u[m] = 1.0 - (np.log1p(t) / ln2)\n",
        "    else:\n",
        "        two_b = np.exp(beta * ln2)\n",
        "        u[m] = (two_b - np.power(1.0 + t, beta)) / (two_b - 1.0)\n",
        "    return np.clip(u, 0.0, 1.0)\n",
        "\n",
        "def ks_statistic(x, cdf):\n",
        "    x = np.sort(np.asarray(x, float)); n = x.size\n",
        "    u = cdf(x); ecdf = (np.arange(1, n+1)) / n\n",
        "    return float(np.max(np.abs(u - ecdf)))\n",
        "\n",
        "def cvm_statistic(x, cdf):\n",
        "    x = np.sort(np.asarray(x, float)); n = x.size\n",
        "    u = cdf(x); i = np.arange(1, n+1)\n",
        "    return float(np.sum((u - (2*i - 1)/(2*n))**2) + 1.0/(12*n))\n",
        "\n",
        "def etll_sample(n, alpha, beta, theta, rng=None):\n",
        "    rng = default_rng() if rng is None else rng\n",
        "    u = rng.uniform(0.0, 1.0, int(n))\n",
        "    if abs(beta) < 1e-8:\n",
        "        t = np.expm1((1.0 - u) * ln2)\n",
        "    else:\n",
        "        two_b = np.exp(beta * ln2)\n",
        "        base  = two_b - (two_b - 1.0) * u\n",
        "        base  = np.maximum(base, 1e-300)\n",
        "        t     = np.expm1(np.log(base)/beta)\n",
        "    return theta * np.power(t, -1.0/alpha)\n",
        "\n",
        "# ---------- MLE (θ fixed) ----------\n",
        "def etll_loglik_alpha_beta(x, alpha, beta, theta):\n",
        "    if alpha <= 0 or abs(beta) > 12:\n",
        "        return -np.inf\n",
        "    xv = np.asarray(x, float); xv = xv[xv > theta]\n",
        "    if xv.size == 0:\n",
        "        return -np.inf\n",
        "    n = xv.size\n",
        "    two_b = np.exp(beta * ln2)\n",
        "    denom = two_b - 1.0\n",
        "    if abs(denom) < 1e-14:\n",
        "        denom = beta * ln2 + 0.5*(beta**2)*(ln2**2)\n",
        "    const = np.log(alpha) + np.log(abs(beta)) - np.log(abs(denom))\n",
        "    ratio = (theta / xv)**alpha\n",
        "    ll = n*const - np.sum(np.log(xv)) + np.sum(alpha*np.log(theta/xv)) + (beta-1.0)*np.sum(np.log1p(ratio))\n",
        "    return float(ll)\n",
        "\n",
        "def fit_mle_etll(x, theta):\n",
        "    x = np.asarray(x, float); x = x[x > theta]\n",
        "    if x.size < 5:\n",
        "        return np.nan, np.nan\n",
        "    lx = np.log(x); m2 = np.mean((lx - lx.mean())**2)\n",
        "    a0 = max(0.1, 1.0/np.sqrt(max(m2, 1e-6))); b0 = 0.5\n",
        "    def nll(p):\n",
        "        a,b = p; v = etll_loglik_alpha_beta(x, a, b, theta)\n",
        "        return -v if np.isfinite(v) else 1e20\n",
        "    res = minimize(nll, x0=[a0, b0], bounds=[(1e-3, 40.0), (-12.0, 12.0)], method=\"L-BFGS-B\")\n",
        "    if res.success:\n",
        "        return float(res.x[0]), float(res.x[1])\n",
        "    res = minimize(nll, x0=[1.5, 0.2], bounds=[(1e-3, 40.0), (-12.0, 12.0)], method=\"L-BFGS-B\")\n",
        "    return (float(res.x[0]), float(res.x[1])) if res.success else (np.nan, np.nan)\n",
        "\n",
        "# ---------- Robust L-estimation J(a,b) (θ fixed) ----------\n",
        "def _ck_tau(beta, a, b, n_quad):\n",
        "    nodes, w = np.polynomial.legendre.leggauss(n_quad)\n",
        "    u = 0.5*(nodes + 1.0); w = 0.5*w\n",
        "    J = a*b * (u**(a-1.0)) * ((1.0 - u**a)**(b-1.0))\n",
        "\n",
        "    if abs(beta) < 1e-10:\n",
        "        t = np.expm1((1.0 - u) * ln2)\n",
        "    else:\n",
        "        two_b = np.exp(beta * ln2)\n",
        "        base  = two_b - (two_b - 1.0) * u\n",
        "        base  = np.maximum(base, 1e-300)\n",
        "        t     = np.expm1(np.log(base)/beta)\n",
        "\n",
        "    t   = np.maximum(t, 1e-300)\n",
        "    ell = np.log(t)\n",
        "\n",
        "    c1  = float(np.sum(w * J * ell))\n",
        "    c2  = float(np.sum(w * J * (ell**2)))\n",
        "    tau = c2 - c1**2\n",
        "    return c1, max(tau, 1e-14)\n",
        "\n",
        "def fit_L_etll_stable(x, a=1.1, b=1.2, theta=500.0, n_quad=NQUAD_OBS, root_grid=GRID_OBS):\n",
        "    x = np.asarray(x, float); x = x[x > theta]\n",
        "    n = x.size\n",
        "    if n < 5:\n",
        "        return np.nan, np.nan\n",
        "\n",
        "    xs  = np.sort(x)\n",
        "    i   = np.arange(1, n+1)\n",
        "    uo  = i/(n+1.0)\n",
        "\n",
        "    Jw  = a*b * (uo**(a-1.0)) * ((1.0 - uo**a)**(b-1.0))\n",
        "    wts = Jw / np.sum(Jw)\n",
        "\n",
        "    lx = np.log(xs)\n",
        "    mu1   = float(np.sum(wts * lx))\n",
        "    mu2   = float(np.sum(wts * (lx**2)))\n",
        "    Delta = max(mu2 - mu1**2, 1e-12)\n",
        "\n",
        "    target = (np.log(theta) - mu1) / np.sqrt(Delta)\n",
        "\n",
        "    def R(beta):\n",
        "        c1, tau = _ck_tau(beta, a, b, n_quad=n_quad)\n",
        "        return c1/np.sqrt(tau) - target\n",
        "\n",
        "    grid = np.linspace(-10.0, 10.0, int(root_grid))\n",
        "    vals = np.array([R(bi) for bi in grid])\n",
        "    sgn  = np.sign(vals)\n",
        "\n",
        "    beta_hat = None\n",
        "    for k in range(len(grid)-1):\n",
        "        if np.isfinite(vals[k]) and np.isfinite(vals[k+1]) and sgn[k]*sgn[k+1] < 0:\n",
        "            beta_hat = brentq(lambda z: R(z), grid[k], grid[k+1], xtol=1e-8, maxiter=400)\n",
        "            break\n",
        "\n",
        "    if beta_hat is None:\n",
        "        from scipy.optimize import minimize_scalar\n",
        "        obj = lambda b: (R(b) if np.isfinite(R(b)) else 1e6)**2\n",
        "        res = minimize_scalar(obj, bounds=(-10.0, 10.0), method=\"bounded\",\n",
        "                              options={\"xatol\":1e-8, \"maxiter\":1000})\n",
        "        beta_hat = float(res.x)\n",
        "\n",
        "    _, tau_hat = _ck_tau(beta_hat, a, b, n_quad=n_quad)\n",
        "    alpha_hat  = np.sqrt(tau_hat / Delta)\n",
        "    return float(alpha_hat), float(beta_hat)\n",
        "\n",
        "def make_safe_L_factory(a_req, b_req, fallbacks=None, n_quad=NQUAD_OBS, root_grid=GRID_OBS):\n",
        "    if fallbacks is None:\n",
        "        fallbacks = [(1.05,1.10), (1.10,1.20), (1.20,1.30)]\n",
        "    def fit_fun(z, _nq=n_quad, _rg=root_grid):\n",
        "        ah, bh = fit_L_etll_stable(z, a_req, b_req, θ, n_quad=_nq, root_grid=_rg)\n",
        "        if np.isfinite(ah) and np.isfinite(bh):\n",
        "            return ah, bh\n",
        "        for (aa,bb) in fallbacks:\n",
        "            ah2, bh2 = fit_L_etll_stable(z, aa, bb, θ, n_quad=_nq, root_grid=_rg)\n",
        "            if np.isfinite(ah2) and np.isfinite(bh2):\n",
        "                return ah2, bh2\n",
        "        return fit_mle_etll(z, θ)\n",
        "    return fit_fun\n",
        "\n",
        "# ---- MC p-values with RE-FITTING (n=50 panels)\n",
        "def mc_pvals_parallel(x, fit_fun, theta, B=2000, seed=1234, n_jobs=N_JOBS, backend=BACKEND,\n",
        "                      nquad_obs=NQUAD_OBS, nquad_mc=NQUAD_MC, grid_obs=GRID_OBS, grid_mc=GRID_MC,\n",
        "                      batch=MC_BATCH):\n",
        "    if _HAS_TPCTL: threadpool_limits(BLAS_THREADS)\n",
        "    x = np.asarray(x, float); x = x[x > theta]\n",
        "    n = x.size\n",
        "    if n == 0: return (np.nan, np.nan, np.nan, np.nan, np.nan, np.nan)\n",
        "\n",
        "    def fit_obs(z): return fit_fun(z, _nq=nquad_obs, _rg=grid_obs)\n",
        "    a_hat, b_hat = fit_obs(x)\n",
        "    cdf_hat = lambda z: etll_cdf(z, a_hat, b_hat, theta)\n",
        "    D_obs = ks_statistic(x, cdf_hat); W_obs = cvm_statistic(x, cdf_hat)\n",
        "\n",
        "    seeds = SeedSequence(seed).spawn(B)\n",
        "    seed_ints = [int(s.generate_state(1)[0]) for s in seeds]\n",
        "\n",
        "    def one_rep(seed_i):\n",
        "        rng = default_rng(seed_i)\n",
        "        xb = etll_sample(n, a_hat, b_hat, theta, rng)\n",
        "        ah, bh = fit_fun(xb, _nq=nquad_mc, _rg=grid_mc)\n",
        "        cdf_b = lambda z, aa=ah, bb=bh: etll_cdf(z, aa, bb, theta)\n",
        "        return ks_statistic(xb, cdf_b), cvm_statistic(xb, cdf_b)\n",
        "\n",
        "    def _chunks(lst, k):\n",
        "        for i in range(0, len(lst), k): yield lst[i:i+k]\n",
        "\n",
        "    Ds_all, Ws_all = [], []\n",
        "    for chunk in _chunks(seed_ints, MC_BATCH):\n",
        "        Ds, Ws = zip(*Parallel(n_jobs=n_jobs, backend=backend)(\n",
        "            delayed(one_rep)(si) for si in chunk\n",
        "        ))\n",
        "        Ds_all.append(np.array(Ds)); Ws_all.append(np.array(Ws))\n",
        "    Ds = np.concatenate(Ds_all); Ws = np.concatenate(Ws_all)\n",
        "\n",
        "    # Davison–Hinkley\n",
        "    p_ks  = (1.0 + np.sum(Ds >= D_obs)) / (B + 1.0)\n",
        "    p_cvm = (1.0 + np.sum(Ws >= W_obs)) / (B + 1.0)\n",
        "    return (a_hat, b_hat, D_obs, W_obs, p_ks, p_cvm)\n",
        "\n",
        "# ---- MC p-values with FIXED PARAMETERS\n",
        "def mc_pvals_fixedparams(x, fit_fun, theta, B=10000, seed=1234, n_jobs=N_JOBS, backend=BACKEND,\n",
        "                         nquad_obs=NQUAD_OBS, batch=MC_BATCH):\n",
        "    if _HAS_TPCTL: threadpool_limits(BLAS_THREADS)\n",
        "    x = np.asarray(x, float); x = x[x > theta]\n",
        "    n = x.size\n",
        "    if n == 0: return (np.nan, np.nan, np.nan, np.nan, np.nan, np.nan)\n",
        "\n",
        "    # Fit once (full accuracy), then DO NOT refit in replicates\n",
        "    a_hat, b_hat = fit_fun(x, _nq=nquad_obs, _rg=GRID_OBS)\n",
        "    cdf_hat = lambda z: etll_cdf(z, a_hat, b_hat, theta)\n",
        "    D_obs = ks_statistic(x, cdf_hat); W_obs = cvm_statistic(x, cdf_hat)\n",
        "\n",
        "    seeds = SeedSequence(seed).spawn(B)\n",
        "    seed_ints = [int(s.generate_state(1)[0]) for s in seeds]\n",
        "\n",
        "    def one_rep(seed_i):\n",
        "        rng = default_rng(seed_i)\n",
        "        xb = etll_sample(n, a_hat, b_hat, theta, rng)\n",
        "        # NO refit here:\n",
        "        return ks_statistic(xb, cdf_hat), cvm_statistic(xb, cdf_hat)\n",
        "\n",
        "    def _chunks(lst, k):\n",
        "        for i in range(0, len(lst), k): yield lst[i:i+k]\n",
        "\n",
        "    Ds_all, Ws_all = [], []\n",
        "    for chunk in _chunks(seed_ints, batch):\n",
        "        Ds, Ws = zip(*Parallel(n_jobs=n_jobs, backend=backend)(\n",
        "            delayed(one_rep)(si) for si in chunk\n",
        "        ))\n",
        "        Ds_all.append(np.array(Ds)); Ws_all.append(np.array(Ws))\n",
        "    Ds = np.concatenate(Ds_all); Ws = np.concatenate(Ws_all)\n",
        "\n",
        "    p_ks  = (1.0 + np.sum(Ds >= D_obs)) / (B + 1.0)\n",
        "    p_cvm = (1.0 + np.sum(Ws >= W_obs)) / (B + 1.0)\n",
        "    return (a_hat, b_hat, D_obs, W_obs, p_ks, p_cvm)\n",
        "\n",
        "# ---------- GoF with selectable mode ----------\n",
        "def gof_with_mode(x, fit_fun, mode=\"mc\", B=100, seed=1234, n_jobs=N_JOBS):\n",
        "    x = np.asarray(x, float); x = x[x > θ]\n",
        "    if x.size == 0:\n",
        "        return {\"Estimator\":\"\", \"alpha\":np.nan, \"beta\":np.nan,\n",
        "                \"KS_p\":np.nan, \"KS_D\":np.nan, \"CvM_p\":np.nan, \"CvM_W\":np.nan,\n",
        "                \"_det\":1.0/(B+1.0)}\n",
        "\n",
        "    if mode == \"mc_fixed\":\n",
        "        a_hat, b_hat, D_obs, W_obs, p_ks, p_cvm = mc_pvals_fixedparams(\n",
        "            x, fit_fun, θ, B=B, seed=seed, n_jobs=n_jobs, nquad_obs=NQUAD_OBS, batch=MC_BATCH\n",
        "        )\n",
        "        return {\"Estimator\":\"\", \"alpha\":a_hat, \"beta\":b_hat,\n",
        "                \"KS_p\":p_ks, \"KS_D\":D_obs, \"CvM_p\":p_cvm, \"CvM_W\":W_obs,\n",
        "                \"_det\":1.0/(B+1.0)}\n",
        "\n",
        "    if mode == \"mc\":\n",
        "        a_hat, b_hat, D_obs, W_obs, p_ks, p_cvm = mc_pvals_parallel(\n",
        "            x, fit_fun, θ, B=B, seed=seed, n_jobs=n_jobs,\n",
        "            nquad_obs=NQUAD_OBS, nquad_mc=NQUAD_MC, grid_obs=GRID_OBS, grid_mc=GRID_MC\n",
        "        )\n",
        "        return {\"Estimator\":\"\", \"alpha\":a_hat, \"beta\":b_hat,\n",
        "                \"KS_p\":p_ks, \"KS_D\":D_obs, \"CvM_p\":p_cvm, \"CvM_W\":W_obs,\n",
        "                \"_det\":1.0/(B+1.0)}\n",
        "\n",
        "    # asymptotic (not used here)\n",
        "    a_hat, b_hat = fit_fun(x)\n",
        "    cdf_hat = lambda z: etll_cdf(z, a_hat, b_hat, θ)\n",
        "    D_obs = ks_statistic(x, cdf_hat)\n",
        "    W_obs = cvm_statistic(x, cdf_hat)\n",
        "    p_ks  = float(kstwobign.sf(np.sqrt(x.size) * D_obs))\n",
        "    u = etll_cdf(np.sort(x), a_hat, b_hat, θ)\n",
        "    p_cvm = float(cramervonmises(u, uniform.cdf).pvalue)\n",
        "    return {\"Estimator\":\"\", \"alpha\":a_hat, \"beta\":b_hat,\n",
        "            \"KS_p\":p_ks, \"KS_D\":D_obs, \"CvM_p\":p_cvm, \"CvM_W\":W_obs,\n",
        "            \"_det\":0.0}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# RISK MEASURES FOR ETELL DISTRIBUTION (with ∞-CTE guard )\n",
        "# ==============================================================================\n",
        "\n",
        "# --------------------------------------------------------------------------\n",
        "# VaR and CTE Calculation\n",
        "# --------------------------------------------------------------------------\n",
        "\n",
        "class ETELLRiskMeasures:\n",
        "    def __init__(self, theta=500.0, n_quad=400):\n",
        "        self.theta = theta\n",
        "        self.n_quad = n_quad\n",
        "        # Precompute Gauss-Legendre nodes and weights for [0,1]\n",
        "        nodes, weights = leggauss(n_quad)\n",
        "        self.u = 0.5 * (nodes + 1.0)   # map [-1,1] -> [0,1]\n",
        "        self.w = 0.5 * weights         # integrates functions on [0,1] (weights sum to 1)\n",
        "        self.ln2 = np.log(2.0)\n",
        "\n",
        "    def etll_quantile(self, u, alpha, beta):\n",
        "        u = np.clip(np.asarray(u, float), 1e-12, 1-1e-12)\n",
        "        if abs(beta) < 1e-10:\n",
        "            t = np.expm1((1.0 - u) * self.ln2)\n",
        "        else:\n",
        "            two_b = np.exp(beta * self.ln2)\n",
        "            base  = np.maximum(two_b - (two_b - 1.0) * u, 1e-300)\n",
        "            t     = np.expm1(np.log(base) / beta)\n",
        "        return self.theta * np.power(np.maximum(t, 1e-300), -1.0 / alpha)\n",
        "\n",
        "    def var(self, alpha, beta, confidence_level=0.99):\n",
        "        return self.etll_quantile(confidence_level, alpha, beta)\n",
        "\n",
        "    def cte(self, alpha, beta, confidence_level=0.99):\n",
        "        # ES/CTE diverges for α ≤ 1 (heavy tail with infinite mean)\n",
        "        if alpha <= 1.0:\n",
        "            return float('inf')\n",
        "        p = float(confidence_level)          # e.g., 0.98, 0.99, 0.995\n",
        "        s = p + (1.0 - p) * self.u           # s ∈ [p,1]\n",
        "        q_vals = self.etll_quantile(s, alpha, beta)\n",
        "        return float(np.sum(self.w * q_vals))\n",
        "\n",
        "    def compute_risk_measures(self, alpha, beta, confidence_levels=[0.98, 0.99, 0.995]):\n",
        "        results = {}\n",
        "        for cl in confidence_levels:\n",
        "            tail_prob = 1.0 - cl\n",
        "            var_val = self.var(alpha, beta, cl)\n",
        "            cte_val = self.cte(alpha, beta, cl)\n",
        "            results[cl] = {\n",
        "                'confidence_level': cl,\n",
        "                'tail_probability': tail_prob,\n",
        "                'VaR': var_val,\n",
        "                'CTE': cte_val\n",
        "            }\n",
        "        return results\n",
        "\n",
        "\n",
        "# --------------------------------------------------------------------------\n",
        "# Empirical Risk Measures\n",
        "# --------------------------------------------------------------------------\n",
        "\n",
        "def empirical_var(x, confidence_level=0.99):\n",
        "    x = np.sort(np.asarray(x, float))\n",
        "    return float(np.quantile(x, confidence_level, method='linear'))\n",
        "\n",
        "def empirical_cte(x, confidence_level=0.99):\n",
        "    x = np.asarray(x, float)\n",
        "    var_emp = empirical_var(x, confidence_level)\n",
        "    exceedances = x[x > var_emp]   # strict exceedances\n",
        "    if exceedances.size == 0:\n",
        "        return np.nan\n",
        "    return float(np.mean(exceedances))\n",
        "\n",
        "\n",
        "# --------------------------------------------------------------------------\n",
        "# Risk Measures Table Generator\n",
        "# --------------------------------------------------------------------------\n",
        "\n",
        "def compute_risk_table(data_dict, estimators, confidence_levels=[0.98, 0.99, 0.995],\n",
        "                       theta=500.0, n_quad=400):\n",
        "    rm = ETELLRiskMeasures(theta=theta, n_quad=n_quad)\n",
        "    results = {}\n",
        "\n",
        "    for data_name, x in data_dict.items():\n",
        "        x = np.asarray(x, float)\n",
        "        x = x[x > theta]\n",
        "        if x.size == 0:\n",
        "            continue\n",
        "\n",
        "        results[data_name] = {}\n",
        "\n",
        "        # Empirical measures\n",
        "        emp_results = {}\n",
        "        for cl in confidence_levels:\n",
        "            emp_results[cl] = {\n",
        "                'VaR': empirical_var(x, cl),\n",
        "                'CTE': empirical_cte(x, cl)\n",
        "            }\n",
        "        results[data_name]['Empirical'] = emp_results\n",
        "\n",
        "        # Fitted model measures\n",
        "        for est_name, fit_fun in estimators:\n",
        "            try:\n",
        "                alpha_hat, beta_hat = fit_fun(x)\n",
        "                if not (np.isfinite(alpha_hat) and np.isfinite(beta_hat)):\n",
        "                    results[data_name][est_name] = None\n",
        "                    continue\n",
        "                model_results = rm.compute_risk_measures(alpha_hat, beta_hat, confidence_levels)\n",
        "                model_results['alpha'] = alpha_hat\n",
        "                model_results['beta'] = beta_hat\n",
        "                results[data_name][est_name] = model_results\n",
        "            except Exception as e:\n",
        "                print(f\"Warning: {est_name} failed on {data_name}: {e}\")\n",
        "                results[data_name][est_name] = None\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "# ---------- helpers for pretty printing ----------\n",
        "_INF_THRESHOLD = 1e15  # anything larger is printed as ∞ to avoid huge numbers\n",
        "\n",
        "def _fmt(v):\n",
        "    if v is None or not np.isfinite(v) or v > _INF_THRESHOLD:\n",
        "        return \"∞\"\n",
        "    return f\"{v:,.2f}\"\n",
        "\n",
        "def _fmtdiff(a, b):\n",
        "    # If either side is non-finite/huge, show dash\n",
        "    bad = lambda z: (z is None) or (not np.isfinite(z)) or (z > _INF_THRESHOLD)\n",
        "    if bad(a) or bad(b):\n",
        "        return \"—\"\n",
        "    return f\"{(a - b):+,.2f}\"\n",
        "\n",
        "\n",
        "def print_risk_table(results, confidence_levels=[0.98, 0.99, 0.995]):\n",
        "    for data_name, data_results in results.items():\n",
        "        print(\"\\n\" + \"=\"*100)\n",
        "        print(f\"Risk Measures: {data_name}\")\n",
        "        print(\"=\"*100)\n",
        "\n",
        "        estimators = [k for k in data_results.keys() if k != 'Empirical']\n",
        "\n",
        "        for cl in confidence_levels:\n",
        "            tail_prob = 1.0 - cl\n",
        "            print(f\"\\n{'Confidence Level':<20} {cl*100:.1f}% (Tail Probability = {tail_prob*100:.2f}%)\")\n",
        "            print(\"-\"*100)\n",
        "\n",
        "            # Header\n",
        "            print(f\"{'Method':<20} {'α̂':>8} {'β̂':>8} {'VaR':>15} {'CTE':>15} {'VaR Diff':>15} {'CTE Diff':>15}\")\n",
        "            print(\"-\"*100)\n",
        "\n",
        "            # Empirical row\n",
        "            emp = data_results['Empirical'][cl]\n",
        "            print(f\"{'Empirical':<20} {'-':>8} {'-':>8} {_fmt(emp['VaR']):>15} {_fmt(emp['CTE']):>15} {'-':>15} {'-':>15}\")\n",
        "\n",
        "            # Model rows\n",
        "            for est_name in estimators:\n",
        "                est_results = data_results[est_name]\n",
        "                if est_results is None or cl not in est_results:\n",
        "                    print(f\"{est_name:<20} {'FAILED':>8} {'FAILED':>8} {'-':>15} {'-':>15} {'-':>15} {'-':>15}\")\n",
        "                    continue\n",
        "\n",
        "                alpha_hat = est_results['alpha']\n",
        "                beta_hat  = est_results['beta']\n",
        "                var_theo  = est_results[cl]['VaR']\n",
        "                cte_theo  = est_results[cl]['CTE']\n",
        "\n",
        "                print(f\"{est_name:<20} {alpha_hat:>8.2f} {beta_hat:>8.2f} \"\n",
        "                      f\"{_fmt(var_theo):>15} {_fmt(cte_theo):>15} \"\n",
        "                      f\"{_fmtdiff(var_theo, emp['VaR']):>15} {_fmtdiff(cte_theo, emp['CTE']):>15}\")\n",
        "\n",
        "\n",
        "def print_comparison_table(results, confidence_level=0.99):\n",
        "    datasets = list(results.keys())\n",
        "    first_data = results[datasets[0]]\n",
        "    estimators = [k for k in first_data.keys() if k != 'Empirical']\n",
        "\n",
        "    print(\"\\n\" + \"=\"*140)\n",
        "    print(f\"Risk Measures Comparison at {confidence_level*100:.1f}% Confidence Level\")\n",
        "    print(\"=\"*140)\n",
        "\n",
        "    # Header\n",
        "    header = f\"{'Method':<20}\"\n",
        "    for data_name in datasets:\n",
        "        header += f\" | {data_name:^28}\"\n",
        "    print(header)\n",
        "\n",
        "    subheader = f\"{'':<20}\"\n",
        "    for _ in datasets:\n",
        "        subheader += f\" | {'VaR':>13} {'CTE':>13}\"\n",
        "    print(subheader)\n",
        "    print(\"-\"*140)\n",
        "\n",
        "    # Empirical row\n",
        "    row = f\"{'Empirical':<20}\"\n",
        "    for data_name in datasets:\n",
        "        emp = results[data_name]['Empirical'][confidence_level]\n",
        "        row += f\" | {_fmt(emp['VaR']):>13} {_fmt(emp['CTE']):>13}\"\n",
        "    print(row)\n",
        "\n",
        "    print(\"-\"*140)\n",
        "\n",
        "    # Model rows\n",
        "    for est_name in ['MLE'] + [e for e in estimators if e != 'MLE']:\n",
        "        row = f\"{est_name:<20}\"\n",
        "        for data_name in datasets:\n",
        "            est_results = results[data_name].get(est_name)\n",
        "            if est_results is None or confidence_level not in est_results:\n",
        "                row += f\" | {'FAILED':>13} {'FAILED':>13}\"\n",
        "            else:\n",
        "                var_theo = est_results[confidence_level]['VaR']\n",
        "                cte_theo = est_results[confidence_level]['CTE']\n",
        "                row += f\" | {_fmt(var_theo):>13} {_fmt(cte_theo):>13}\"\n",
        "        print(row)\n",
        "\n",
        "    print(\"=\"*140)\n",
        "\n",
        "\n",
        "# --------------------------------------------------------------------------\n",
        "# Run\n",
        "# --------------------------------------------------------------------------\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    data_dict = {\n",
        "        'Sampled (n=50)': x_sampled,\n",
        "        'Modified Sampled': x_mod_sampled,\n",
        "        'Original (n=9020)': x_original,\n",
        "        'Modified Original': x_mod_original,\n",
        "    }\n",
        "\n",
        "    estimators = [\n",
        "        (\"MLE\", lambda z: fit_mle_etll(z, θ)),\n",
        "        (\"J(1.25,9.00)\", make_safe_L_factory(1.25, 9.00)),\n",
        "        (\"J(1.35,3.50)\", make_safe_L_factory(1.35, 3.50)),\n",
        "        (\"J(1.30,1.60)\", make_safe_L_factory(1.30, 1.60)),\n",
        "        (\"J(1.15,4.00)\", make_safe_L_factory(1.15, 4.00)),\n",
        "    ]\n",
        "\n",
        "    print(\"Computing risk measures...\")\n",
        "    results = compute_risk_table(\n",
        "        data_dict=data_dict,\n",
        "        estimators=estimators,\n",
        "        confidence_levels=[0.98, 0.99, 0.995],\n",
        "        theta=500.0,\n",
        "        n_quad=400\n",
        "    )\n",
        "\n",
        "    print_risk_table(results, confidence_levels=[0.98, 0.99, 0.995])\n",
        "    print_comparison_table(results, confidence_level=0.98)\n",
        "    print_comparison_table(results, confidence_level=0.99)\n",
        "    print_comparison_table(results, confidence_level=0.995)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGsoqXdH_T1m",
        "outputId": "93028352-5cca-433c-80df-aa2bc7bdb76c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing risk measures...\n",
            "\n",
            "====================================================================================================\n",
            "Risk Measures: Sampled (n=50)\n",
            "====================================================================================================\n",
            "\n",
            "Confidence Level     98.0% (Tail Probability = 2.00%)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Method                     α̂       β̂             VaR             CTE        VaR Diff        CTE Diff\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Empirical                   -        -        4,381.60        4,607.00               -               -\n",
            "MLE                      1.77    -1.14        6,905.49       15,934.55       +2,523.89      +11,327.55\n",
            "J(1.25,9.00)             1.65    -0.96        8,082.37       20,571.90       +3,700.77      +15,964.90\n",
            "J(1.35,3.50)             1.47    -0.28        9,848.23       30,713.72       +5,466.63      +26,106.72\n",
            "J(1.30,1.60)             1.60    -0.71        8,318.60       22,072.34       +3,937.00      +17,465.34\n",
            "J(1.15,4.00)             1.65    -0.84        7,857.76       19,935.47       +3,476.16      +15,328.47\n",
            "\n",
            "Confidence Level     99.0% (Tail Probability = 1.00%)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Method                     α̂       β̂             VaR             CTE        VaR Diff        CTE Diff\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Empirical                   -        -        4,494.30        4,607.00               -               -\n",
            "MLE                      1.77    -1.14       10,253.51       23,611.90       +5,759.21      +19,004.90\n",
            "J(1.25,9.00)             1.65    -0.96       12,350.75       31,367.78       +7,856.45      +26,760.78\n",
            "J(1.35,3.50)             1.47    -0.28       15,850.09       49,328.51      +11,355.79      +44,721.51\n",
            "J(1.30,1.60)             1.60    -0.71       12,856.91       34,041.39       +8,362.61      +29,434.39\n",
            "J(1.15,4.00)             1.65    -0.84       11,996.02       30,370.14       +7,501.72      +25,763.14\n",
            "\n",
            "Confidence Level     99.5% (Tail Probability = 0.50%)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Method                     α̂       β̂             VaR             CTE        VaR Diff        CTE Diff\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Empirical                   -        -        4,550.65        4,607.00               -               -\n",
            "MLE                      1.77    -1.14       15,202.42       34,972.75      +10,651.77      +30,365.75\n",
            "J(1.25,9.00)             1.65    -0.96       18,844.62       47,808.72      +14,293.97      +43,201.72\n",
            "J(1.35,3.50)             1.47    -0.28       25,474.40       79,198.53      +20,923.75      +74,591.53\n",
            "J(1.30,1.60)             1.60    -0.71       19,841.87       52,479.66      +15,291.22      +47,872.66\n",
            "J(1.15,4.00)             1.65    -0.84       18,286.63       46,247.25      +13,735.98      +41,640.25\n",
            "\n",
            "====================================================================================================\n",
            "Risk Measures: Modified Sampled\n",
            "====================================================================================================\n",
            "\n",
            "Confidence Level     98.0% (Tail Probability = 2.00%)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Method                     α̂       β̂             VaR             CTE        VaR Diff        CTE Diff\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Empirical                   -        -       44,289.46    2,000,000.00               -               -\n",
            "MLE                      0.26     9.67       29,458.33               ∞      -14,831.13               —\n",
            "J(1.25,9.00)             1.65    -0.96        8,082.37       20,571.90      -36,207.09   -1,979,428.10\n",
            "J(1.35,3.50)             1.45    -0.24       10,068.60       32,100.53      -34,220.86   -1,967,899.47\n",
            "J(1.30,1.60)             0.52     4.68       51,681.27               ∞       +7,391.81               —\n",
            "J(1.15,4.00)             1.65    -0.83        7,884.37       20,053.59      -36,405.09   -1,979,946.41\n",
            "\n",
            "Confidence Level     99.0% (Tail Probability = 1.00%)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Method                     α̂       β̂             VaR             CTE        VaR Diff        CTE Diff\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Empirical                   -        -    1,022,144.73    2,000,000.00               -               -\n",
            "MLE                      0.26     9.67       87,918.47               ∞     -934,226.26               —\n",
            "J(1.25,9.00)             1.65    -0.96       12,350.75       31,367.78   -1,009,793.98   -1,968,632.22\n",
            "J(1.35,3.50)             1.45    -0.24       16,287.66       51,820.06   -1,005,857.07   -1,948,179.94\n",
            "J(1.30,1.60)             0.52     4.68      169,249.74               ∞     -852,894.99               —\n",
            "J(1.15,4.00)             1.65    -0.83       12,045.17       30,571.66   -1,010,099.56   -1,969,428.34\n",
            "\n",
            "Confidence Level     99.5% (Tail Probability = 0.50%)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Method                     α̂       β̂             VaR             CTE        VaR Diff        CTE Diff\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Empirical                   -        -    1,511,072.37    2,000,000.00               -               -\n",
            "MLE                      0.26     9.67      322,068.90               ∞   -1,189,003.46               —\n",
            "J(1.25,9.00)             1.65    -0.96       18,844.62       47,808.72   -1,492,227.74   -1,952,191.28\n",
            "J(1.35,3.50)             1.45    -0.24       26,311.93       83,625.96   -1,484,760.43   -1,916,374.04\n",
            "J(1.30,1.60)             0.52     4.68      590,543.02               ∞     -920,529.35               —\n",
            "J(1.15,4.00)             1.65    -0.83       18,374.54       46,587.03   -1,492,697.82   -1,953,412.97\n",
            "\n",
            "====================================================================================================\n",
            "Risk Measures: Original (n=9020)\n",
            "====================================================================================================\n",
            "\n",
            "Confidence Level     98.0% (Tail Probability = 2.00%)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Method                     α̂       β̂             VaR             CTE        VaR Diff        CTE Diff\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Empirical                   -        -       12,009.30       33,725.79               -               -\n",
            "MLE                      1.49    -1.06       11,034.15       33,284.18         -975.15         -441.61\n",
            "J(1.25,9.00)             1.64    -1.49        8,939.63       22,808.43       -3,069.67      -10,917.36\n",
            "J(1.35,3.50)             1.59    -1.35        9,679.92       26,139.85       -2,329.38       -7,585.94\n",
            "J(1.30,1.60)             1.49    -1.03       10,999.70       33,210.97       -1,009.60         -514.82\n",
            "J(1.15,4.00)             1.60    -1.41        9,443.68       25,024.14       -2,565.62       -8,701.65\n",
            "\n",
            "Confidence Level     99.0% (Tail Probability = 1.00%)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Method                     α̂       β̂             VaR             CTE        VaR Diff        CTE Diff\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Empirical                   -        -       19,991.14       51,638.16               -               -\n",
            "MLE                      1.49    -1.06       17,625.93       53,031.90       -2,365.21       +1,393.73\n",
            "J(1.25,9.00)             1.64    -1.49       13,672.13       34,800.10       -6,319.01      -16,838.07\n",
            "J(1.35,3.50)             1.59    -1.35       15,035.28       40,501.98       -4,955.86      -11,136.19\n",
            "J(1.30,1.60)             1.49    -1.03       17,574.67       52,927.12       -2,416.47       +1,288.95\n",
            "J(1.15,4.00)             1.60    -1.41       14,594.18       38,578.14       -5,396.96      -13,060.02\n",
            "\n",
            "Confidence Level     99.5% (Tail Probability = 0.50%)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Method                     α̂       β̂             VaR             CTE        VaR Diff        CTE Diff\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Empirical                   -        -       32,069.19       77,271.35               -               -\n",
            "MLE                      1.49    -1.06       28,107.38       84,460.02       -3,961.80       +7,188.67\n",
            "J(1.25,9.00)             1.64    -1.49       20,875.24       53,071.72      -11,193.95      -24,199.63\n",
            "J(1.35,3.50)             1.59    -1.35       23,314.01       62,726.57       -8,755.17      -14,544.78\n",
            "J(1.30,1.60)             1.49    -1.03       28,031.84       84,312.20       -4,037.34       +7,040.85\n",
            "J(1.15,4.00)             1.60    -1.41       22,515.81       59,446.18       -9,553.38      -17,825.17\n",
            "\n",
            "====================================================================================================\n",
            "Risk Measures: Modified Original\n",
            "====================================================================================================\n",
            "\n",
            "Confidence Level     98.0% (Tail Probability = 2.00%)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Method                     α̂       β̂             VaR             CTE        VaR Diff        CTE Diff\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Empirical                   -        -       12,009.30       42,204.44               -               -\n",
            "MLE                      1.49    -1.06       11,045.99       33,353.02         -963.31       -8,851.42\n",
            "J(1.25,9.00)             1.64    -1.49        8,939.63       22,808.43       -3,069.67      -19,396.01\n",
            "J(1.35,3.50)             1.59    -1.35        9,679.92       26,139.85       -2,329.38      -16,064.59\n",
            "J(1.30,1.60)             1.49    -1.03       11,001.06       33,219.15       -1,008.24       -8,985.29\n",
            "J(1.15,4.00)             1.60    -1.41        9,443.68       25,024.14       -2,565.62      -17,180.30\n",
            "\n",
            "Confidence Level     99.0% (Tail Probability = 1.00%)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Method                     α̂       β̂             VaR             CTE        VaR Diff        CTE Diff\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Empirical                   -        -       19,991.14       68,502.29               -               -\n",
            "MLE                      1.49    -1.06       17,649.07       53,154.29       -2,342.07      -15,347.99\n",
            "J(1.25,9.00)             1.64    -1.49       13,672.13       34,800.10       -6,319.01      -33,702.19\n",
            "J(1.35,3.50)             1.59    -1.35       15,035.28       40,501.98       -4,955.86      -28,000.31\n",
            "J(1.30,1.60)             1.49    -1.03       17,577.36       52,941.70       -2,413.78      -15,560.58\n",
            "J(1.15,4.00)             1.60    -1.41       14,594.18       38,578.14       -5,396.96      -29,924.14\n",
            "\n",
            "Confidence Level     99.5% (Tail Probability = 0.50%)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Method                     α̂       β̂             VaR             CTE        VaR Diff        CTE Diff\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Empirical                   -        -       32,069.19      110,632.98               -               -\n",
            "MLE                      1.49    -1.06       28,151.02       84,675.22       -3,918.16      -25,957.76\n",
            "J(1.25,9.00)             1.64    -1.49       20,875.24       53,071.72      -11,193.95      -57,561.26\n",
            "J(1.35,3.50)             1.59    -1.35       23,314.01       62,726.57       -8,755.17      -47,906.41\n",
            "J(1.30,1.60)             1.49    -1.03       28,036.96       84,337.92       -4,032.22      -26,295.06\n",
            "J(1.15,4.00)             1.60    -1.41       22,515.81       59,446.18       -9,553.38      -51,186.80\n",
            "\n",
            "============================================================================================================================================\n",
            "Risk Measures Comparison at 98.0% Confidence Level\n",
            "============================================================================================================================================\n",
            "Method               |        Sampled (n=50)        |       Modified Sampled       |      Original (n=9020)       |      Modified Original      \n",
            "                     |           VaR           CTE |           VaR           CTE |           VaR           CTE |           VaR           CTE\n",
            "--------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Empirical            |      4,381.60      4,607.00 |     44,289.46  2,000,000.00 |     12,009.30     33,725.79 |     12,009.30     42,204.44\n",
            "--------------------------------------------------------------------------------------------------------------------------------------------\n",
            "MLE                  |      6,905.49     15,934.55 |     29,458.33             ∞ |     11,034.15     33,284.18 |     11,045.99     33,353.02\n",
            "J(1.25,9.00)         |      8,082.37     20,571.90 |      8,082.37     20,571.90 |      8,939.63     22,808.43 |      8,939.63     22,808.43\n",
            "J(1.35,3.50)         |      9,848.23     30,713.72 |     10,068.60     32,100.53 |      9,679.92     26,139.85 |      9,679.92     26,139.85\n",
            "J(1.30,1.60)         |      8,318.60     22,072.34 |     51,681.27             ∞ |     10,999.70     33,210.97 |     11,001.06     33,219.15\n",
            "J(1.15,4.00)         |      7,857.76     19,935.47 |      7,884.37     20,053.59 |      9,443.68     25,024.14 |      9,443.68     25,024.14\n",
            "============================================================================================================================================\n",
            "\n",
            "============================================================================================================================================\n",
            "Risk Measures Comparison at 99.0% Confidence Level\n",
            "============================================================================================================================================\n",
            "Method               |        Sampled (n=50)        |       Modified Sampled       |      Original (n=9020)       |      Modified Original      \n",
            "                     |           VaR           CTE |           VaR           CTE |           VaR           CTE |           VaR           CTE\n",
            "--------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Empirical            |      4,494.30      4,607.00 |  1,022,144.73  2,000,000.00 |     19,991.14     51,638.16 |     19,991.14     68,502.29\n",
            "--------------------------------------------------------------------------------------------------------------------------------------------\n",
            "MLE                  |     10,253.51     23,611.90 |     87,918.47             ∞ |     17,625.93     53,031.90 |     17,649.07     53,154.29\n",
            "J(1.25,9.00)         |     12,350.75     31,367.78 |     12,350.75     31,367.78 |     13,672.13     34,800.10 |     13,672.13     34,800.10\n",
            "J(1.35,3.50)         |     15,850.09     49,328.51 |     16,287.66     51,820.06 |     15,035.28     40,501.98 |     15,035.28     40,501.98\n",
            "J(1.30,1.60)         |     12,856.91     34,041.39 |    169,249.74             ∞ |     17,574.67     52,927.12 |     17,577.36     52,941.70\n",
            "J(1.15,4.00)         |     11,996.02     30,370.14 |     12,045.17     30,571.66 |     14,594.18     38,578.14 |     14,594.18     38,578.14\n",
            "============================================================================================================================================\n",
            "\n",
            "============================================================================================================================================\n",
            "Risk Measures Comparison at 99.5% Confidence Level\n",
            "============================================================================================================================================\n",
            "Method               |        Sampled (n=50)        |       Modified Sampled       |      Original (n=9020)       |      Modified Original      \n",
            "                     |           VaR           CTE |           VaR           CTE |           VaR           CTE |           VaR           CTE\n",
            "--------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Empirical            |      4,550.65      4,607.00 |  1,511,072.37  2,000,000.00 |     32,069.19     77,271.35 |     32,069.19    110,632.98\n",
            "--------------------------------------------------------------------------------------------------------------------------------------------\n",
            "MLE                  |     15,202.42     34,972.75 |    322,068.90             ∞ |     28,107.38     84,460.02 |     28,151.02     84,675.22\n",
            "J(1.25,9.00)         |     18,844.62     47,808.72 |     18,844.62     47,808.72 |     20,875.24     53,071.72 |     20,875.24     53,071.72\n",
            "J(1.35,3.50)         |     25,474.40     79,198.53 |     26,311.93     83,625.96 |     23,314.01     62,726.57 |     23,314.01     62,726.57\n",
            "J(1.30,1.60)         |     19,841.87     52,479.66 |    590,543.02             ∞ |     28,031.84     84,312.20 |     28,036.96     84,337.92\n",
            "J(1.15,4.00)         |     18,286.63     46,247.25 |     18,374.54     46,587.03 |     22,515.81     59,446.18 |     22,515.81     59,446.18\n",
            "============================================================================================================================================\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}