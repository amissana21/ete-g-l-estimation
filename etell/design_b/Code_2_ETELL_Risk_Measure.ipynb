{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3LfTxi6bqZkl"
      },
      "outputs": [],
      "source": [
        "!pip install jax jaxlib\n",
        "!pip install --quiet --upgrade scipy\n",
        "!pip install --quiet jax jaxlib optax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nSZoOLdPiRhT"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "from jax.scipy.stats import norm\n",
        "import jax.numpy as jnp\n",
        "from scipy.stats import norm\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.optimize import minimize_scalar, brentq, minimize\n",
        "from scipy.special import gamma\n",
        "from numpy.polynomial.legendre import leggauss\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from math import log\n",
        "from numpy.random import default_rng, SeedSequence\n",
        "from scipy.stats import kstwobign, cramervonmises, uniform\n",
        "from joblib import Parallel, delayed\n",
        "from itertools import zip_longest\n",
        "from collections import OrderedDict\n",
        "from scipy.stats import uniform, cramervonmises, kstwobign\n",
        "from joblib import Parallel, delayed\n",
        "from itertools import zip_longest\n",
        "import matplotlib.patches as mpatches\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ==============================================================\n",
        "# Risk Measures\n",
        "# ==============================================================\n"
      ],
      "metadata": {
        "id": "qFvvPE35DBrh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================\n",
        "# DESIGN B: Real Data Analysis - Norwegian Fire Insurance\n",
        "# Different J (J₁ ≠ J₂), Same h = log(x)\n",
        "# ==============================================================\n",
        "\n",
        "# ==============================================================\n",
        "# 1) LOAD DATA\n",
        "# ==============================================================\n",
        "\n",
        "path = \"/content/sample_data/norwegianfire_raw.csv\"\n",
        "df = pd.read_csv(path)\n",
        "df[\"year_full\"] = 1900 + df[\"year\"].astype(int)\n",
        "\n",
        "# -------- Choose the cap in NOK -----------------\n",
        "MONSTER_NOK = 2_000_000_000  # 2 billion NOK\n",
        "MONSTER_kNOK = MONSTER_NOK / 1_000.0\n",
        "\n",
        "# 2) Strict threshold: keep claims EXCEEDING 500 kNOK\n",
        "theta_kNOK = 500.0\n",
        "df_work = df.loc[df[\"size\"] > theta_kNOK].copy()\n",
        "n_total = len(df)\n",
        "n_work  = len(df_work)\n",
        "\n",
        "# 3) Helper for \"nearest\" empirical quantile\n",
        "def q_nearest(x: np.ndarray, p: float) -> float:\n",
        "    x = np.asarray(x, float)\n",
        "    x = x[~np.isnan(x)]\n",
        "    if x.size == 0:\n",
        "        return np.nan\n",
        "    s = pd.Series(x)\n",
        "    try:\n",
        "        return float(s.quantile(p, method=\"nearest\"))\n",
        "    except TypeError:\n",
        "        try:\n",
        "            return float(s.quantile(p, interpolation=\"nearest\"))\n",
        "        except TypeError:\n",
        "            try:\n",
        "                return float(np.quantile(x, p, method=\"nearest\"))\n",
        "            except TypeError:\n",
        "                return float(np.percentile(x, 100*p, interpolation=\"nearest\"))\n",
        "\n",
        "# 4) Headline stats\n",
        "s = df_work[\"size\"].astype(float)\n",
        "n = s.size\n",
        "m1 = s.mean()\n",
        "q1 = q_nearest(s.values, 0.25)\n",
        "q3 = q_nearest(s.values, 0.75)\n",
        "m2 = np.mean((s - m1)**2)\n",
        "m3 = np.mean((s - m1)**3)\n",
        "g1 = m3 / (m2**1.5) if m2 > 0 else np.nan\n",
        "skew_unbiased = (np.sqrt(n*(n-1))/(n-2))*g1 if n > 2 else np.nan\n",
        "\n",
        "print(\"=== Norwegian fire insurance (kNOK), strict > 500 ===\")\n",
        "print(f\"n_total: {n_total}\")\n",
        "print(f\"n_after_theta (x>500): {n_work}\")\n",
        "print(f\"year_min_max: ({int(df['year_full'].min())}, {int(df['year_full'].max())})\")\n",
        "print(f\"min_kNOK: {s.min():,.0f}\")\n",
        "print(f\"max_kNOK: {s.max():,.0f}\")\n",
        "print(f\"mean_kNOK: {m1:,.3f}\")\n",
        "print(f\"q1_kNOK: {q1:,.0f}\")\n",
        "print(f\"q3_kNOK: {q3:,.0f}\")\n",
        "print(f\"skewness: {skew_unbiased:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2seXsNUb7L1H",
        "outputId": "6c2ef4ff-15b2-4c79-da40-edf1ce41f950"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Norwegian fire insurance (kNOK), strict > 500 ===\n",
            "n_total: 9181\n",
            "n_after_theta (x>500): 9020\n",
            "year_min_max: (1972, 1992)\n",
            "min_kNOK: 501\n",
            "max_kNOK: 465,365\n",
            "mean_kNOK: 2,247.860\n",
            "q1_kNOK: 711\n",
            "q3_kNOK: 1,817\n",
            "skewness: 30.61\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        " # ---------- Build the four arrays ----------\n",
        "# 1) Original data\n",
        "x_original = np.asarray(df_work[\"size\"].values, dtype=float)\n",
        "x_original = np.sort(x_original)\n",
        "\n",
        "# 2) Modified original\n",
        "x_mod_original = x_original.copy()\n",
        "imax = np.argmax(x_mod_original)\n",
        "x_mod_original[imax] = MONSTER_kNOK\n",
        "x_mod_original = np.sort(x_mod_original)\n",
        "\n",
        "# 3) Sampled: n=50\n",
        "rng = np.random.default_rng(123)\n",
        "idx50 = rng.choice(x_original.shape[0], size=50, replace=False)\n",
        "x_sampled = np.sort(x_original[idx50])\n",
        "\n",
        "# 4) Modified sampled\n",
        "x_mod_sampled = x_sampled.copy()\n",
        "jmax = np.argmax(x_mod_sampled)\n",
        "x_mod_sampled[jmax] = MONSTER_kNOK\n",
        "x_mod_sampled = np.sort(x_mod_sampled)\n",
        "\n",
        "# 5) Wire up θ\n",
        "θ = theta_kNOK\n",
        "\n",
        "print(f\"\\nCounts: {len(x_original)}, {len(x_mod_original)}, {len(x_sampled)}, {len(x_mod_sampled)}\")\n",
        "print(f\"Original max -> Modified original max: {np.max(x_original):,.0f} -> {np.max(x_mod_original):,.0f}\")\n",
        "print(f\"Sampled max  -> Modified sampled max : {np.max(x_sampled):,.0f}  -> {np.max(x_mod_sampled):,.0f}\")\n",
        "print(f\"θ (fixed): {θ:,.0f} kNOK\")\n",
        "print(f\"Monster (cap): {MONSTER_kNOK:,.0f} kNOK  = {int(MONSTER_NOK):,} NOK\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7aGpdIyV8-pr",
        "outputId": "1772bcec-347d-4880-bbe7-2a99c723ba23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Counts: 9020, 9020, 50, 50\n",
            "Original max -> Modified original max: 465,365 -> 2,000,000\n",
            "Sampled max  -> Modified sampled max : 4,607  -> 2,000,000\n",
            "θ (fixed): 500 kNOK\n",
            "Monster (cap): 2,000,000 kNOK  = 2,000,000,000 NOK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- optional: keep BLAS threads = 1 per worker to avoid oversubscription\n",
        "try:\n",
        "    from threadpoolctl import threadpool_limits\n",
        "    _HAS_TPCTL = True\n",
        "except Exception:\n",
        "    _HAS_TPCTL = False\n",
        "\n",
        "# ---------------- Performance knobs ----------------\n",
        "N_JOBS       = -1       # use all cores\n",
        "BACKEND      = \"loky\"   # processes for CPU-bound work\n",
        "BLAS_THREADS = 1        # 1 BLAS thread per worker\n",
        "\n",
        "# Numerical effort: high for observed fit, lighter for MC refits\n",
        "NQUAD_OBS = 800\n",
        "NQUAD_MC  = 200\n",
        "GRID_OBS  = 401\n",
        "GRID_MC   = 201\n",
        "MC_BATCH  = 200         # chunk MC jobs to lower overhead\n",
        "\n",
        "# ---- Monte-Carlo reps\n",
        "# Use big B for full-sample fixed-parameter MC\n",
        "MC_B_ORIG      = 10000\n",
        "MC_B_MOD_ORIG  = 10000\n",
        "# Moderate B for n=50 refitting MC\n",
        "MC_B_SAMP      = 2000\n",
        "MC_B_MOD_SAMP  = 2000\n",
        "\n",
        "ln2 = np.log(2.0)\n",
        "\n",
        "\n",
        "# ==============================================================\n",
        "# 2) CORE ETLL FUNCTIONS\n",
        "# ==============================================================\n",
        "\n",
        "def etll_cdf(x, alpha, beta, theta):\n",
        "    x = np.asarray(x, float)\n",
        "    u = np.zeros_like(x, dtype=float)\n",
        "    m = x > theta\n",
        "    if not np.any(m):\n",
        "        return u\n",
        "    t = (theta / x[m])**alpha\n",
        "    if abs(beta) < 1e-8:\n",
        "        u[m] = 1.0 - (np.log1p(t) / ln2)\n",
        "    else:\n",
        "        two_b = np.exp(beta * ln2)\n",
        "        u[m] = (two_b - np.power(1.0 + t, beta)) / (two_b - 1.0)\n",
        "    return np.clip(u, 0.0, 1.0)\n",
        "\n",
        "def ks_statistic(x, cdf):\n",
        "    x = np.sort(np.asarray(x, float)); n = x.size\n",
        "    u = cdf(x); ecdf = (np.arange(1, n+1)) / n\n",
        "    return float(np.max(np.abs(u - ecdf)))\n",
        "\n",
        "def cvm_statistic(x, cdf):\n",
        "    x = np.sort(np.asarray(x, float)); n = x.size\n",
        "    u = cdf(x); i = np.arange(1, n+1)\n",
        "    return float(np.sum((u - (2*i - 1)/(2*n))**2) + 1.0/(12*n))\n",
        "\n",
        "def etll_sample(n, alpha, beta, theta, rng=None):\n",
        "    rng = default_rng() if rng is None else rng\n",
        "    u = rng.uniform(0.0, 1.0, int(n))\n",
        "    if abs(beta) < 1e-8:\n",
        "        t = np.expm1((1.0 - u) * ln2)\n",
        "    else:\n",
        "        two_b = np.exp(beta * ln2)\n",
        "        base  = two_b - (two_b - 1.0) * u\n",
        "        base  = np.maximum(base, 1e-300)\n",
        "        t     = np.expm1(np.log(base)/beta)\n",
        "    return theta * np.power(t, -1.0/alpha)\n",
        "\n",
        "def etll_loglik_alpha_beta(x, alpha, beta, theta):\n",
        "    if alpha <= 0 or abs(beta) > 12:\n",
        "        return -np.inf\n",
        "    xv = np.asarray(x, float); xv = xv[xv > theta]\n",
        "    if xv.size == 0:\n",
        "        return -np.inf\n",
        "    n = xv.size\n",
        "    two_b = np.exp(beta * ln2)\n",
        "    denom = two_b - 1.0\n",
        "    if abs(denom) < 1e-14:\n",
        "        denom = beta * ln2 + 0.5*(beta**2)*(ln2**2)\n",
        "    const = np.log(alpha) + np.log(abs(beta)) - np.log(abs(denom))\n",
        "    ratio = (theta / xv)**alpha\n",
        "    ll = n*const - np.sum(np.log(xv)) + np.sum(alpha*np.log(theta/xv)) + (beta-1.0)*np.sum(np.log1p(ratio))\n",
        "    return float(ll)\n",
        "\n",
        "def fit_mle_etll(x, theta):\n",
        "    x = np.asarray(x, float); x = x[x > theta]\n",
        "    if x.size < 5:\n",
        "        return np.nan, np.nan\n",
        "    lx = np.log(x); m2 = np.mean((lx - lx.mean())**2)\n",
        "    a0 = max(0.1, 1.0/np.sqrt(max(m2, 1e-6))); b0 = 0.5\n",
        "    def nll(p):\n",
        "        a,b = p; v = etll_loglik_alpha_beta(x, a, b, theta)\n",
        "        return -v if np.isfinite(v) else 1e20\n",
        "    res = minimize(nll, x0=[a0, b0], bounds=[(1e-3, 40.0), (-12.0, 12.0)], method=\"L-BFGS-B\")\n",
        "    if res.success:\n",
        "        return float(res.x[0]), float(res.x[1])\n",
        "    res = minimize(nll, x0=[1.5, 0.2], bounds=[(1e-3, 40.0), (-12.0, 12.0)], method=\"L-BFGS-B\")\n",
        "    return (float(res.x[0]), float(res.x[1])) if res.success else (np.nan, np.nan)\n",
        "\n",
        "# ==============================================================\n",
        "# 3) DESIGN B L-ESTIMATOR\n",
        "# ==============================================================\n",
        "\n",
        "def _cw_tau_designB(beta, a1, b1, a2, b2, n_quad):\n",
        "    \"\"\"\n",
        "    Compute c_{w,1}, c_{w,2}, and τ_w for Design B\n",
        "    \"\"\"\n",
        "    nodes, w = np.polynomial.legendre.leggauss(n_quad)\n",
        "    u = 0.5*(nodes + 1.0); w = 0.5*w\n",
        "\n",
        "    J1 = a1*b1 * (u**(a1-1.0)) * ((1.0 - u**a1)**(b1-1.0))\n",
        "    J2 = a2*b2 * (u**(a2-1.0)) * ((1.0 - u**a2)**(b2-1.0))\n",
        "\n",
        "    if abs(beta) < 1e-10:\n",
        "        t = np.expm1((1.0 - u) * ln2)\n",
        "    else:\n",
        "        two_b = np.exp(beta * ln2)\n",
        "        base  = two_b - (two_b - 1.0) * u\n",
        "        base  = np.maximum(base, 1e-300)\n",
        "        t     = np.expm1(np.log(base)/beta)\n",
        "\n",
        "    t   = np.maximum(t, 1e-300)\n",
        "    ell = np.log(t)\n",
        "\n",
        "    c1  = float(np.sum(w * J1 * ell))\n",
        "    c2  = float(np.sum(w * J2 * ell))\n",
        "    tau_w = c2 - c1\n",
        "\n",
        "    return c1, c2, tau_w\n",
        "\n",
        "def fit_L_etll_designB_stable(x, a1=1.0, b1=1.0, a2=1.0, b2=2.0, theta=500.0,\n",
        "                               n_quad=NQUAD_OBS, root_grid=GRID_OBS):\n",
        "    \"\"\"\n",
        "    Design B: Two different weights J₁(a1,b1) and J₂(a2,b2)\n",
        "    \"\"\"\n",
        "    x = np.asarray(x, float); x = x[x > theta]\n",
        "    n = x.size\n",
        "    if n < 5:\n",
        "        return np.nan, np.nan\n",
        "\n",
        "    xs  = np.sort(x)\n",
        "    i   = np.arange(1, n+1)\n",
        "    uo  = i/(n+1.0)\n",
        "\n",
        "    # Two different weights\n",
        "    J1 = a1*b1 * (uo**(a1-1.0)) * ((1.0 - uo**a1)**(b1-1.0))\n",
        "    J2 = a2*b2 * (uo**(a2-1.0)) * ((1.0 - uo**a2)**(b2-1.0))\n",
        "\n",
        "    # Normalize separately (important for Design B)\n",
        "    J1 = J1 / np.sum(J1)\n",
        "    J2 = J2 / np.sum(J2)\n",
        "\n",
        "    lx = np.log(xs)\n",
        "    mu1 = float(np.sum(J1 * lx))\n",
        "    mu2 = float(np.sum(J2 * lx))\n",
        "    Delta_w = mu2 - mu1\n",
        "\n",
        "    if abs(Delta_w) < 1e-12:\n",
        "        return np.nan, np.nan\n",
        "\n",
        "    # Solve Ψ(β) = c_{w,1}/τ_w + (log θ - μ₁)/Δ_w = 0\n",
        "    def Psi(beta):\n",
        "        c1, c2, tau_w = _cw_tau_designB(beta, a1, b1, a2, b2, n_quad=n_quad)\n",
        "        if abs(tau_w) < 1e-14:\n",
        "            return np.nan\n",
        "        return c1/tau_w + (np.log(theta) - mu1) / Delta_w\n",
        "\n",
        "    grid = np.linspace(-10.0, 10.0, int(root_grid))\n",
        "    vals = np.array([Psi(bi) for bi in grid])\n",
        "    sgn  = np.sign(vals)\n",
        "\n",
        "    beta_hat = None\n",
        "    for k in range(len(grid)-1):\n",
        "        if np.isfinite(vals[k]) and np.isfinite(vals[k+1]) and sgn[k]*sgn[k+1] < 0:\n",
        "            try:\n",
        "                beta_hat = brentq(lambda z: Psi(z), grid[k], grid[k+1], xtol=1e-8, maxiter=400)\n",
        "                break\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "    if beta_hat is None:\n",
        "        obj = lambda b: (Psi(b) if np.isfinite(Psi(b)) else 1e6)**2\n",
        "        res = minimize_scalar(obj, bounds=(-10.0, 10.0), method=\"bounded\",\n",
        "                              options={\"xatol\":1e-8, \"maxiter\":1000})\n",
        "        beta_hat = float(res.x)\n",
        "\n",
        "    c1, c2, tau_w_hat = _cw_tau_designB(beta_hat, a1, b1, a2, b2, n_quad=n_quad)\n",
        "\n",
        "    # Design B: α̂ = -τ_w / Δ_w\n",
        "    alpha_hat = -tau_w_hat / Delta_w\n",
        "\n",
        "    if alpha_hat <= 0:\n",
        "        return np.nan, np.nan\n",
        "\n",
        "    return float(alpha_hat), float(beta_hat)\n",
        "\n",
        "def make_safe_L_designB_factory(a1_req, b1_req, a2_req, b2_req, fallbacks=None,\n",
        "                                n_quad=NQUAD_OBS, root_grid=GRID_OBS):\n",
        "    \"\"\"\n",
        "    Factory for Design B with fallbacks\n",
        "    \"\"\"\n",
        "    if fallbacks is None:\n",
        "        # Fallback to known good pairs\n",
        "        fallbacks = [\n",
        "            ((1.0, 1.0), (1.0, 2.0)),   # Optimal\n",
        "            ((1.0, 1.0), (2.0, 1.0)),   # Optimal symmetric\n",
        "            ((1.0, 1.0), (0.8, 1.0)),   # Moderate\n",
        "        ]\n",
        "\n",
        "    def fit_fun(z, _nq=n_quad, _rg=root_grid):\n",
        "        ah, bh = fit_L_etll_designB_stable(z, a1_req, b1_req, a2_req, b2_req,\n",
        "                                          θ, n_quad=_nq, root_grid=_rg)\n",
        "        if np.isfinite(ah) and np.isfinite(bh):\n",
        "            return ah, bh\n",
        "\n",
        "        # Try fallbacks\n",
        "        for ((a1_fb, b1_fb), (a2_fb, b2_fb)) in fallbacks:\n",
        "            ah2, bh2 = fit_L_etll_designB_stable(z, a1_fb, b1_fb, a2_fb, b2_fb,\n",
        "                                                θ, n_quad=_nq, root_grid=_rg)\n",
        "            if np.isfinite(ah2) and np.isfinite(bh2):\n",
        "                return ah2, bh2\n",
        "\n",
        "        # Last resort: MLE\n",
        "        return fit_mle_etll(z, θ)\n",
        "\n",
        "    return fit_fun\n",
        "\n",
        "# ==============================================================\n",
        "# 4) MC P-VALUES\n",
        "# ==============================================================\n",
        "\n",
        "def mc_pvals_parallel_designB(x, fit_fun, theta, B=2000, seed=1234, n_jobs=N_JOBS, backend=BACKEND,\n",
        "                              nquad_obs=NQUAD_OBS, nquad_mc=NQUAD_MC, grid_obs=GRID_OBS, grid_mc=GRID_MC,\n",
        "                              batch=MC_BATCH):\n",
        "    if _HAS_TPCTL: threadpool_limits(BLAS_THREADS)\n",
        "    x = np.asarray(x, float); x = x[x > theta]\n",
        "    n = x.size\n",
        "    if n == 0: return (np.nan, np.nan, np.nan, np.nan, np.nan, np.nan)\n",
        "\n",
        "    def fit_obs(z): return fit_fun(z, _nq=nquad_obs, _rg=grid_obs)\n",
        "    a_hat, b_hat = fit_obs(x)\n",
        "    cdf_hat = lambda z: etll_cdf(z, a_hat, b_hat, theta)\n",
        "    D_obs = ks_statistic(x, cdf_hat); W_obs = cvm_statistic(x, cdf_hat)\n",
        "\n",
        "    seeds = SeedSequence(seed).spawn(B)\n",
        "    seed_ints = [int(s.generate_state(1)[0]) for s in seeds]\n",
        "\n",
        "    def one_rep(seed_i):\n",
        "        rng = default_rng(seed_i)\n",
        "        xb = etll_sample(n, a_hat, b_hat, theta, rng)\n",
        "        ah, bh = fit_fun(xb, _nq=nquad_mc, _rg=grid_mc)\n",
        "        cdf_b = lambda z, aa=ah, bb=bh: etll_cdf(z, aa, bb, theta)\n",
        "        return ks_statistic(xb, cdf_b), cvm_statistic(xb, cdf_b)\n",
        "\n",
        "    def _chunks(lst, k):\n",
        "        for i in range(0, len(lst), k): yield lst[i:i+k]\n",
        "\n",
        "    Ds_all, Ws_all = [], []\n",
        "    for chunk in _chunks(seed_ints, MC_BATCH):\n",
        "        Ds, Ws = zip(*Parallel(n_jobs=n_jobs, backend=backend)(\n",
        "            delayed(one_rep)(si) for si in chunk\n",
        "        ))\n",
        "        Ds_all.append(np.array(Ds)); Ws_all.append(np.array(Ws))\n",
        "    Ds = np.concatenate(Ds_all); Ws = np.concatenate(Ws_all)\n",
        "\n",
        "    p_ks  = (1.0 + np.sum(Ds >= D_obs)) / (B + 1.0)\n",
        "    p_cvm = (1.0 + np.sum(Ws >= W_obs)) / (B + 1.0)\n",
        "    return (a_hat, b_hat, D_obs, W_obs, p_ks, p_cvm)\n",
        "\n",
        "def mc_pvals_fixedparams_designB(x, fit_fun, theta, B=10000, seed=1234, n_jobs=N_JOBS, backend=BACKEND,\n",
        "                                 nquad_obs=NQUAD_OBS, batch=MC_BATCH):\n",
        "    if _HAS_TPCTL: threadpool_limits(BLAS_THREADS)\n",
        "    x = np.asarray(x, float); x = x[x > theta]\n",
        "    n = x.size\n",
        "    if n == 0: return (np.nan, np.nan, np.nan, np.nan, np.nan, np.nan)\n",
        "\n",
        "    a_hat, b_hat = fit_fun(x, _nq=nquad_obs, _rg=GRID_OBS)\n",
        "    cdf_hat = lambda z: etll_cdf(z, a_hat, b_hat, theta)\n",
        "    D_obs = ks_statistic(x, cdf_hat); W_obs = cvm_statistic(x, cdf_hat)\n",
        "\n",
        "    seeds = SeedSequence(seed).spawn(B)\n",
        "    seed_ints = [int(s.generate_state(1)[0]) for s in seeds]\n",
        "\n",
        "    def one_rep(seed_i):\n",
        "        rng = default_rng(seed_i)\n",
        "        xb = etll_sample(n, a_hat, b_hat, theta, rng)\n",
        "        return ks_statistic(xb, cdf_hat), cvm_statistic(xb, cdf_hat)\n",
        "\n",
        "    def _chunks(lst, k):\n",
        "        for i in range(0, len(lst), k): yield lst[i:i+k]\n",
        "\n",
        "    Ds_all, Ws_all = [], []\n",
        "    for chunk in _chunks(seed_ints, batch):\n",
        "        Ds, Ws = zip(*Parallel(n_jobs=n_jobs, backend=backend)(\n",
        "            delayed(one_rep)(si) for si in chunk\n",
        "        ))\n",
        "        Ds_all.append(np.array(Ds)); Ws_all.append(np.array(Ws))\n",
        "    Ds = np.concatenate(Ds_all); Ws = np.concatenate(Ws_all)\n",
        "\n",
        "    p_ks  = (1.0 + np.sum(Ds >= D_obs)) / (B + 1.0)\n",
        "    p_cvm = (1.0 + np.sum(Ws >= W_obs)) / (B + 1.0)\n",
        "    return (a_hat, b_hat, D_obs, W_obs, p_ks, p_cvm)\n",
        "\n",
        "# ==============================================================\n",
        "# 5) GoF with selectable mode\n",
        "# ==============================================================\n",
        "\n",
        "def gof_with_mode_designB(x, fit_fun, mode=\"mc\", B=100, seed=1234, n_jobs=N_JOBS):\n",
        "    x = np.asarray(x, float); x = x[x > θ]\n",
        "    if x.size == 0:\n",
        "        return {\"Estimator\":\"\", \"alpha\":np.nan, \"beta\":np.nan,\n",
        "                \"KS_p\":np.nan, \"KS_D\":np.nan, \"CvM_p\":np.nan, \"CvM_W\":np.nan,\n",
        "                \"_det\":1.0/(B+1.0)}\n",
        "\n",
        "    if mode == \"mc_fixed\":\n",
        "        a_hat, b_hat, D_obs, W_obs, p_ks, p_cvm = mc_pvals_fixedparams_designB(\n",
        "            x, fit_fun, θ, B=B, seed=seed, n_jobs=n_jobs, nquad_obs=NQUAD_OBS, batch=MC_BATCH\n",
        "        )\n",
        "        return {\"Estimator\":\"\", \"alpha\":a_hat, \"beta\":b_hat,\n",
        "                \"KS_p\":p_ks, \"KS_D\":D_obs, \"CvM_p\":p_cvm, \"CvM_W\":W_obs,\n",
        "                \"_det\":1.0/(B+1.0)}\n",
        "\n",
        "    if mode == \"mc\":\n",
        "        a_hat, b_hat, D_obs, W_obs, p_ks, p_cvm = mc_pvals_parallel_designB(\n",
        "            x, fit_fun, θ, B=B, seed=seed, n_jobs=n_jobs,\n",
        "            nquad_obs=NQUAD_OBS, nquad_mc=NQUAD_MC, grid_obs=GRID_OBS, grid_mc=GRID_MC\n",
        "        )\n",
        "        return {\"Estimator\":\"\", \"alpha\":a_hat, \"beta\":b_hat,\n",
        "                \"KS_p\":p_ks, \"KS_D\":D_obs, \"CvM_p\":p_cvm, \"CvM_W\":W_obs,\n",
        "                \"_det\":1.0/(B+1.0)}\n",
        "\n",
        "    # asymptotic\n",
        "    a_hat, b_hat = fit_fun(x)\n",
        "    cdf_hat = lambda z: etll_cdf(z, a_hat, b_hat, θ)\n",
        "    D_obs = ks_statistic(x, cdf_hat)\n",
        "    W_obs = cvm_statistic(x, cdf_hat)\n",
        "    p_ks  = float(kstwobign.sf(np.sqrt(x.size) * D_obs))\n",
        "    u = etll_cdf(np.sort(x), a_hat, b_hat, θ)\n",
        "    p_cvm = float(cramervonmises(u, uniform.cdf).pvalue)\n",
        "    return {\"Estimator\":\"\", \"alpha\":a_hat, \"beta\":b_hat,\n",
        "            \"KS_p\":p_ks, \"KS_D\":D_obs, \"CvM_p\":p_cvm, \"CvM_W\":W_obs,\n",
        "            \"_det\":0.0}\n",
        "\n",
        "def build_panel_designB(x, estimators, mode=\"mc\", B=100, seed=1234, n_jobs=N_JOBS):\n",
        "    rows = []\n",
        "    for (name, fit_fun) in estimators:\n",
        "        r = gof_with_mode_designB(x, fit_fun, mode=mode, B=B, seed=seed, n_jobs=n_jobs)\n",
        "        r[\"Estimator\"] = name\n",
        "        rows.append(r)\n",
        "    return rows\n"
      ],
      "metadata": {
        "id": "ne8gDBdj3K4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# RISK MEASURES FOR DESIGN B (Different J, Same h)\n",
        "# ==============================================================================\n",
        "\n",
        "\n",
        "\n",
        "class ETELLRiskMeasures:\n",
        "\n",
        "    def __init__(self, theta=500.0, n_quad=400):\n",
        "        self.theta = theta\n",
        "        self.n_quad = n_quad\n",
        "        nodes, weights = leggauss(n_quad)\n",
        "        self.u = 0.5 * (nodes + 1.0)\n",
        "        self.w = 0.5 * weights\n",
        "        self.ln2 = np.log(2.0)\n",
        "\n",
        "    def etll_quantile(self, u, alpha, beta):\n",
        "        u = np.clip(np.asarray(u, float), 1e-12, 1-1e-12)\n",
        "        if abs(beta) < 1e-10:\n",
        "            t = np.expm1((1.0 - u) * self.ln2)\n",
        "        else:\n",
        "            two_b = np.exp(beta * self.ln2)\n",
        "            base = np.maximum(two_b - (two_b - 1.0) * u, 1e-300)\n",
        "            t = np.expm1(np.log(base) / beta)\n",
        "        return self.theta * np.power(np.maximum(t, 1e-300), -1.0 / alpha)\n",
        "\n",
        "    def var(self, alpha, beta, confidence_level=0.99):\n",
        "        return self.etll_quantile(confidence_level, alpha, beta)\n",
        "\n",
        "    def cte(self, alpha, beta, confidence_level=0.99):\n",
        "        if alpha <= 1.0:\n",
        "            return float('inf')\n",
        "        p = float(confidence_level)\n",
        "        s = p + (1.0 - p) * self.u\n",
        "        q_vals = self.etll_quantile(s, alpha, beta)\n",
        "        return float(np.sum(self.w * q_vals))\n",
        "\n",
        "    def compute_risk_measures(self, alpha, beta, confidence_levels=[0.98, 0.99, 0.995]):\n",
        "        results = {}\n",
        "        for cl in confidence_levels:\n",
        "            tail_prob = 1.0 - cl\n",
        "            var_val = self.var(alpha, beta, cl)\n",
        "            cte_val = self.cte(alpha, beta, cl)\n",
        "            results[cl] = {\n",
        "                'confidence_level': cl,\n",
        "                'tail_probability': tail_prob,\n",
        "                'VaR': var_val,\n",
        "                'CTE': cte_val\n",
        "            }\n",
        "        return results\n",
        "\n",
        "\n",
        "# Empirical measures\n",
        "def empirical_var(x, confidence_level=0.99):\n",
        "    x = np.sort(np.asarray(x, float))\n",
        "    return float(np.quantile(x, confidence_level, method='linear'))\n",
        "\n",
        "def empirical_cte(x, confidence_level=0.99):\n",
        "    x = np.asarray(x, float)\n",
        "    var_emp = empirical_var(x, confidence_level)\n",
        "    exceedances = x[x > var_emp]\n",
        "    if exceedances.size == 0:\n",
        "        return np.nan\n",
        "    return float(np.mean(exceedances))\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# DESIGN B SPECIFIC: Risk table computation\n",
        "# ==============================================================================\n",
        "\n",
        "def compute_risk_table_designB(data_dict, estimators, confidence_levels=[0.98, 0.99, 0.995],\n",
        "                               theta=500.0, n_quad=400):\n",
        "\n",
        "    rm = ETELLRiskMeasures(theta=theta, n_quad=n_quad)\n",
        "    results = {}\n",
        "\n",
        "    for data_name, x in data_dict.items():\n",
        "        x = np.asarray(x, float)\n",
        "        x = x[x > theta]\n",
        "\n",
        "        if x.size == 0:\n",
        "            continue\n",
        "\n",
        "        results[data_name] = {}\n",
        "\n",
        "        # Empirical measures\n",
        "        emp_results = {}\n",
        "        for cl in confidence_levels:\n",
        "            emp_results[cl] = {\n",
        "                'VaR': empirical_var(x, cl),\n",
        "                'CTE': empirical_cte(x, cl)\n",
        "            }\n",
        "        results[data_name]['Empirical'] = emp_results\n",
        "\n",
        "        # Fitted model measures\n",
        "        for est_name, fit_fun in estimators:\n",
        "            try:\n",
        "                alpha_hat, beta_hat = fit_fun(x)\n",
        "\n",
        "                if not (np.isfinite(alpha_hat) and np.isfinite(beta_hat)):\n",
        "                    results[data_name][est_name] = None\n",
        "                    continue\n",
        "\n",
        "                model_results = rm.compute_risk_measures(\n",
        "                    alpha_hat, beta_hat, confidence_levels\n",
        "                )\n",
        "\n",
        "                # Add fitted parameters\n",
        "                model_results['alpha'] = alpha_hat\n",
        "                model_results['beta'] = beta_hat\n",
        "\n",
        "                results[data_name][est_name] = model_results\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Warning: {est_name} failed on {data_name}: {e}\")\n",
        "                results[data_name][est_name] = None\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "_INF_THRESHOLD = 1e15\n",
        "\n",
        "def _fmt(v):\n",
        "    if v is None or not np.isfinite(v) or v > _INF_THRESHOLD:\n",
        "        return \"∞\"\n",
        "    return f\"{v:,.2f}\"\n",
        "\n",
        "def _fmtdiff(a, b):\n",
        "    bad = lambda z: (z is None) or (not np.isfinite(z)) or (z > _INF_THRESHOLD)\n",
        "    if bad(a) or bad(b):\n",
        "        return \"—\"\n",
        "    return f\"{(a - b):+,.2f}\"\n",
        "\n",
        "\n",
        "def print_risk_table_designB(results, confidence_levels=[0.98, 0.99, 0.995]):\n",
        "    \"\"\"Print detailed risk measures table for Design B\"\"\"\n",
        "    for data_name, data_results in results.items():\n",
        "        print(\"\\n\" + \"=\"*100)\n",
        "        print(f\"Risk Measures (Design B): {data_name}\")\n",
        "        print(\"=\"*100)\n",
        "\n",
        "        estimators = [k for k in data_results.keys() if k != 'Empirical']\n",
        "\n",
        "        for cl in confidence_levels:\n",
        "            tail_prob = 1.0 - cl\n",
        "            print(f\"\\n{'Confidence Level':<20} {cl*100:.1f}% (Tail Probability = {tail_prob*100:.2f}%)\")\n",
        "            print(\"-\"*100)\n",
        "\n",
        "            # Header\n",
        "            print(f\"{'Method':<20} {'α̂':>8} {'β̂':>8} {'VaR':>15} {'CTE':>15} {'VaR Diff':>15} {'CTE Diff':>15}\")\n",
        "            print(\"-\"*100)\n",
        "\n",
        "            # Empirical row\n",
        "            emp = data_results['Empirical'][cl]\n",
        "            print(f\"{'Empirical':<20} {'-':>8} {'-':>8} {_fmt(emp['VaR']):>15} {_fmt(emp['CTE']):>15} {'-':>15} {'-':>15}\")\n",
        "\n",
        "            # Model rows\n",
        "            for est_name in estimators:\n",
        "                est_results = data_results[est_name]\n",
        "                if est_results is None or cl not in est_results:\n",
        "                    print(f\"{est_name:<20} {'FAILED':>8} {'FAILED':>8} {'-':>15} {'-':>15} {'-':>15} {'-':>15}\")\n",
        "                    continue\n",
        "\n",
        "                alpha_hat = est_results['alpha']\n",
        "                beta_hat = est_results['beta']\n",
        "                var_theo = est_results[cl]['VaR']\n",
        "                cte_theo = est_results[cl]['CTE']\n",
        "\n",
        "                print(f\"{est_name:<20} {alpha_hat:>8.2f} {beta_hat:>8.2f} \"\n",
        "                      f\"{_fmt(var_theo):>15} {_fmt(cte_theo):>15} \"\n",
        "                      f\"{_fmtdiff(var_theo, emp['VaR']):>15} {_fmtdiff(cte_theo, emp['CTE']):>15}\")\n",
        "\n",
        "\n",
        "def print_comparison_table_designB(results, confidence_level=0.99):\n",
        "    \"\"\"Print side-by-side comparison for Design B\"\"\"\n",
        "    datasets = list(results.keys())\n",
        "    first_data = results[datasets[0]]\n",
        "    estimators = [k for k in first_data.keys() if k != 'Empirical']\n",
        "\n",
        "    print(\"\\n\" + \"=\"*140)\n",
        "    print(f\"Risk Measures Comparison (Design B) at {confidence_level*100:.1f}% Confidence Level\")\n",
        "    print(\"=\"*140)\n",
        "\n",
        "    # Header\n",
        "    header = f\"{'Method':<20}\"\n",
        "    for data_name in datasets:\n",
        "        header += f\" | {data_name:^28}\"\n",
        "    print(header)\n",
        "\n",
        "    subheader = f\"{'':<20}\"\n",
        "    for _ in datasets:\n",
        "        subheader += f\" | {'VaR':>13} {'CTE':>13}\"\n",
        "    print(subheader)\n",
        "    print(\"-\"*140)\n",
        "\n",
        "    # Empirical row\n",
        "    row = f\"{'Empirical':<20}\"\n",
        "    for data_name in datasets:\n",
        "        emp = results[data_name]['Empirical'][confidence_level]\n",
        "        row += f\" | {_fmt(emp['VaR']):>13} {_fmt(emp['CTE']):>13}\"\n",
        "    print(row)\n",
        "\n",
        "    print(\"-\"*140)\n",
        "\n",
        "    # Model rows\n",
        "    for est_name in ['MLE'] + [e for e in estimators if e != 'MLE']:\n",
        "        row = f\"{est_name:<20}\"\n",
        "        for data_name in datasets:\n",
        "            est_results = results[data_name].get(est_name)\n",
        "            if est_results is None or confidence_level not in est_results:\n",
        "                row += f\" | {'FAILED':>13} {'FAILED':>13}\"\n",
        "            else:\n",
        "                var_theo = est_results[confidence_level]['VaR']\n",
        "                cte_theo = est_results[confidence_level]['CTE']\n",
        "                row += f\" | {_fmt(var_theo):>13} {_fmt(cte_theo):>13}\"\n",
        "        print(row)\n",
        "\n",
        "    print(\"=\"*140)\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# RUN RISK MEASURES FOR DESIGN B\n",
        "# ==============================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # Define datasets (same as Method 1)\n",
        "    data_dict_designB = {\n",
        "        'Sampled (n=50)': x_sampled,\n",
        "        'Modified Sampled': x_mod_sampled,\n",
        "        'Original (n=9020)': x_original,\n",
        "        'Modified Original': x_mod_original,\n",
        "    }\n",
        "\n",
        "    # Define estimators for Design B\n",
        "\n",
        "    estimators_samp_risk = [\n",
        "        (\"MLE\", lambda z: fit_mle_etll(z, θ)),\n",
        "        (\"J₂(1.8,1.1)\", make_safe_L_designB_factory(1.0, 1.0, 1.8, 1.1)),\n",
        "        (\"J₂(1.9,1.1)\", make_safe_L_designB_factory(1.0, 1.0, 1.9, 1.1)),\n",
        "        (\"J₂(2.0,1.1)\", make_safe_L_designB_factory(1.0, 1.0, 2.0, 1.1)),\n",
        "        (\"J₂(2.2,1.1)\", make_safe_L_designB_factory(1.0, 1.0, 2.2, 1.1)),\n",
        "    ]\n",
        "\n",
        "    # For original data (n=9020)\n",
        "    estimators_orig_risk = [\n",
        "        (\"MLE\", lambda z: fit_mle_etll(z, θ)),\n",
        "        (\"J₂(3.0,12.0)\", make_safe_L_designB_factory(11.0, 6.0, 3.0, 12.0)),\n",
        "    ]\n",
        "\n",
        "\n",
        "    estimators_designB_unified = [\n",
        "        (\"MLE\", lambda z: fit_mle_etll(z, θ)),\n",
        "        (\"J₂(1.8,1.1)\", make_safe_L_designB_factory(1.0, 1.0, 1.8, 1.1)),\n",
        "        (\"J₂(1.9,1.1)\", make_safe_L_designB_factory(1.0, 1.0, 1.9, 1.1)),\n",
        "        (\"J₂(2.0,1.1)\", make_safe_L_designB_factory(1.0, 1.0, 2.0, 1.1)),\n",
        "        (\"J₂(2.2,1.1)\", make_safe_L_designB_factory(1.0, 1.0, 2.2, 1.1)),\n",
        "    ]\n",
        "\n",
        "    print(\"\\n\" + \"=\"*100)\n",
        "    print(\"COMPUTING RISK MEASURES FOR DESIGN B\")\n",
        "    print(\"=\"*100)\n",
        "    print(\"Datasets: 4 (Original, Modified Original, Sampled, Modified Sampled)\")\n",
        "    print(\"Estimators: Design B with J₁(1.0,1.0) fixed, varying J₂\")\n",
        "    print(\"Confidence Levels: 98%, 99%, 99.5%\")\n",
        "    print(\"=\"*100)\n",
        "\n",
        "    results_designB = compute_risk_table_designB(\n",
        "        data_dict=data_dict_designB,\n",
        "        estimators=estimators_designB_unified,\n",
        "        confidence_levels=[0.98, 0.99, 0.995],\n",
        "        theta=500.0,\n",
        "        n_quad=400\n",
        "    )\n",
        "\n",
        "    # Print detailed tables\n",
        "    print_risk_table_designB(results_designB, confidence_levels=[0.98, 0.99, 0.995])\n",
        "\n",
        "    # Print comparison tables\n",
        "    print_comparison_table_designB(results_designB, confidence_level=0.98)\n",
        "    print_comparison_table_designB(results_designB, confidence_level=0.99)\n",
        "    print_comparison_table_designB(results_designB, confidence_level=0.995)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35kgeTgo2jGV",
        "outputId": "fbc120eb-0371-4d2a-b286-41cafe5b3ace"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "====================================================================================================\n",
            "COMPUTING RISK MEASURES FOR DESIGN B\n",
            "====================================================================================================\n",
            "Datasets: 4 (Original, Modified Original, Sampled, Modified Sampled)\n",
            "Estimators: Design B with J₁(1.0,1.0) fixed, varying J₂\n",
            "Confidence Levels: 98%, 99%, 99.5%\n",
            "====================================================================================================\n",
            "\n",
            "====================================================================================================\n",
            "Risk Measures (Design B): Sampled (n=50)\n",
            "====================================================================================================\n",
            "\n",
            "Confidence Level     98.0% (Tail Probability = 2.00%)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Method                     α̂       β̂             VaR             CTE        VaR Diff        CTE Diff\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Empirical                   -        -        4,381.60        4,607.00               -               -\n",
            "MLE                      1.77    -1.14        6,905.49       15,934.55       +2,523.89      +11,327.55\n",
            "J₂(1.8,1.1)              1.68    -0.75        7,372.69       18,232.07       +2,991.09      +13,625.07\n",
            "J₂(1.9,1.1)              1.70    -0.82        7,260.26       17,686.43       +2,878.66      +13,079.43\n",
            "J₂(2.0,1.1)              1.71    -0.87        7,177.16       17,292.21       +2,795.56      +12,685.21\n",
            "J₂(2.2,1.1)              1.73    -0.95        7,055.40       16,727.96       +2,673.80      +12,120.96\n",
            "\n",
            "Confidence Level     99.0% (Tail Probability = 1.00%)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Method                     α̂       β̂             VaR             CTE        VaR Diff        CTE Diff\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Empirical                   -        -        4,494.30        4,607.00               -               -\n",
            "MLE                      1.77    -1.14       10,253.51       23,611.90       +5,759.21      +19,004.90\n",
            "J₂(1.8,1.1)              1.68    -0.75       11,173.34       27,575.05       +6,679.04      +22,968.05\n",
            "J₂(1.9,1.1)              1.70    -0.82       10,955.45       26,634.20       +6,461.15      +22,027.20\n",
            "J₂(2.0,1.1)              1.71    -0.87       10,795.30       25,956.87       +6,301.00      +21,349.87\n",
            "J₂(2.2,1.1)              1.73    -0.95       10,561.93       24,991.01       +6,067.63      +20,384.01\n",
            "\n",
            "Confidence Level     99.5% (Tail Probability = 0.50%)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Method                     α̂       β̂             VaR             CTE        VaR Diff        CTE Diff\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Empirical                   -        -        4,550.65        4,607.00               -               -\n",
            "MLE                      1.77    -1.14       15,202.42       34,972.75      +10,651.77      +30,365.75\n",
            "J₂(1.8,1.1)              1.68    -0.75       16,909.17       41,688.77      +12,358.52      +37,081.77\n",
            "J₂(1.9,1.1)              1.70    -0.82       16,507.72       40,092.09      +11,957.07      +35,485.09\n",
            "J₂(2.0,1.1)              1.71    -0.87       16,214.05       38,946.76      +11,663.40      +34,339.76\n",
            "J₂(2.2,1.1)              1.73    -0.95       15,788.34       37,319.74      +11,237.69      +32,712.74\n",
            "\n",
            "====================================================================================================\n",
            "Risk Measures (Design B): Modified Sampled\n",
            "====================================================================================================\n",
            "\n",
            "Confidence Level     98.0% (Tail Probability = 2.00%)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Method                     α̂       β̂             VaR             CTE        VaR Diff        CTE Diff\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Empirical                   -        -       44,289.46    2,000,000.00               -               -\n",
            "MLE                      0.26     9.67       29,458.33               ∞      -14,831.13               —\n",
            "J₂(1.8,1.1)              1.28     0.07       13,829.97       60,116.57      -30,459.49   -1,939,883.43\n",
            "J₂(1.9,1.1)              1.24     0.24       14,527.72       69,112.62      -29,761.74   -1,930,887.38\n",
            "J₂(2.0,1.1)              1.21     0.39       15,118.80       77,872.66      -29,170.66   -1,922,127.34\n",
            "J₂(2.2,1.1)              1.17     0.60       16,084.64       94,940.44      -28,204.82   -1,905,059.56\n",
            "\n",
            "Confidence Level     99.0% (Tail Probability = 1.00%)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Method                     α̂       β̂             VaR             CTE        VaR Diff        CTE Diff\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Empirical                   -        -    1,022,144.73    2,000,000.00               -               -\n",
            "MLE                      0.26     9.67       87,918.47               ∞     -934,226.26               —\n",
            "J₂(1.8,1.1)              1.28     0.07       23,835.52      103,392.11     -998,309.21   -1,896,607.89\n",
            "J₂(1.9,1.1)              1.24     0.24       25,435.63      120,776.35     -996,709.10   -1,879,223.65\n",
            "J₂(2.0,1.1)              1.21     0.39       26,819.27      137,907.25     -995,325.46   -1,862,092.75\n",
            "J₂(2.2,1.1)              1.17     0.60       29,136.43      171,765.66     -993,008.30   -1,828,234.34\n",
            "\n",
            "Confidence Level     99.5% (Tail Probability = 0.50%)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Method                     α̂       β̂             VaR             CTE        VaR Diff        CTE Diff\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Empirical                   -        -    1,511,072.37    2,000,000.00               -               -\n",
            "MLE                      0.26     9.67      322,068.90               ∞   -1,189,003.46               —\n",
            "J₂(1.8,1.1)              1.28     0.07       41,026.68      177,776.50   -1,470,045.69   -1,822,223.50\n",
            "J₂(1.9,1.1)              1.24     0.24       44,482.55      211,017.59   -1,466,589.81   -1,788,982.41\n",
            "J₂(2.0,1.1)              1.21     0.39       47,527.08      244,183.93   -1,463,545.28   -1,755,816.07\n",
            "J₂(2.2,1.1)              1.17     0.60       52,740.58      310,723.75   -1,458,331.78   -1,689,276.25\n",
            "\n",
            "====================================================================================================\n",
            "Risk Measures (Design B): Original (n=9020)\n",
            "====================================================================================================\n",
            "\n",
            "Confidence Level     98.0% (Tail Probability = 2.00%)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Method                     α̂       β̂             VaR             CTE        VaR Diff        CTE Diff\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Empirical                   -        -       12,009.30       33,725.79               -               -\n",
            "MLE                      1.49    -1.06       11,034.15       33,284.18         -975.15         -441.61\n",
            "J₂(1.8,1.1)              1.51    -1.17       10,804.70       31,738.45       -1,204.60       -1,987.34\n",
            "J₂(1.9,1.1)              1.51    -1.14       10,868.36       32,131.99       -1,140.94       -1,593.80\n",
            "J₂(2.0,1.1)              1.50    -1.13       10,920.28       32,456.06       -1,089.02       -1,269.73\n",
            "J₂(2.2,1.1)              1.50    -1.09       11,002.77       32,976.86       -1,006.53         -748.93\n",
            "\n",
            "Confidence Level     99.0% (Tail Probability = 1.00%)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Method                     α̂       β̂             VaR             CTE        VaR Diff        CTE Diff\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Empirical                   -        -       19,991.14       51,638.16               -               -\n",
            "MLE                      1.49    -1.06       17,625.93       53,031.90       -2,365.21       +1,393.73\n",
            "J₂(1.8,1.1)              1.51    -1.17       17,148.23       50,243.48       -2,842.91       -1,394.68\n",
            "J₂(1.9,1.1)              1.51    -1.14       17,276.63       50,947.04       -2,714.51         -691.13\n",
            "J₂(2.0,1.1)              1.50    -1.13       17,381.55       51,527.13       -2,609.59         -111.03\n",
            "J₂(2.2,1.1)              1.50    -1.09       17,548.63       52,460.77       -2,442.51         +822.60\n",
            "\n",
            "Confidence Level     99.5% (Tail Probability = 0.50%)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Method                     α̂       β̂             VaR             CTE        VaR Diff        CTE Diff\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Empirical                   -        -       32,069.19       77,271.35               -               -\n",
            "MLE                      1.49    -1.06       28,107.38       84,460.02       -3,961.80       +7,188.67\n",
            "J₂(1.8,1.1)              1.51    -1.17       27,169.19       79,503.05       -4,899.99       +2,231.70\n",
            "J₂(1.9,1.1)              1.51    -1.14       27,416.09       80,744.19       -4,653.09       +3,472.84\n",
            "J₂(2.0,1.1)              1.50    -1.13       27,618.18       81,768.87       -4,451.00       +4,497.52\n",
            "J₂(2.2,1.1)              1.50    -1.09       27,940.68       83,420.55       -4,128.51       +6,149.20\n",
            "\n",
            "====================================================================================================\n",
            "Risk Measures (Design B): Modified Original\n",
            "====================================================================================================\n",
            "\n",
            "Confidence Level     98.0% (Tail Probability = 2.00%)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Method                     α̂       β̂             VaR             CTE        VaR Diff        CTE Diff\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Empirical                   -        -       12,009.30       42,204.44               -               -\n",
            "MLE                      1.49    -1.06       11,045.99       33,353.02         -963.31       -8,851.42\n",
            "J₂(1.8,1.1)              1.51    -1.17       10,797.96       31,688.86       -1,211.34      -10,515.58\n",
            "J₂(1.9,1.1)              1.51    -1.15       10,863.80       32,095.31       -1,145.50      -10,109.12\n",
            "J₂(2.0,1.1)              1.50    -1.13       10,917.39       32,429.43       -1,091.91       -9,775.01\n",
            "J₂(2.2,1.1)              1.50    -1.10       11,002.30       32,965.08       -1,007.00       -9,239.36\n",
            "\n",
            "Confidence Level     99.0% (Tail Probability = 1.00%)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Method                     α̂       β̂             VaR             CTE        VaR Diff        CTE Diff\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Empirical                   -        -       19,991.14       68,502.29               -               -\n",
            "MLE                      1.49    -1.06       17,649.07       53,154.29       -2,342.07      -15,347.99\n",
            "J₂(1.8,1.1)              1.51    -1.17       17,133.56       50,153.38       -2,857.58      -18,348.90\n",
            "J₂(1.9,1.1)              1.51    -1.15       17,266.33       50,879.89       -2,724.81      -17,622.40\n",
            "J₂(2.0,1.1)              1.50    -1.13       17,374.60       51,477.88       -2,616.54      -17,024.41\n",
            "J₂(2.2,1.1)              1.50    -1.10       17,546.55       52,438.02       -2,444.59      -16,064.26\n",
            "\n",
            "Confidence Level     99.5% (Tail Probability = 0.50%)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Method                     α̂       β̂             VaR             CTE        VaR Diff        CTE Diff\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Empirical                   -        -       32,069.19      110,632.98               -               -\n",
            "MLE                      1.49    -1.06       28,151.02       84,675.22       -3,918.16      -25,957.76\n",
            "J₂(1.8,1.1)              1.51    -1.17       27,139.67       79,342.09       -4,929.51      -31,290.88\n",
            "J₂(1.9,1.1)              1.51    -1.15       27,394.89       80,623.47       -4,674.29      -30,009.51\n",
            "J₂(2.0,1.1)              1.50    -1.13       27,603.39       81,679.61       -4,465.79      -28,953.37\n",
            "J₂(2.2,1.1)              1.50    -1.10       27,935.23       83,378.02       -4,133.95      -27,254.96\n",
            "\n",
            "============================================================================================================================================\n",
            "Risk Measures Comparison (Design B) at 98.0% Confidence Level\n",
            "============================================================================================================================================\n",
            "Method               |        Sampled (n=50)        |       Modified Sampled       |      Original (n=9020)       |      Modified Original      \n",
            "                     |           VaR           CTE |           VaR           CTE |           VaR           CTE |           VaR           CTE\n",
            "--------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Empirical            |      4,381.60      4,607.00 |     44,289.46  2,000,000.00 |     12,009.30     33,725.79 |     12,009.30     42,204.44\n",
            "--------------------------------------------------------------------------------------------------------------------------------------------\n",
            "MLE                  |      6,905.49     15,934.55 |     29,458.33             ∞ |     11,034.15     33,284.18 |     11,045.99     33,353.02\n",
            "J₂(1.8,1.1)          |      7,372.69     18,232.07 |     13,829.97     60,116.57 |     10,804.70     31,738.45 |     10,797.96     31,688.86\n",
            "J₂(1.9,1.1)          |      7,260.26     17,686.43 |     14,527.72     69,112.62 |     10,868.36     32,131.99 |     10,863.80     32,095.31\n",
            "J₂(2.0,1.1)          |      7,177.16     17,292.21 |     15,118.80     77,872.66 |     10,920.28     32,456.06 |     10,917.39     32,429.43\n",
            "J₂(2.2,1.1)          |      7,055.40     16,727.96 |     16,084.64     94,940.44 |     11,002.77     32,976.86 |     11,002.30     32,965.08\n",
            "============================================================================================================================================\n",
            "\n",
            "============================================================================================================================================\n",
            "Risk Measures Comparison (Design B) at 99.0% Confidence Level\n",
            "============================================================================================================================================\n",
            "Method               |        Sampled (n=50)        |       Modified Sampled       |      Original (n=9020)       |      Modified Original      \n",
            "                     |           VaR           CTE |           VaR           CTE |           VaR           CTE |           VaR           CTE\n",
            "--------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Empirical            |      4,494.30      4,607.00 |  1,022,144.73  2,000,000.00 |     19,991.14     51,638.16 |     19,991.14     68,502.29\n",
            "--------------------------------------------------------------------------------------------------------------------------------------------\n",
            "MLE                  |     10,253.51     23,611.90 |     87,918.47             ∞ |     17,625.93     53,031.90 |     17,649.07     53,154.29\n",
            "J₂(1.8,1.1)          |     11,173.34     27,575.05 |     23,835.52    103,392.11 |     17,148.23     50,243.48 |     17,133.56     50,153.38\n",
            "J₂(1.9,1.1)          |     10,955.45     26,634.20 |     25,435.63    120,776.35 |     17,276.63     50,947.04 |     17,266.33     50,879.89\n",
            "J₂(2.0,1.1)          |     10,795.30     25,956.87 |     26,819.27    137,907.25 |     17,381.55     51,527.13 |     17,374.60     51,477.88\n",
            "J₂(2.2,1.1)          |     10,561.93     24,991.01 |     29,136.43    171,765.66 |     17,548.63     52,460.77 |     17,546.55     52,438.02\n",
            "============================================================================================================================================\n",
            "\n",
            "============================================================================================================================================\n",
            "Risk Measures Comparison (Design B) at 99.5% Confidence Level\n",
            "============================================================================================================================================\n",
            "Method               |        Sampled (n=50)        |       Modified Sampled       |      Original (n=9020)       |      Modified Original      \n",
            "                     |           VaR           CTE |           VaR           CTE |           VaR           CTE |           VaR           CTE\n",
            "--------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Empirical            |      4,550.65      4,607.00 |  1,511,072.37  2,000,000.00 |     32,069.19     77,271.35 |     32,069.19    110,632.98\n",
            "--------------------------------------------------------------------------------------------------------------------------------------------\n",
            "MLE                  |     15,202.42     34,972.75 |    322,068.90             ∞ |     28,107.38     84,460.02 |     28,151.02     84,675.22\n",
            "J₂(1.8,1.1)          |     16,909.17     41,688.77 |     41,026.68    177,776.50 |     27,169.19     79,503.05 |     27,139.67     79,342.09\n",
            "J₂(1.9,1.1)          |     16,507.72     40,092.09 |     44,482.55    211,017.59 |     27,416.09     80,744.19 |     27,394.89     80,623.47\n",
            "J₂(2.0,1.1)          |     16,214.05     38,946.76 |     47,527.08    244,183.93 |     27,618.18     81,768.87 |     27,603.39     81,679.61\n",
            "J₂(2.2,1.1)          |     15,788.34     37,319.74 |     52,740.58    310,723.75 |     27,940.68     83,420.55 |     27,935.23     83,378.02\n",
            "============================================================================================================================================\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}